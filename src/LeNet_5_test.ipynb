{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS & PREPRODUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhyunseokerikjung\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_100450-39l6atze</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/LeNet_5_test/runs/39l6atze\" target=\"_blank\">efficient-dawn-37</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/LeNet_5_test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/hyunseokerikjung/LeNet_5_test/runs/39l6atze?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x212c191d850>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "wandb.init(project=\"LeNet_5_test\", entity=\"hyunseokerikjung\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('emnist-byclass-mapping.txt', sep=\" \", header=None)\n",
    "data.columns = ['Target','ASCII']\n",
    "\n",
    "col=[]\n",
    "for i in data.ASCII.tolist():\n",
    "    col.append(chr(i))\n",
    "\n",
    "data['ASCII_Target'] = pd.Series(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_df = pd.read_csv('augmented_emnist.csv')\n",
    "aug_df.rename(columns={'25':'Target'}, inplace=True)\n",
    "\n",
    "# train_df=pd.merge(train_df, data, how='left', on='Target')\n",
    "# train_df=train_df.drop(['Target','ASCII'],axis=1)\n",
    "# train_df.rename(columns={'ASCII_Target':'Target'}, inplace=True)\n",
    "\n",
    "train_y = np.array(aug_df.pop('Target'))\n",
    "train_x = aug_df\n",
    "\n",
    "train_x = train_x / 255.0\n",
    "train_x = train_x.values.reshape([-1, 28, 28, 1])\n",
    "train_y = keras.utils.to_categorical(train_y)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('emnist-byclass-train.csv/emnist-byclass-train.csv')\n",
    "train_df.rename(columns={'35':'Target'}, inplace=True)\n",
    "\n",
    "# train_df=pd.merge(train_df, data, how='left', on='Target')\n",
    "# train_df=train_df.drop(['Target','ASCII'],axis=1)\n",
    "# train_df.rename(columns={'ASCII_Target':'Target'}, inplace=True)\n",
    "\n",
    "train_y = np.array(train_df.pop('Target'))\n",
    "train_x = train_df\n",
    "\n",
    "train_x = train_x / 255.0\n",
    "train_x = train_x.values.reshape([-1, 28, 28, 1])\n",
    "train_y = keras.utils.to_categorical(train_y)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('emnist-byclass-test.csv/emnist-byclass-test.csv')\n",
    "test_df.rename(columns={'18':'Target'}, inplace=True)\n",
    "\n",
    "# test_df=pd.merge(test_df, data, how='left', on='Target')\n",
    "# test_df=test_df.drop(['Target','ASCII'],axis=1)\n",
    "# test_df.rename(columns={'ASCII_Target':'Target'}, inplace=True)\n",
    "\n",
    "test_y = np.array(test_df.pop('Target'))\n",
    "test_x = test_df\n",
    "\n",
    "test_x = test_x / 255.0\n",
    "test_x = test_x.values.reshape([-1, 28, 28, 1])\n",
    "test_y = keras.utils.to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_df = pd.read_csv('our_handmade_dataset.csv')\n",
    "hand_df.rename(columns={'0':'Target'}, inplace=True)\n",
    "\n",
    "# hand_df=pd.merge(hand_df, data, how='left', on='Target')\n",
    "# hand_df=hand_df.drop(['Target','ASCII'],axis=1)\n",
    "# hand_df.rename(columns={'ASCII_Target':'Target'}, inplace=True)\n",
    "\n",
    "hand_y = np.array(hand_df.pop('Target'))\n",
    "hand_x = hand_df\n",
    "\n",
    "hand_x = hand_x / 255.0\n",
    "hand_x = hand_x.values.reshape([-1, 28, 28, 1])\n",
    "hand_y = keras.utils.to_categorical(hand_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode=\"constant\",\n",
    "    cval=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original LeNet_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 6)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 1, 120)         48120     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                5270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,126\n",
      "Trainable params: 66,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lenet_5_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation='tanh', input_shape=train_x[0].shape, padding='same'),\n",
    "    keras.layers.AveragePooling2D(),\n",
    "    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation='tanh', padding='valid'),\n",
    "    keras.layers.AveragePooling2D(),\n",
    "    keras.layers.Conv2D(120, kernel_size=5, strides=1, activation='tanh', padding='valid'),\n",
    "    keras.layers.Flatten(),   \n",
    "    keras.layers.Dense(84, activation='tanh'),\n",
    "    keras.layers.Dense(62, activation='softmax')\n",
    "])\n",
    "lenet_5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17449/17449 [==============================] - 55s 3ms/step - loss: 0.5816 - accuracy: 0.8079 - val_loss: 0.4674 - val_accuracy: 0.8347\n",
      "Epoch 2/100\n",
      "17449/17449 [==============================] - 54s 3ms/step - loss: 0.4497 - accuracy: 0.8407 - val_loss: 0.4576 - val_accuracy: 0.8392\n",
      "Epoch 3/100\n",
      "17449/17449 [==============================] - 53s 3ms/step - loss: 0.4319 - accuracy: 0.8453 - val_loss: 0.4496 - val_accuracy: 0.8397\n",
      "Epoch 4/100\n",
      "17449/17449 [==============================] - 53s 3ms/step - loss: 0.4220 - accuracy: 0.8480 - val_loss: 0.4377 - val_accuracy: 0.8444\n",
      "Epoch 5/100\n",
      "17449/17449 [==============================] - 53s 3ms/step - loss: 0.4159 - accuracy: 0.8497 - val_loss: 0.4338 - val_accuracy: 0.8471\n",
      "Epoch 6/100\n",
      "17449/17449 [==============================] - 58s 3ms/step - loss: 0.4113 - accuracy: 0.8510 - val_loss: 0.4303 - val_accuracy: 0.8467\n",
      "Epoch 7/100\n",
      "17449/17449 [==============================] - 57s 3ms/step - loss: 0.4067 - accuracy: 0.8528 - val_loss: 0.4264 - val_accuracy: 0.8488\n",
      "Epoch 8/100\n",
      "17449/17449 [==============================] - 57s 3ms/step - loss: 0.4035 - accuracy: 0.8530 - val_loss: 0.4324 - val_accuracy: 0.8469\n",
      "Epoch 9/100\n",
      "17449/17449 [==============================] - 56s 3ms/step - loss: 0.4010 - accuracy: 0.8538 - val_loss: 0.4322 - val_accuracy: 0.8436\n",
      "Epoch 10/100\n",
      "17449/17449 [==============================] - 56s 3ms/step - loss: 0.3985 - accuracy: 0.8541 - val_loss: 0.4348 - val_accuracy: 0.8427\n",
      "Epoch 11/100\n",
      "17449/17449 [==============================] - 56s 3ms/step - loss: 0.3965 - accuracy: 0.8551 - val_loss: 0.4285 - val_accuracy: 0.8478\n",
      "Epoch 12/100\n",
      "17449/17449 [==============================] - 56s 3ms/step - loss: 0.3958 - accuracy: 0.8555 - val_loss: 0.4323 - val_accuracy: 0.8455\n",
      "Epoch 13/100\n",
      "17449/17449 [==============================] - 57s 3ms/step - loss: 0.3942 - accuracy: 0.8552 - val_loss: 0.4293 - val_accuracy: 0.8464\n",
      "Epoch 14/100\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.3931 - accuracy: 0.8557 - val_loss: 0.4246 - val_accuracy: 0.8488\n",
      "Epoch 15/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.3914 - accuracy: 0.8568 - val_loss: 0.4348 - val_accuracy: 0.8414\n",
      "Epoch 16/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.3910 - accuracy: 0.8562 - val_loss: 0.4316 - val_accuracy: 0.8466\n",
      "Epoch 17/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.3902 - accuracy: 0.8571 - val_loss: 0.4305 - val_accuracy: 0.8483\n",
      "Epoch 18/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.3884 - accuracy: 0.8576 - val_loss: 0.4257 - val_accuracy: 0.8481\n",
      "Epoch 19/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3881 - accuracy: 0.8571 - val_loss: 0.4245 - val_accuracy: 0.8490\n",
      "Epoch 20/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.3870 - accuracy: 0.8576 - val_loss: 0.4247 - val_accuracy: 0.8487\n",
      "Epoch 21/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.3866 - accuracy: 0.8574 - val_loss: 0.4307 - val_accuracy: 0.8481\n",
      "Epoch 22/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.3856 - accuracy: 0.8580 - val_loss: 0.4260 - val_accuracy: 0.8498\n",
      "Epoch 23/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3852 - accuracy: 0.8585 - val_loss: 0.4258 - val_accuracy: 0.8480\n",
      "Epoch 24/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3843 - accuracy: 0.8580 - val_loss: 0.4246 - val_accuracy: 0.8484\n",
      "Epoch 25/100\n",
      "17449/17449 [==============================] - 49s 3ms/step - loss: 0.3840 - accuracy: 0.8583 - val_loss: 0.4266 - val_accuracy: 0.8482\n",
      "Epoch 26/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3828 - accuracy: 0.8587 - val_loss: 0.4319 - val_accuracy: 0.8455\n",
      "Epoch 27/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3839 - accuracy: 0.8584 - val_loss: 0.4288 - val_accuracy: 0.8480\n",
      "Epoch 28/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3824 - accuracy: 0.8585 - val_loss: 0.4237 - val_accuracy: 0.8500\n",
      "Epoch 29/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.3816 - accuracy: 0.8591 - val_loss: 0.4288 - val_accuracy: 0.8487\n",
      "Epoch 30/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3806 - accuracy: 0.8593 - val_loss: 0.4274 - val_accuracy: 0.8477\n",
      "Epoch 31/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3816 - accuracy: 0.8595 - val_loss: 0.4276 - val_accuracy: 0.8485\n",
      "Epoch 32/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3813 - accuracy: 0.8591 - val_loss: 0.4267 - val_accuracy: 0.8495\n",
      "Epoch 33/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3798 - accuracy: 0.8592 - val_loss: 0.4238 - val_accuracy: 0.8493\n",
      "Epoch 34/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3799 - accuracy: 0.8597 - val_loss: 0.4226 - val_accuracy: 0.8515\n",
      "Epoch 35/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3802 - accuracy: 0.8591 - val_loss: 0.4338 - val_accuracy: 0.8471\n",
      "Epoch 36/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.3793 - accuracy: 0.8594 - val_loss: 0.4284 - val_accuracy: 0.8491\n",
      "Epoch 37/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3780 - accuracy: 0.8598 - val_loss: 0.4286 - val_accuracy: 0.8479\n",
      "Epoch 38/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3788 - accuracy: 0.8598 - val_loss: 0.4255 - val_accuracy: 0.8500\n",
      "Epoch 39/100\n",
      "17449/17449 [==============================] - 49s 3ms/step - loss: 0.3784 - accuracy: 0.8595 - val_loss: 0.4275 - val_accuracy: 0.8501\n",
      "Epoch 40/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3789 - accuracy: 0.8599 - val_loss: 0.4298 - val_accuracy: 0.8483\n",
      "Epoch 41/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.3779 - accuracy: 0.8601 - val_loss: 0.4249 - val_accuracy: 0.8504\n",
      "Epoch 42/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3778 - accuracy: 0.8596 - val_loss: 0.4253 - val_accuracy: 0.8492\n",
      "Epoch 43/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.3776 - accuracy: 0.8603 - val_loss: 0.4285 - val_accuracy: 0.8501\n",
      "Epoch 44/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.3775 - accuracy: 0.8599 - val_loss: 0.4285 - val_accuracy: 0.8472\n",
      "3636/3636 [==============================] - 6s 2ms/step - loss: 0.4168 - accuracy: 0.8515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41677936911582947, 0.851464033126831]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet_5_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_lenet5_emnist_model.h5\", save_best_only=True)\n",
    "\n",
    "lenet_5_model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y), callbacks=[early_stopping_cb])\n",
    "\n",
    "lenet_5_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet_5_SeLU\n",
    "\n",
    "SeLU performs better(speed & accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 6)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 1, 120)         48120     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                5270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,126\n",
      "Trainable params: 66,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "lenet_5_selu_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=train_x[0].shape, padding='same'),\n",
    "    keras.layers.AveragePooling2D(),\n",
    "    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.AveragePooling2D(),\n",
    "    keras.layers.Conv2D(120, kernel_size=5, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.Flatten(),   \n",
    "    keras.layers.Dense(84, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(62, activation='softmax')\n",
    "])\n",
    "\n",
    "lenet_5_selu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.5755 - accuracy: 0.8070 - val_loss: 0.4708 - val_accuracy: 0.8314\n",
      "Epoch 2/10\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.4502 - accuracy: 0.8397 - val_loss: 0.4465 - val_accuracy: 0.8389\n",
      "Epoch 3/10\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4300 - accuracy: 0.8452 - val_loss: 0.4342 - val_accuracy: 0.8444\n",
      "Epoch 4/10\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.4200 - accuracy: 0.8479 - val_loss: 0.4274 - val_accuracy: 0.8462\n",
      "Epoch 5/10\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.4120 - accuracy: 0.8502 - val_loss: 0.4326 - val_accuracy: 0.8424\n",
      "Epoch 6/10\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4065 - accuracy: 0.8521 - val_loss: 0.4373 - val_accuracy: 0.8455\n",
      "Epoch 7/10\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.4026 - accuracy: 0.8527 - val_loss: 0.4340 - val_accuracy: 0.8425\n",
      "Epoch 8/10\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3981 - accuracy: 0.8544 - val_loss: 0.4230 - val_accuracy: 0.8497\n",
      "Epoch 9/10\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3955 - accuracy: 0.8549 - val_loss: 0.4282 - val_accuracy: 0.8439\n",
      "Epoch 10/10\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.3925 - accuracy: 0.8556 - val_loss: 0.4387 - val_accuracy: 0.8460\n",
      "3636/3636 [==============================] - 6s 2ms/step - loss: 0.4333 - accuracy: 0.8460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4332740604877472, 0.8460480570793152]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet_5_selu_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_lenet5_emnist_model.h5\", save_best_only=True)\n",
    "\n",
    "lenet_5_selu_model.fit(train_x, train_y, epochs=10, validation_data=(val_x, val_y), callbacks=[early_stopping_cb])\n",
    "\n",
    "lenet_5_selu_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He Yanmei SeLU Lenet_5 model\n",
    "\n",
    "Lowers amount of parameters = lower inference time, less stable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "lenet_5_improved_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, kernel_size=5, strides=2, activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=train_x[0].shape, padding='same'),\n",
    "    keras.layers.Conv2D(64, kernel_size=3, strides=2, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.Conv2D(32, kernel_size=1, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(62, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17449/17449 [==============================] - 55s 3ms/step - loss: 1.0739 - accuracy: 0.6858 - val_loss: 0.7372 - val_accuracy: 0.7655\n",
      "Epoch 2/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.6588 - accuracy: 0.7867 - val_loss: 0.6335 - val_accuracy: 0.7957\n",
      "Epoch 3/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.5938 - accuracy: 0.8041 - val_loss: 0.5728 - val_accuracy: 0.8088\n",
      "Epoch 4/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.5607 - accuracy: 0.8134 - val_loss: 0.5567 - val_accuracy: 0.8149\n",
      "Epoch 5/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.5389 - accuracy: 0.8193 - val_loss: 0.5499 - val_accuracy: 0.8155\n",
      "Epoch 6/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.5246 - accuracy: 0.8234 - val_loss: 0.5298 - val_accuracy: 0.8224\n",
      "Epoch 7/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.5135 - accuracy: 0.8267 - val_loss: 0.5168 - val_accuracy: 0.8260\n",
      "Epoch 8/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.5048 - accuracy: 0.8290 - val_loss: 0.5093 - val_accuracy: 0.8291\n",
      "Epoch 9/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4981 - accuracy: 0.8309 - val_loss: 0.5095 - val_accuracy: 0.8290\n",
      "Epoch 10/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.4923 - accuracy: 0.8323 - val_loss: 0.5066 - val_accuracy: 0.8307\n",
      "Epoch 11/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4876 - accuracy: 0.8335 - val_loss: 0.5029 - val_accuracy: 0.8292\n",
      "Epoch 12/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4830 - accuracy: 0.8349 - val_loss: 0.5092 - val_accuracy: 0.8272\n",
      "Epoch 13/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4790 - accuracy: 0.8360 - val_loss: 0.4905 - val_accuracy: 0.8339\n",
      "Epoch 14/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4758 - accuracy: 0.8370 - val_loss: 0.4983 - val_accuracy: 0.8308\n",
      "Epoch 15/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4727 - accuracy: 0.8381 - val_loss: 0.5040 - val_accuracy: 0.8304\n",
      "Epoch 16/100\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.4700 - accuracy: 0.8386 - val_loss: 0.4886 - val_accuracy: 0.8356\n",
      "Epoch 17/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4677 - accuracy: 0.8392 - val_loss: 0.4893 - val_accuracy: 0.8347\n",
      "Epoch 18/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4658 - accuracy: 0.8397 - val_loss: 0.4894 - val_accuracy: 0.8304\n",
      "Epoch 19/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4632 - accuracy: 0.8404 - val_loss: 0.4803 - val_accuracy: 0.8367\n",
      "Epoch 20/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4614 - accuracy: 0.8411 - val_loss: 0.4807 - val_accuracy: 0.8369\n",
      "Epoch 21/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4598 - accuracy: 0.8416 - val_loss: 0.4797 - val_accuracy: 0.8372\n",
      "Epoch 22/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4585 - accuracy: 0.8417 - val_loss: 0.4880 - val_accuracy: 0.8337\n",
      "Epoch 23/100\n",
      "17449/17449 [==============================] - 47s 3ms/step - loss: 0.4567 - accuracy: 0.8420 - val_loss: 0.4766 - val_accuracy: 0.8368\n",
      "Epoch 24/100\n",
      "17449/17449 [==============================] - 47s 3ms/step - loss: 0.4551 - accuracy: 0.8425 - val_loss: 0.4772 - val_accuracy: 0.8354\n",
      "Epoch 25/100\n",
      "17449/17449 [==============================] - 47s 3ms/step - loss: 0.4539 - accuracy: 0.8432 - val_loss: 0.4856 - val_accuracy: 0.8352\n",
      "Epoch 26/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4527 - accuracy: 0.8434 - val_loss: 0.4713 - val_accuracy: 0.8392\n",
      "Epoch 27/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4514 - accuracy: 0.8438 - val_loss: 0.4830 - val_accuracy: 0.8347\n",
      "Epoch 28/100\n",
      "17449/17449 [==============================] - 47s 3ms/step - loss: 0.4501 - accuracy: 0.8441 - val_loss: 0.4767 - val_accuracy: 0.8375\n",
      "Epoch 29/100\n",
      "17449/17449 [==============================] - 49s 3ms/step - loss: 0.4493 - accuracy: 0.8445 - val_loss: 0.4756 - val_accuracy: 0.8359\n",
      "Epoch 30/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4480 - accuracy: 0.8446 - val_loss: 0.4884 - val_accuracy: 0.8342\n",
      "Epoch 31/100\n",
      "17449/17449 [==============================] - 49s 3ms/step - loss: 0.4470 - accuracy: 0.8447 - val_loss: 0.4782 - val_accuracy: 0.8378\n",
      "Epoch 32/100\n",
      "17449/17449 [==============================] - 47s 3ms/step - loss: 0.4462 - accuracy: 0.8449 - val_loss: 0.4705 - val_accuracy: 0.8383\n",
      "Epoch 33/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4448 - accuracy: 0.8456 - val_loss: 0.4744 - val_accuracy: 0.8382\n",
      "Epoch 34/100\n",
      "17449/17449 [==============================] - 49s 3ms/step - loss: 0.4444 - accuracy: 0.8453 - val_loss: 0.4661 - val_accuracy: 0.8411\n",
      "Epoch 35/100\n",
      "17449/17449 [==============================] - 47s 3ms/step - loss: 0.4434 - accuracy: 0.8463 - val_loss: 0.4712 - val_accuracy: 0.8378\n",
      "Epoch 36/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4427 - accuracy: 0.8461 - val_loss: 0.4721 - val_accuracy: 0.8385\n",
      "Epoch 37/100\n",
      "17449/17449 [==============================] - 47s 3ms/step - loss: 0.4418 - accuracy: 0.8463 - val_loss: 0.4643 - val_accuracy: 0.8410\n",
      "Epoch 38/100\n",
      "17449/17449 [==============================] - 49s 3ms/step - loss: 0.4413 - accuracy: 0.8463 - val_loss: 0.4671 - val_accuracy: 0.8405\n",
      "Epoch 39/100\n",
      "17449/17449 [==============================] - 47s 3ms/step - loss: 0.4405 - accuracy: 0.8466 - val_loss: 0.4677 - val_accuracy: 0.8398\n",
      "Epoch 40/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4398 - accuracy: 0.8468 - val_loss: 0.4689 - val_accuracy: 0.8398\n",
      "Epoch 41/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4394 - accuracy: 0.8468 - val_loss: 0.4789 - val_accuracy: 0.8382\n",
      "Epoch 42/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4390 - accuracy: 0.8468 - val_loss: 0.4703 - val_accuracy: 0.8398\n",
      "Epoch 43/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4378 - accuracy: 0.8474 - val_loss: 0.4687 - val_accuracy: 0.8399\n",
      "Epoch 44/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4377 - accuracy: 0.8473 - val_loss: 0.4727 - val_accuracy: 0.8372\n",
      "Epoch 45/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4370 - accuracy: 0.8476 - val_loss: 0.4824 - val_accuracy: 0.8347\n",
      "Epoch 46/100\n",
      "17449/17449 [==============================] - 47s 3ms/step - loss: 0.4364 - accuracy: 0.8477 - val_loss: 0.4638 - val_accuracy: 0.8404\n",
      "Epoch 47/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4359 - accuracy: 0.8479 - val_loss: 0.4764 - val_accuracy: 0.8373\n",
      "Epoch 48/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4353 - accuracy: 0.8477 - val_loss: 0.4670 - val_accuracy: 0.8400\n",
      "Epoch 49/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4347 - accuracy: 0.8479 - val_loss: 0.4697 - val_accuracy: 0.8392\n",
      "Epoch 50/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4343 - accuracy: 0.8485 - val_loss: 0.4680 - val_accuracy: 0.8410\n",
      "Epoch 51/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4337 - accuracy: 0.8483 - val_loss: 0.4633 - val_accuracy: 0.8418\n",
      "Epoch 52/100\n",
      "17449/17449 [==============================] - 49s 3ms/step - loss: 0.4332 - accuracy: 0.8486 - val_loss: 0.4631 - val_accuracy: 0.8429\n",
      "Epoch 53/100\n",
      "17449/17449 [==============================] - 47s 3ms/step - loss: 0.4329 - accuracy: 0.8482 - val_loss: 0.4667 - val_accuracy: 0.8400\n",
      "Epoch 54/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4325 - accuracy: 0.8489 - val_loss: 0.4691 - val_accuracy: 0.8383\n",
      "Epoch 55/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4320 - accuracy: 0.8488 - val_loss: 0.4695 - val_accuracy: 0.8386\n",
      "Epoch 56/100\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.4313 - accuracy: 0.8489 - val_loss: 0.4691 - val_accuracy: 0.8397\n",
      "Epoch 57/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.4314 - accuracy: 0.8493 - val_loss: 0.4648 - val_accuracy: 0.8432\n",
      "Epoch 58/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4310 - accuracy: 0.8491 - val_loss: 0.4585 - val_accuracy: 0.8434\n",
      "Epoch 59/100\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4306 - accuracy: 0.8493 - val_loss: 0.4665 - val_accuracy: 0.8397\n",
      "Epoch 60/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.4304 - accuracy: 0.8493 - val_loss: 0.4593 - val_accuracy: 0.8420\n",
      "Epoch 61/100\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.4297 - accuracy: 0.8496 - val_loss: 0.4596 - val_accuracy: 0.8435\n",
      "Epoch 62/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4293 - accuracy: 0.8497 - val_loss: 0.4651 - val_accuracy: 0.8413\n",
      "Epoch 63/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4291 - accuracy: 0.8497 - val_loss: 0.4703 - val_accuracy: 0.8384\n",
      "Epoch 64/100\n",
      "17449/17449 [==============================] - 47s 3ms/step - loss: 0.4287 - accuracy: 0.8494 - val_loss: 0.4669 - val_accuracy: 0.8403\n",
      "Epoch 65/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4283 - accuracy: 0.8497 - val_loss: 0.4624 - val_accuracy: 0.8430\n",
      "Epoch 66/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4279 - accuracy: 0.8498 - val_loss: 0.4716 - val_accuracy: 0.8387\n",
      "Epoch 67/100\n",
      "17449/17449 [==============================] - 48s 3ms/step - loss: 0.4276 - accuracy: 0.8500 - val_loss: 0.4632 - val_accuracy: 0.8410\n",
      "Epoch 68/100\n",
      "17449/17449 [==============================] - 47s 3ms/step - loss: 0.4273 - accuracy: 0.8502 - val_loss: 0.4655 - val_accuracy: 0.8391\n",
      "3636/3636 [==============================] - 5s 1ms/step - loss: 0.4552 - accuracy: 0.8441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.455183744430542, 0.8441395163536072]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet_5_improved_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_lenet5_emnist_model.h5\", save_best_only=True)\n",
    "\n",
    "lenet_5_improved_model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y), callbacks=[early_stopping_cb])\n",
    "\n",
    "lenet_5_improved_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build #20220515\n",
    "\n",
    "87.09% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "my_lenet_5_selu_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, kernel_size=5, strides=1,  activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=train_x[0].shape, padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, kernel_size=5, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(32, kernel_size=3, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(62, activation='softmax')\n",
    "])\n",
    "\n",
    "my_lenet_5_selu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lenet_5_selu_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_lenet5_emnist_model.h5\", save_best_only=True)\n",
    "  \n",
    "my_lenet_5_selu_model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y), callbacks=[early_stopping_cb, model_checkpoint_cb])\n",
    "\n",
    "my_lenet_5_selu_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.time()\n",
    "now = time.localtime(now)\n",
    "my_lenet_5_selu_model.save(\"my_lenet5_emnist_model_%2d%02d%02d.h5\" %(now.tm_year, now.tm_mon, now.tm_mday), save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build #20220517\n",
    "\n",
    "testing wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "lenet_5_selu_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=train_x[0].shape, padding='same'),\n",
    "    keras.layers.AveragePooling2D(),\n",
    "    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.AveragePooling2D(),\n",
    "    keras.layers.Conv2D(120, kernel_size=5, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.Flatten(),   \n",
    "    keras.layers.Dense(84, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(62, activation='softmax')\n",
    "])\n",
    "\n",
    "lenet_5_selu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet_5_selu_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "lenet_5_selu_model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y), callbacks=[early_stopping_cb, WandbCallback()])\n",
    "\n",
    "lenet_5_selu_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_train(config_defaults=None):\n",
    "    \n",
    "    # Set default values\n",
    "    config_defaults = {\n",
    "      'n_first_node' : 32,\n",
    "      'n_second_node' : 128,\n",
    "      'n_third_node' : 64,\n",
    "      'n_dense_size' : 128\n",
    "    }\n",
    "    # Initialize wandb with a sample project name\n",
    "    wandb.init(config=config_defaults)  # this gets over-written in the Sweep\n",
    "\n",
    "    # initialize model\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(wandb.config.n_first_node, kernel_size=5, strides=1,  activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=train_x[0].shape, padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Conv2D(wandb.config.n_second_node, kernel_size=5, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Conv2D(wandb.config.n_third_node, kernel_size=3, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.GlobalAveragePooling2D())\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(62, activation='softmax'))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    # Instantiate an optimizer to train the model.\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=3e-4, beta_1=0.9, beta_2=0.999)\n",
    "    # Instantiate a loss function.\n",
    "    # loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])\n",
    "    hist = model.fit(val_x, val_y, epochs=10, validation_data=(test_x, test_y), callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: fd73n8t8\n",
      "Sweep URL: https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z6mv1ujh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_021635-z6mv1ujh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/z6mv1ujh\" target=\"_blank\">smooth-sweep-1</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        1664      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 256)       409856    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 128)       295040    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                7998      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 716,350\n",
      "Trainable params: 715,454\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 47s 10ms/step - loss: 0.8096 - accuracy: 0.7640 - val_loss: 0.5741 - val_accuracy: 0.8100 - _timestamp: 1654967853.0000 - _runtime: 58.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 43s 10ms/step - loss: 0.4930 - accuracy: 0.8310 - val_loss: 0.5202 - val_accuracy: 0.8251 - _timestamp: 1654967897.0000 - _runtime: 102.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 43s 10ms/step - loss: 0.4530 - accuracy: 0.8428 - val_loss: 0.4472 - val_accuracy: 0.8440 - _timestamp: 1654967940.0000 - _runtime: 145.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 43s 10ms/step - loss: 0.4315 - accuracy: 0.8484 - val_loss: 0.4481 - val_accuracy: 0.8441 - _timestamp: 1654967983.0000 - _runtime: 188.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 43s 10ms/step - loss: 0.4147 - accuracy: 0.8525 - val_loss: 0.5123 - val_accuracy: 0.8286 - _timestamp: 1654968027.0000 - _runtime: 232.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 43s 10ms/step - loss: 0.4040 - accuracy: 0.8554 - val_loss: 0.4333 - val_accuracy: 0.8449 - _timestamp: 1654968070.0000 - _runtime: 275.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 43s 10ms/step - loss: 0.3931 - accuracy: 0.8579 - val_loss: 0.4013 - val_accuracy: 0.8554 - _timestamp: 1654968113.0000 - _runtime: 318.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 39s 9ms/step - loss: 0.3840 - accuracy: 0.8606 - val_loss: 0.4063 - val_accuracy: 0.8528 - _timestamp: 1654968152.0000 - _runtime: 357.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 39s 9ms/step - loss: 0.3778 - accuracy: 0.8620 - val_loss: 0.4026 - val_accuracy: 0.8568 - _timestamp: 1654968192.0000 - _runtime: 397.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 40s 9ms/step - loss: 0.3709 - accuracy: 0.8637 - val_loss: 0.3938 - val_accuracy: 0.8591 - _timestamp: 1654968231.0000 - _runtime: 436.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6684a8e1764ab68d8d1200e2d463b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='8.260 MB of 8.260 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▆▆▄▆▇▇██</td></tr><tr><td>val_loss</td><td>█▆▃▃▆▃▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86371</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.39382</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.37094</td></tr><tr><td>val_accuracy</td><td>0.85912</td></tr><tr><td>val_loss</td><td>0.39382</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">smooth-sweep-1</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/z6mv1ujh\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/z6mv1ujh</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_021635-z6mv1ujh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bhyqw9e2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_022401-bhyqw9e2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/bhyqw9e2\" target=\"_blank\">efficient-sweep-2</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        1664      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 256)       409856    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 128)       295040    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                7998      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 716,350\n",
      "Trainable params: 715,454\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 40s 9ms/step - loss: 0.8132 - accuracy: 0.7632 - val_loss: 0.6882 - val_accuracy: 0.7769 - _timestamp: 1654968292.0000 - _runtime: 51.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 39s 9ms/step - loss: 0.4960 - accuracy: 0.8314 - val_loss: 0.4905 - val_accuracy: 0.8306 - _timestamp: 1654968331.0000 - _runtime: 90.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 40s 9ms/step - loss: 0.4545 - accuracy: 0.8419 - val_loss: 0.5397 - val_accuracy: 0.8225 - _timestamp: 1654968371.0000 - _runtime: 130.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 40s 9ms/step - loss: 0.4305 - accuracy: 0.8488 - val_loss: 0.4351 - val_accuracy: 0.8494 - _timestamp: 1654968411.0000 - _runtime: 170.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 40s 9ms/step - loss: 0.4156 - accuracy: 0.8528 - val_loss: 0.4115 - val_accuracy: 0.8529 - _timestamp: 1654968450.0000 - _runtime: 209.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 40s 9ms/step - loss: 0.4056 - accuracy: 0.8551 - val_loss: 0.4114 - val_accuracy: 0.8543 - _timestamp: 1654968490.0000 - _runtime: 249.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 39s 9ms/step - loss: 0.3940 - accuracy: 0.8586 - val_loss: 0.4286 - val_accuracy: 0.8478 - _timestamp: 1654968529.0000 - _runtime: 288.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 39s 9ms/step - loss: 0.3849 - accuracy: 0.8599 - val_loss: 0.3910 - val_accuracy: 0.8600 - _timestamp: 1654968569.0000 - _runtime: 328.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 39s 9ms/step - loss: 0.3777 - accuracy: 0.8619 - val_loss: 0.4243 - val_accuracy: 0.8492 - _timestamp: 1654968608.0000 - _runtime: 367.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 40s 9ms/step - loss: 0.3713 - accuracy: 0.8639 - val_loss: 0.3961 - val_accuracy: 0.8583 - _timestamp: 1654968647.0000 - _runtime: 406.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d3f39ff6fd48209d45b1b7f0ac1f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='8.260 MB of 8.260 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▆▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▆▅▇▇█▇█▇█</td></tr><tr><td>val_loss</td><td>█▃▅▂▁▁▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86387</td></tr><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_loss</td><td>0.391</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.3713</td></tr><tr><td>val_accuracy</td><td>0.85834</td></tr><tr><td>val_loss</td><td>0.39609</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">efficient-sweep-2</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/bhyqw9e2\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/bhyqw9e2</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_022401-bhyqw9e2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hbspdga4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_023056-hbspdga4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/hbspdga4\" target=\"_blank\">leafy-sweep-3</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        1664      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 256)       409856    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 64)        147520    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 64)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                4030      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 564,606\n",
      "Trainable params: 563,838\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 36s 8ms/step - loss: 0.8969 - accuracy: 0.7478 - val_loss: 0.7521 - val_accuracy: 0.7628 - _timestamp: 1654968704.0000 - _runtime: 48.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.5209 - accuracy: 0.8251 - val_loss: 0.5855 - val_accuracy: 0.8054 - _timestamp: 1654968739.0000 - _runtime: 83.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.4776 - accuracy: 0.8358 - val_loss: 0.4787 - val_accuracy: 0.8326 - _timestamp: 1654968774.0000 - _runtime: 118.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.4533 - accuracy: 0.8426 - val_loss: 0.4579 - val_accuracy: 0.8404 - _timestamp: 1654968809.0000 - _runtime: 153.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.4365 - accuracy: 0.8477 - val_loss: 0.4610 - val_accuracy: 0.8389 - _timestamp: 1654968845.0000 - _runtime: 189.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.4226 - accuracy: 0.8506 - val_loss: 0.4851 - val_accuracy: 0.8334 - _timestamp: 1654968880.0000 - _runtime: 224.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.4150 - accuracy: 0.8522 - val_loss: 0.4679 - val_accuracy: 0.8376 - _timestamp: 1654968915.0000 - _runtime: 259.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.4064 - accuracy: 0.8549 - val_loss: 0.4552 - val_accuracy: 0.8422 - _timestamp: 1654968951.0000 - _runtime: 295.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.3993 - accuracy: 0.8560 - val_loss: 0.4181 - val_accuracy: 0.8511 - _timestamp: 1654968986.0000 - _runtime: 330.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 39s 9ms/step - loss: 0.3925 - accuracy: 0.8586 - val_loss: 0.4318 - val_accuracy: 0.8480 - _timestamp: 1654969025.0000 - _runtime: 369.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81908c5431f14c1ca6b13f06895e9841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='6.524 MB of 6.524 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▇▇▇▇▇▇██</td></tr><tr><td>val_loss</td><td>█▅▂▂▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.85864</td></tr><tr><td>best_epoch</td><td>8</td></tr><tr><td>best_val_loss</td><td>0.41813</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.39247</td></tr><tr><td>val_accuracy</td><td>0.84803</td></tr><tr><td>val_loss</td><td>0.43184</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">leafy-sweep-3</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/hbspdga4\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/hbspdga4</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_023056-hbspdga4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: czguadg8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_023713-czguadg8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/czguadg8\" target=\"_blank\">flowing-sweep-4</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 256)       205056    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 256)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                15934     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814,078\n",
      "Trainable params: 812,990\n",
      "Non-trainable params: 1,088\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 51s 12ms/step - loss: 0.7636 - accuracy: 0.7729 - val_loss: 0.5021 - val_accuracy: 0.8249 - _timestamp: 1654969096.0000 - _runtime: 62.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 50s 12ms/step - loss: 0.4791 - accuracy: 0.8353 - val_loss: 0.4720 - val_accuracy: 0.8362 - _timestamp: 1654969147.0000 - _runtime: 113.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 51s 12ms/step - loss: 0.4408 - accuracy: 0.8454 - val_loss: 0.4681 - val_accuracy: 0.8352 - _timestamp: 1654969198.0000 - _runtime: 164.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 51s 12ms/step - loss: 0.4169 - accuracy: 0.8516 - val_loss: 0.4182 - val_accuracy: 0.8523 - _timestamp: 1654969249.0000 - _runtime: 215.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 51s 12ms/step - loss: 0.4021 - accuracy: 0.8552 - val_loss: 0.4279 - val_accuracy: 0.8490 - _timestamp: 1654969299.0000 - _runtime: 265.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 47s 11ms/step - loss: 0.3896 - accuracy: 0.8586 - val_loss: 0.4267 - val_accuracy: 0.8490 - _timestamp: 1654969346.0000 - _runtime: 312.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 46s 10ms/step - loss: 0.3790 - accuracy: 0.8618 - val_loss: 0.4123 - val_accuracy: 0.8523 - _timestamp: 1654969392.0000 - _runtime: 358.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 46s 11ms/step - loss: 0.3716 - accuracy: 0.8632 - val_loss: 0.3959 - val_accuracy: 0.8560 - _timestamp: 1654969438.0000 - _runtime: 404.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 46s 11ms/step - loss: 0.3624 - accuracy: 0.8652 - val_loss: 0.3885 - val_accuracy: 0.8578 - _timestamp: 1654969484.0000 - _runtime: 450.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 46s 11ms/step - loss: 0.3556 - accuracy: 0.8681 - val_loss: 0.4071 - val_accuracy: 0.8548 - _timestamp: 1654969530.0000 - _runtime: 496.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143d0a3f02284a9db2061adc81ef05b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='9.377 MB of 9.377 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▆▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▃▇▆▆▇██▇</td></tr><tr><td>val_loss</td><td>█▆▆▃▃▃▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86815</td></tr><tr><td>best_epoch</td><td>8</td></tr><tr><td>best_val_loss</td><td>0.38848</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.35558</td></tr><tr><td>val_accuracy</td><td>0.85476</td></tr><tr><td>val_loss</td><td>0.40711</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">flowing-sweep-4</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/czguadg8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/czguadg8</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_023713-czguadg8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hg48r0s0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_024541-hg48r0s0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/hg48r0s0\" target=\"_blank\">swift-sweep-5</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        1664      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                7998      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 363,454\n",
      "Trainable params: 362,814\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 31s 7ms/step - loss: 0.8410 - accuracy: 0.7559 - val_loss: 0.5686 - val_accuracy: 0.8121 - _timestamp: 1654969582.0000 - _runtime: 41.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.5118 - accuracy: 0.8270 - val_loss: 0.5091 - val_accuracy: 0.8277 - _timestamp: 1654969612.0000 - _runtime: 71.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4682 - accuracy: 0.8390 - val_loss: 0.5041 - val_accuracy: 0.8252 - _timestamp: 1654969643.0000 - _runtime: 102.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4429 - accuracy: 0.8454 - val_loss: 0.4406 - val_accuracy: 0.8459 - _timestamp: 1654969672.0000 - _runtime: 131.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4273 - accuracy: 0.8495 - val_loss: 0.4229 - val_accuracy: 0.8509 - _timestamp: 1654969702.0000 - _runtime: 161.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4150 - accuracy: 0.8530 - val_loss: 0.4279 - val_accuracy: 0.8476 - _timestamp: 1654969732.0000 - _runtime: 191.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4049 - accuracy: 0.8544 - val_loss: 0.4134 - val_accuracy: 0.8499 - _timestamp: 1654969762.0000 - _runtime: 221.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.3949 - accuracy: 0.8583 - val_loss: 0.4322 - val_accuracy: 0.8494 - _timestamp: 1654969792.0000 - _runtime: 251.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.3902 - accuracy: 0.8586 - val_loss: 0.4030 - val_accuracy: 0.8574 - _timestamp: 1654969822.0000 - _runtime: 281.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.3838 - accuracy: 0.8607 - val_loss: 0.3994 - val_accuracy: 0.8592 - _timestamp: 1654969851.0000 - _runtime: 310.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8491fe5a82a240849631fecc155a2750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.223 MB of 4.223 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▃▆▇▆▇▇██</td></tr><tr><td>val_loss</td><td>█▆▅▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86065</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.39945</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.38379</td></tr><tr><td>val_accuracy</td><td>0.85922</td></tr><tr><td>val_loss</td><td>0.39945</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">swift-sweep-5</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/hg48r0s0\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/hg48r0s0</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_024541-hg48r0s0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5h7dtti8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_025101-5h7dtti8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/5h7dtti8\" target=\"_blank\">expert-sweep-6</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 128)       3328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 128)      512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 256)       819456    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 128)       295040    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                7998      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,127,870\n",
      "Trainable params: 1,126,846\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "   1/4363 [..............................] - ETA: 1:01:55 - loss: 4.0748 - accuracy: 0.0312WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0042s vs `on_train_batch_end` time: 0.0045s). Check your callbacks.\n",
      "4363/4363 [==============================] - 47s 11ms/step - loss: 0.8037 - accuracy: 0.7647 - val_loss: 0.5847 - val_accuracy: 0.8115 - _timestamp: 1654969919.0000 - _runtime: 58.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 46s 11ms/step - loss: 0.4947 - accuracy: 0.8326 - val_loss: 0.4829 - val_accuracy: 0.8325 - _timestamp: 1654969965.0000 - _runtime: 104.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 46s 11ms/step - loss: 0.4531 - accuracy: 0.8424 - val_loss: 0.4452 - val_accuracy: 0.8455 - _timestamp: 1654970011.0000 - _runtime: 150.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 46s 10ms/step - loss: 0.4290 - accuracy: 0.8493 - val_loss: 0.4324 - val_accuracy: 0.8477 - _timestamp: 1654970057.0000 - _runtime: 196.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 46s 10ms/step - loss: 0.4146 - accuracy: 0.8513 - val_loss: 0.4243 - val_accuracy: 0.8520 - _timestamp: 1654970103.0000 - _runtime: 242.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 46s 11ms/step - loss: 0.4025 - accuracy: 0.8551 - val_loss: 0.4532 - val_accuracy: 0.8425 - _timestamp: 1654970149.0000 - _runtime: 288.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 46s 11ms/step - loss: 0.3921 - accuracy: 0.8579 - val_loss: 0.4278 - val_accuracy: 0.8477 - _timestamp: 1654970195.0000 - _runtime: 334.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 46s 11ms/step - loss: 0.3846 - accuracy: 0.8605 - val_loss: 0.4007 - val_accuracy: 0.8556 - _timestamp: 1654970240.0000 - _runtime: 379.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 46s 10ms/step - loss: 0.3764 - accuracy: 0.8624 - val_loss: 0.4027 - val_accuracy: 0.8544 - _timestamp: 1654970286.0000 - _runtime: 425.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 46s 10ms/step - loss: 0.3697 - accuracy: 0.8639 - val_loss: 0.3947 - val_accuracy: 0.8600 - _timestamp: 1654970332.0000 - _runtime: 471.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d32ab385eb45ecacd2316ea8eedc3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='12.969 MB of 12.969 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▆▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▆▇▅▆▇▇█</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86388</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.39469</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.36975</td></tr><tr><td>val_accuracy</td><td>0.86004</td></tr><tr><td>val_loss</td><td>0.39469</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">expert-sweep-6</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/5h7dtti8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/5h7dtti8</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_025101-5h7dtti8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: alniounc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_025903-alniounc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/alniounc\" target=\"_blank\">helpful-sweep-7</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        1664      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                7998      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 363,454\n",
      "Trainable params: 362,814\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.8386 - accuracy: 0.7559 - val_loss: 0.5647 - val_accuracy: 0.8116 - _timestamp: 1654970384.0000 - _runtime: 41.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.5068 - accuracy: 0.8289 - val_loss: 0.5157 - val_accuracy: 0.8268 - _timestamp: 1654970414.0000 - _runtime: 71.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4626 - accuracy: 0.8404 - val_loss: 0.4830 - val_accuracy: 0.8361 - _timestamp: 1654970444.0000 - _runtime: 101.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4392 - accuracy: 0.8463 - val_loss: 0.4466 - val_accuracy: 0.8445 - _timestamp: 1654970474.0000 - _runtime: 131.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4228 - accuracy: 0.8501 - val_loss: 0.4615 - val_accuracy: 0.8435 - _timestamp: 1654970504.0000 - _runtime: 161.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4115 - accuracy: 0.8541 - val_loss: 0.4206 - val_accuracy: 0.8505 - _timestamp: 1654970533.0000 - _runtime: 190.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4016 - accuracy: 0.8571 - val_loss: 0.4225 - val_accuracy: 0.8490 - _timestamp: 1654970563.0000 - _runtime: 220.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.3936 - accuracy: 0.8576 - val_loss: 0.4094 - val_accuracy: 0.8549 - _timestamp: 1654970593.0000 - _runtime: 250.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.3862 - accuracy: 0.8602 - val_loss: 0.4214 - val_accuracy: 0.8535 - _timestamp: 1654970622.0000 - _runtime: 279.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.3804 - accuracy: 0.8626 - val_loss: 0.4037 - val_accuracy: 0.8547 - _timestamp: 1654970652.0000 - _runtime: 309.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb4ced89e0f4cd6b2016ed8c065c1c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.223 MB of 4.223 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▆▆▇▇███</td></tr><tr><td>val_loss</td><td>█▆▄▃▄▂▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86258</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.40371</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.38036</td></tr><tr><td>val_accuracy</td><td>0.8547</td></tr><tr><td>val_loss</td><td>0.40371</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">helpful-sweep-7</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/alniounc\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/alniounc</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_025903-alniounc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vd8vhme0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_030423-vd8vhme0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/vd8vhme0\" target=\"_blank\">genial-sweep-8</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 128)       3328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 128)      512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 256)       819456    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 128)       295040    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                7998      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,127,870\n",
      "Trainable params: 1,126,846\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 46s 11ms/step - loss: 0.8054 - accuracy: 0.7645 - val_loss: 0.5431 - val_accuracy: 0.8154 - _timestamp: 1654970721.0000 - _runtime: 57.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 46s 10ms/step - loss: 0.4970 - accuracy: 0.8317 - val_loss: 0.5279 - val_accuracy: 0.8191 - _timestamp: 1654970766.0000 - _runtime: 102.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 46s 10ms/step - loss: 0.4553 - accuracy: 0.8421 - val_loss: 0.4880 - val_accuracy: 0.8335 - _timestamp: 1654970812.0000 - _runtime: 148.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 46s 10ms/step - loss: 0.4325 - accuracy: 0.8480 - val_loss: 0.4668 - val_accuracy: 0.8389 - _timestamp: 1654970857.0000 - _runtime: 193.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 46s 10ms/step - loss: 0.4150 - accuracy: 0.8526 - val_loss: 0.4242 - val_accuracy: 0.8515 - _timestamp: 1654970903.0000 - _runtime: 239.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 45s 10ms/step - loss: 0.4039 - accuracy: 0.8556 - val_loss: 0.4276 - val_accuracy: 0.8506 - _timestamp: 1654970948.0000 - _runtime: 284.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 46s 10ms/step - loss: 0.3940 - accuracy: 0.8583 - val_loss: 0.4125 - val_accuracy: 0.8539 - _timestamp: 1654970994.0000 - _runtime: 330.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 46s 10ms/step - loss: 0.3851 - accuracy: 0.8606 - val_loss: 0.4005 - val_accuracy: 0.8569 - _timestamp: 1654971039.0000 - _runtime: 375.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 46s 10ms/step - loss: 0.3779 - accuracy: 0.8619 - val_loss: 0.4058 - val_accuracy: 0.8558 - _timestamp: 1654971085.0000 - _runtime: 421.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 46s 10ms/step - loss: 0.3708 - accuracy: 0.8643 - val_loss: 0.4106 - val_accuracy: 0.8524 - _timestamp: 1654971131.0000 - _runtime: 467.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d1f707e1ba4bb9aed60bcb4051651e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='12.969 MB of 12.969 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▆▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▄▅▇▇▇██▇</td></tr><tr><td>val_loss</td><td>█▇▅▄▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86433</td></tr><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_loss</td><td>0.40049</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.37077</td></tr><tr><td>val_accuracy</td><td>0.85237</td></tr><tr><td>val_loss</td><td>0.41057</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">genial-sweep-8</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/vd8vhme0\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/vd8vhme0</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_030423-vd8vhme0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gtj7gth2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_031220-gtj7gth2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/gtj7gth2\" target=\"_blank\">summer-sweep-9</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        1664      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 256)       409856    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 256)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                15934     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,019,838\n",
      "Trainable params: 1,018,686\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 50s 11ms/step - loss: 0.7514 - accuracy: 0.7749 - val_loss: 0.6876 - val_accuracy: 0.7751 - _timestamp: 1654971201.0000 - _runtime: 61.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 49s 11ms/step - loss: 0.4757 - accuracy: 0.8368 - val_loss: 0.4573 - val_accuracy: 0.8415 - _timestamp: 1654971249.0000 - _runtime: 109.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 49s 11ms/step - loss: 0.4388 - accuracy: 0.8458 - val_loss: 0.4874 - val_accuracy: 0.8346 - _timestamp: 1654971298.0000 - _runtime: 158.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 49s 11ms/step - loss: 0.4162 - accuracy: 0.8518 - val_loss: 0.4237 - val_accuracy: 0.8461 - _timestamp: 1654971347.0000 - _runtime: 207.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 50s 11ms/step - loss: 0.4011 - accuracy: 0.8560 - val_loss: 0.4070 - val_accuracy: 0.8528 - _timestamp: 1654971397.0000 - _runtime: 257.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 49s 11ms/step - loss: 0.3889 - accuracy: 0.8599 - val_loss: 0.4010 - val_accuracy: 0.8558 - _timestamp: 1654971445.0000 - _runtime: 305.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 49s 11ms/step - loss: 0.3781 - accuracy: 0.8615 - val_loss: 0.3951 - val_accuracy: 0.8585 - _timestamp: 1654971494.0000 - _runtime: 354.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 49s 11ms/step - loss: 0.3690 - accuracy: 0.8649 - val_loss: 0.4032 - val_accuracy: 0.8534 - _timestamp: 1654971543.0000 - _runtime: 403.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 49s 11ms/step - loss: 0.3618 - accuracy: 0.8663 - val_loss: 0.4011 - val_accuracy: 0.8588 - _timestamp: 1654971592.0000 - _runtime: 452.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 49s 11ms/step - loss: 0.3526 - accuracy: 0.8687 - val_loss: 0.3998 - val_accuracy: 0.8557 - _timestamp: 1654971640.0000 - _runtime: 500.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d43630f05b4f75ac71e7c40de27688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='11.731 MB of 11.731 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▆▇▇▇▇███</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▃▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▇▆▇▇█████</td></tr><tr><td>val_loss</td><td>█▂▃▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86873</td></tr><tr><td>best_epoch</td><td>6</td></tr><tr><td>best_val_loss</td><td>0.39506</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.35262</td></tr><tr><td>val_accuracy</td><td>0.85568</td></tr><tr><td>val_loss</td><td>0.39981</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">summer-sweep-9</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/gtj7gth2\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/gtj7gth2</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_031220-gtj7gth2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qnjroyky with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_032057-qnjroyky</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/qnjroyky\" target=\"_blank\">lunar-sweep-10</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 128)       102528    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 256)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                15934     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 416,126\n",
      "Trainable params: 415,294\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.7789 - accuracy: 0.7660 - val_loss: 0.5564 - val_accuracy: 0.8155 - _timestamp: 1654971706.0000 - _runtime: 49.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 36s 8ms/step - loss: 0.4901 - accuracy: 0.8328 - val_loss: 0.4737 - val_accuracy: 0.8390 - _timestamp: 1654971741.0000 - _runtime: 84.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.4511 - accuracy: 0.8429 - val_loss: 0.4914 - val_accuracy: 0.8310 - _timestamp: 1654971777.0000 - _runtime: 120.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.4266 - accuracy: 0.8492 - val_loss: 0.4352 - val_accuracy: 0.8457 - _timestamp: 1654971812.0000 - _runtime: 155.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.4116 - accuracy: 0.8530 - val_loss: 0.4234 - val_accuracy: 0.8495 - _timestamp: 1654971847.0000 - _runtime: 190.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 36s 8ms/step - loss: 0.4002 - accuracy: 0.8568 - val_loss: 0.4146 - val_accuracy: 0.8508 - _timestamp: 1654971883.0000 - _runtime: 226.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.3896 - accuracy: 0.8594 - val_loss: 0.4430 - val_accuracy: 0.8469 - _timestamp: 1654971918.0000 - _runtime: 261.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.3816 - accuracy: 0.8608 - val_loss: 0.4009 - val_accuracy: 0.8555 - _timestamp: 1654971954.0000 - _runtime: 297.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.3736 - accuracy: 0.8630 - val_loss: 0.3968 - val_accuracy: 0.8586 - _timestamp: 1654971989.0000 - _runtime: 332.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.3684 - accuracy: 0.8647 - val_loss: 0.4344 - val_accuracy: 0.8454 - _timestamp: 1654972025.0000 - _runtime: 368.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f9736962ba4415a98059915c816977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.825 MB of 4.825 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▆▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▄▆▇▇▆▇█▆</td></tr><tr><td>val_loss</td><td>█▄▅▃▂▂▃▁▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86468</td></tr><tr><td>best_epoch</td><td>8</td></tr><tr><td>best_val_loss</td><td>0.39675</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.36844</td></tr><tr><td>val_accuracy</td><td>0.84541</td></tr><tr><td>val_loss</td><td>0.43435</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lunar-sweep-10</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/qnjroyky\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/qnjroyky</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_032057-qnjroyky\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7f6wen20 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_032721-7f6wen20</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/7f6wen20\" target=\"_blank\">electric-sweep-11</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 128)       3328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 128)      512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 128)       409728    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                7998      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 570,174\n",
      "Trainable params: 569,406\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.8233 - accuracy: 0.7589 - val_loss: 0.6121 - val_accuracy: 0.8010 - _timestamp: 1654972087.0000 - _runtime: 46.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 34s 8ms/step - loss: 0.5085 - accuracy: 0.8274 - val_loss: 0.4719 - val_accuracy: 0.8367 - _timestamp: 1654972122.0000 - _runtime: 81.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 34s 8ms/step - loss: 0.4646 - accuracy: 0.8391 - val_loss: 0.4513 - val_accuracy: 0.8442 - _timestamp: 1654972156.0000 - _runtime: 115.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 34s 8ms/step - loss: 0.4395 - accuracy: 0.8460 - val_loss: 0.4907 - val_accuracy: 0.8326 - _timestamp: 1654972190.0000 - _runtime: 149.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 34s 8ms/step - loss: 0.4244 - accuracy: 0.8501 - val_loss: 0.4155 - val_accuracy: 0.8544 - _timestamp: 1654972225.0000 - _runtime: 184.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.4125 - accuracy: 0.8523 - val_loss: 0.4280 - val_accuracy: 0.8479 - _timestamp: 1654972259.0000 - _runtime: 218.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 34s 8ms/step - loss: 0.4026 - accuracy: 0.8557 - val_loss: 0.4155 - val_accuracy: 0.8535 - _timestamp: 1654972294.0000 - _runtime: 253.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 34s 8ms/step - loss: 0.3945 - accuracy: 0.8575 - val_loss: 0.4233 - val_accuracy: 0.8489 - _timestamp: 1654972328.0000 - _runtime: 287.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 34s 8ms/step - loss: 0.3898 - accuracy: 0.8583 - val_loss: 0.4115 - val_accuracy: 0.8555 - _timestamp: 1654972362.0000 - _runtime: 321.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.3815 - accuracy: 0.8608 - val_loss: 0.4005 - val_accuracy: 0.8581 - _timestamp: 1654972397.0000 - _runtime: 356.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06e661fe5f14617b152f58f11f263b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='6.588 MB of 6.588 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▅█▇▇▇██</td></tr><tr><td>val_loss</td><td>█▃▃▄▁▂▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86076</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.40054</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.38145</td></tr><tr><td>val_accuracy</td><td>0.85812</td></tr><tr><td>val_loss</td><td>0.40054</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">electric-sweep-11</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/7f6wen20\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/7f6wen20</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_032721-7f6wen20\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ats67lbi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_033327-ats67lbi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/ats67lbi\" target=\"_blank\">electric-sweep-12</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        1664      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                7998      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 363,454\n",
      "Trainable params: 362,814\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.8419 - accuracy: 0.7554 - val_loss: 0.6716 - val_accuracy: 0.7816 - _timestamp: 1654972449.0000 - _runtime: 42.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.5110 - accuracy: 0.8269 - val_loss: 0.5448 - val_accuracy: 0.8176 - _timestamp: 1654972478.0000 - _runtime: 71.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4657 - accuracy: 0.8387 - val_loss: 0.4847 - val_accuracy: 0.8320 - _timestamp: 1654972508.0000 - _runtime: 101.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4433 - accuracy: 0.8450 - val_loss: 0.4372 - val_accuracy: 0.8453 - _timestamp: 1654972538.0000 - _runtime: 131.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4260 - accuracy: 0.8494 - val_loss: 0.4521 - val_accuracy: 0.8416 - _timestamp: 1654972567.0000 - _runtime: 160.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4143 - accuracy: 0.8525 - val_loss: 0.4621 - val_accuracy: 0.8415 - _timestamp: 1654972597.0000 - _runtime: 190.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4042 - accuracy: 0.8551 - val_loss: 0.4308 - val_accuracy: 0.8498 - _timestamp: 1654972627.0000 - _runtime: 220.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.3965 - accuracy: 0.8573 - val_loss: 0.4241 - val_accuracy: 0.8498 - _timestamp: 1654972656.0000 - _runtime: 249.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.3893 - accuracy: 0.8593 - val_loss: 0.4164 - val_accuracy: 0.8524 - _timestamp: 1654972686.0000 - _runtime: 279.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.3827 - accuracy: 0.8611 - val_loss: 0.4042 - val_accuracy: 0.8573 - _timestamp: 1654972716.0000 - _runtime: 309.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d23a23d1de14a4a88557f9f18268201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.223 MB of 4.223 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▇▇▇▇▇██</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86105</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.40416</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.38271</td></tr><tr><td>val_accuracy</td><td>0.85729</td></tr><tr><td>val_loss</td><td>0.40416</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">electric-sweep-12</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/ats67lbi\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/ats67lbi</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_033327-ats67lbi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 61eht4p6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_033853-61eht4p6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/61eht4p6\" target=\"_blank\">fanciful-sweep-13</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 128)       3328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 128)      512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 128)       409728    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 64)        73792     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 64)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                4030      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,158\n",
      "Trainable params: 491,518\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 31s 7ms/step - loss: 0.9229 - accuracy: 0.7401 - val_loss: 0.6165 - val_accuracy: 0.7930 - _timestamp: 1654972775.0000 - _runtime: 42.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.5398 - accuracy: 0.8212 - val_loss: 0.5244 - val_accuracy: 0.8233 - _timestamp: 1654972805.0000 - _runtime: 72.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4908 - accuracy: 0.8323 - val_loss: 0.5067 - val_accuracy: 0.8291 - _timestamp: 1654972836.0000 - _runtime: 103.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4640 - accuracy: 0.8394 - val_loss: 0.4717 - val_accuracy: 0.8397 - _timestamp: 1654972866.0000 - _runtime: 133.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4466 - accuracy: 0.8442 - val_loss: 0.4495 - val_accuracy: 0.8446 - _timestamp: 1654972896.0000 - _runtime: 163.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4343 - accuracy: 0.8469 - val_loss: 0.4500 - val_accuracy: 0.8416 - _timestamp: 1654972927.0000 - _runtime: 194.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4247 - accuracy: 0.8497 - val_loss: 0.4389 - val_accuracy: 0.8465 - _timestamp: 1654972957.0000 - _runtime: 224.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4149 - accuracy: 0.8523 - val_loss: 0.4352 - val_accuracy: 0.8462 - _timestamp: 1654972987.0000 - _runtime: 254.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 31s 7ms/step - loss: 0.4081 - accuracy: 0.8546 - val_loss: 0.4233 - val_accuracy: 0.8525 - _timestamp: 1654973018.0000 - _runtime: 285.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4027 - accuracy: 0.8563 - val_loss: 0.4226 - val_accuracy: 0.8498 - _timestamp: 1654973048.0000 - _runtime: 315.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e50d832dab42ec8f59a884e6be1a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.696 MB of 5.696 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▅▆▇▇▇▇██</td></tr><tr><td>val_loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.8563</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.42263</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.4027</td></tr><tr><td>val_accuracy</td><td>0.8498</td></tr><tr><td>val_loss</td><td>0.42263</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fanciful-sweep-13</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/61eht4p6\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/61eht4p6</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_033853-61eht4p6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vi5lrdkg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_034419-vi5lrdkg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/vi5lrdkg\" target=\"_blank\">dainty-sweep-14</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 256)       205056    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 128)       295040    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                7998      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 510,590\n",
      "Trainable params: 509,758\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 38s 9ms/step - loss: 0.8336 - accuracy: 0.7583 - val_loss: 0.5257 - val_accuracy: 0.8237 - _timestamp: 1654973107.0000 - _runtime: 48.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.5037 - accuracy: 0.8297 - val_loss: 0.5584 - val_accuracy: 0.8105 - _timestamp: 1654973144.0000 - _runtime: 85.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.4593 - accuracy: 0.8413 - val_loss: 0.4654 - val_accuracy: 0.8408 - _timestamp: 1654973181.0000 - _runtime: 122.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 37s 9ms/step - loss: 0.4362 - accuracy: 0.8461 - val_loss: 0.4662 - val_accuracy: 0.8405 - _timestamp: 1654973218.0000 - _runtime: 159.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 37s 9ms/step - loss: 0.4217 - accuracy: 0.8499 - val_loss: 0.4956 - val_accuracy: 0.8292 - _timestamp: 1654973255.0000 - _runtime: 196.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 37s 9ms/step - loss: 0.4081 - accuracy: 0.8546 - val_loss: 0.4309 - val_accuracy: 0.8449 - _timestamp: 1654973292.0000 - _runtime: 233.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.3984 - accuracy: 0.8574 - val_loss: 0.4065 - val_accuracy: 0.8559 - _timestamp: 1654973329.0000 - _runtime: 270.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.3885 - accuracy: 0.8596 - val_loss: 0.4087 - val_accuracy: 0.8553 - _timestamp: 1654973366.0000 - _runtime: 307.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 37s 9ms/step - loss: 0.3822 - accuracy: 0.8616 - val_loss: 0.4159 - val_accuracy: 0.8540 - _timestamp: 1654973403.0000 - _runtime: 344.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 37s 9ms/step - loss: 0.3755 - accuracy: 0.8633 - val_loss: 0.4086 - val_accuracy: 0.8541 - _timestamp: 1654973441.0000 - _runtime: 382.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50fcf50701c8436fb3c8100bcbda6849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.906 MB of 5.906 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▃▁▆▆▄▆████</td></tr><tr><td>val_loss</td><td>▆█▄▄▅▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86325</td></tr><tr><td>best_epoch</td><td>6</td></tr><tr><td>best_val_loss</td><td>0.4065</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.37552</td></tr><tr><td>val_accuracy</td><td>0.85414</td></tr><tr><td>val_loss</td><td>0.40861</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dainty-sweep-14</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/vi5lrdkg\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/vi5lrdkg</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_034419-vi5lrdkg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: blka3jqf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_035049-blka3jqf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/blka3jqf\" target=\"_blank\">pretty-sweep-15</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 128)       102528    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 256)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                15934     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 416,126\n",
      "Trainable params: 415,294\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 36s 8ms/step - loss: 0.7829 - accuracy: 0.7673 - val_loss: 0.6008 - val_accuracy: 0.8025 - _timestamp: 1654973496.0000 - _runtime: 47.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.4910 - accuracy: 0.8336 - val_loss: 0.5015 - val_accuracy: 0.8313 - _timestamp: 1654973531.0000 - _runtime: 82.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.4501 - accuracy: 0.8427 - val_loss: 0.4470 - val_accuracy: 0.8453 - _timestamp: 1654973567.0000 - _runtime: 118.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.4252 - accuracy: 0.8496 - val_loss: 0.4179 - val_accuracy: 0.8521 - _timestamp: 1654973602.0000 - _runtime: 153.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.4114 - accuracy: 0.8527 - val_loss: 0.4231 - val_accuracy: 0.8508 - _timestamp: 1654973637.0000 - _runtime: 188.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.3984 - accuracy: 0.8568 - val_loss: 0.4602 - val_accuracy: 0.8420 - _timestamp: 1654973672.0000 - _runtime: 223.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.3896 - accuracy: 0.8591 - val_loss: 0.4138 - val_accuracy: 0.8543 - _timestamp: 1654973707.0000 - _runtime: 258.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.3806 - accuracy: 0.8619 - val_loss: 0.3979 - val_accuracy: 0.8581 - _timestamp: 1654973742.0000 - _runtime: 293.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.3725 - accuracy: 0.8636 - val_loss: 0.3997 - val_accuracy: 0.8566 - _timestamp: 1654973778.0000 - _runtime: 329.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.3671 - accuracy: 0.8647 - val_loss: 0.3947 - val_accuracy: 0.8595 - _timestamp: 1654973813.0000 - _runtime: 364.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc00e8fab1dd47c7a0d8312dbfc6ecb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.825 MB of 4.825 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▆▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇▇▆▇███</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86472</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.39469</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.36708</td></tr><tr><td>val_accuracy</td><td>0.85949</td></tr><tr><td>val_loss</td><td>0.39469</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pretty-sweep-15</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/blka3jqf\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/blka3jqf</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_035049-blka3jqf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rz3aslyy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_035702-rz3aslyy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/rz3aslyy\" target=\"_blank\">astral-sweep-16</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 128)       3328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 128)      512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 256)       819456    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 64)        147520    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 64)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                4030      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 976,126\n",
      "Trainable params: 975,230\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 42s 10ms/step - loss: 0.8901 - accuracy: 0.7503 - val_loss: 0.7210 - val_accuracy: 0.7719 - _timestamp: 1654973875.0000 - _runtime: 53.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 41s 9ms/step - loss: 0.5194 - accuracy: 0.8256 - val_loss: 0.5530 - val_accuracy: 0.8147 - _timestamp: 1654973916.0000 - _runtime: 94.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 41s 9ms/step - loss: 0.4744 - accuracy: 0.8367 - val_loss: 0.4802 - val_accuracy: 0.8372 - _timestamp: 1654973958.0000 - _runtime: 136.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 41s 9ms/step - loss: 0.4489 - accuracy: 0.8444 - val_loss: 0.4904 - val_accuracy: 0.8326 - _timestamp: 1654973999.0000 - _runtime: 177.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 42s 10ms/step - loss: 0.4341 - accuracy: 0.8472 - val_loss: 0.4870 - val_accuracy: 0.8345 - _timestamp: 1654974041.0000 - _runtime: 219.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 42s 10ms/step - loss: 0.4218 - accuracy: 0.8511 - val_loss: 0.4297 - val_accuracy: 0.8498 - _timestamp: 1654974082.0000 - _runtime: 260.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 41s 9ms/step - loss: 0.4118 - accuracy: 0.8535 - val_loss: 0.4305 - val_accuracy: 0.8494 - _timestamp: 1654974123.0000 - _runtime: 301.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 41s 9ms/step - loss: 0.4025 - accuracy: 0.8550 - val_loss: 0.4966 - val_accuracy: 0.8252 - _timestamp: 1654974165.0000 - _runtime: 343.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 42s 10ms/step - loss: 0.3950 - accuracy: 0.8578 - val_loss: 0.4182 - val_accuracy: 0.8519 - _timestamp: 1654974206.0000 - _runtime: 384.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 41s 9ms/step - loss: 0.3898 - accuracy: 0.8591 - val_loss: 0.4027 - val_accuracy: 0.8565 - _timestamp: 1654974248.0000 - _runtime: 426.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9319acab8c97483babeaf993dd99132d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='11.233 MB of 11.233 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▆▆▇▇▅██</td></tr><tr><td>val_loss</td><td>█▄▃▃▃▂▂▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.85906</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.40272</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.38982</td></tr><tr><td>val_accuracy</td><td>0.85654</td></tr><tr><td>val_loss</td><td>0.40272</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">astral-sweep-16</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/rz3aslyy\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/rz3aslyy</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_035702-rz3aslyy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0ke12e49 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_040424-0ke12e49</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/0ke12e49\" target=\"_blank\">helpful-sweep-17</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 256)       205056    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 128)       295040    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                7998      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 510,590\n",
      "Trainable params: 509,758\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 38s 8ms/step - loss: 0.8306 - accuracy: 0.7588 - val_loss: 0.5806 - val_accuracy: 0.8087 - _timestamp: 1654974313.0000 - _runtime: 49.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.4993 - accuracy: 0.8309 - val_loss: 0.4686 - val_accuracy: 0.8395 - _timestamp: 1654974350.0000 - _runtime: 86.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.4546 - accuracy: 0.8423 - val_loss: 0.5311 - val_accuracy: 0.8246 - _timestamp: 1654974387.0000 - _runtime: 123.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.4316 - accuracy: 0.8478 - val_loss: 0.4457 - val_accuracy: 0.8454 - _timestamp: 1654974424.0000 - _runtime: 160.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.4162 - accuracy: 0.8525 - val_loss: 0.4324 - val_accuracy: 0.8489 - _timestamp: 1654974460.0000 - _runtime: 196.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.4056 - accuracy: 0.8538 - val_loss: 0.4192 - val_accuracy: 0.8511 - _timestamp: 1654974497.0000 - _runtime: 233.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.3950 - accuracy: 0.8568 - val_loss: 0.4145 - val_accuracy: 0.8506 - _timestamp: 1654974534.0000 - _runtime: 270.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.3873 - accuracy: 0.8600 - val_loss: 0.4218 - val_accuracy: 0.8521 - _timestamp: 1654974571.0000 - _runtime: 307.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.3789 - accuracy: 0.8625 - val_loss: 0.4125 - val_accuracy: 0.8550 - _timestamp: 1654974608.0000 - _runtime: 344.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.3732 - accuracy: 0.8631 - val_loss: 0.4023 - val_accuracy: 0.8554 - _timestamp: 1654974644.0000 - _runtime: 380.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb6e848af5041ad9b99c33814edfad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.906 MB of 5.906 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▆▃▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▄▆▃▂▂▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86315</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.40227</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.37325</td></tr><tr><td>val_accuracy</td><td>0.85537</td></tr><tr><td>val_loss</td><td>0.40227</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">helpful-sweep-17</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/0ke12e49\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/0ke12e49</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_040424-0ke12e49\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p0d96mux with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_041054-p0d96mux</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/p0d96mux\" target=\"_blank\">fine-sweep-18</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 128)       3328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 128)      512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 256)       819456    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 256)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                15934     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,431,358\n",
      "Trainable params: 1,430,078\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 56s 13ms/step - loss: 0.7401 - accuracy: 0.7767 - val_loss: 0.5349 - val_accuracy: 0.8206 - _timestamp: 1654974721.0000 - _runtime: 67.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 55s 13ms/step - loss: 0.4761 - accuracy: 0.8358 - val_loss: 0.4621 - val_accuracy: 0.8396 - _timestamp: 1654974776.0000 - _runtime: 122.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 55s 13ms/step - loss: 0.4361 - accuracy: 0.8469 - val_loss: 0.4620 - val_accuracy: 0.8407 - _timestamp: 1654974831.0000 - _runtime: 177.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 55s 13ms/step - loss: 0.4146 - accuracy: 0.8527 - val_loss: 0.4267 - val_accuracy: 0.8476 - _timestamp: 1654974886.0000 - _runtime: 232.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 55s 13ms/step - loss: 0.4000 - accuracy: 0.8560 - val_loss: 0.4467 - val_accuracy: 0.8437 - _timestamp: 1654974941.0000 - _runtime: 287.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 55s 13ms/step - loss: 0.3867 - accuracy: 0.8596 - val_loss: 0.4122 - val_accuracy: 0.8541 - _timestamp: 1654974996.0000 - _runtime: 342.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 55s 13ms/step - loss: 0.3760 - accuracy: 0.8627 - val_loss: 0.3936 - val_accuracy: 0.8562 - _timestamp: 1654975051.0000 - _runtime: 397.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 55s 13ms/step - loss: 0.3672 - accuracy: 0.8640 - val_loss: 0.3964 - val_accuracy: 0.8588 - _timestamp: 1654975106.0000 - _runtime: 452.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 55s 13ms/step - loss: 0.3571 - accuracy: 0.8671 - val_loss: 0.3975 - val_accuracy: 0.8532 - _timestamp: 1654975161.0000 - _runtime: 507.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 55s 13ms/step - loss: 0.3505 - accuracy: 0.8697 - val_loss: 0.3881 - val_accuracy: 0.8614 - _timestamp: 1654975216.0000 - _runtime: 562.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56190d80fdda4a1c86e1a01b56c21486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='16.440 MB of 16.440 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▇▇▇▇███</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▃▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▄▆▅▇▇█▇█</td></tr><tr><td>val_loss</td><td>█▅▅▃▄▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86967</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.38814</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.35048</td></tr><tr><td>val_accuracy</td><td>0.8614</td></tr><tr><td>val_loss</td><td>0.38814</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fine-sweep-18</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/p0d96mux\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/p0d96mux</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_041054-p0d96mux\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m08o59c0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_042024-m08o59c0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/m08o59c0\" target=\"_blank\">dazzling-sweep-19</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        1664      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                7998      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 363,454\n",
      "Trainable params: 362,814\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.8318 - accuracy: 0.7585 - val_loss: 0.6051 - val_accuracy: 0.8036 - _timestamp: 1654975265.0000 - _runtime: 41.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.5061 - accuracy: 0.8299 - val_loss: 0.4940 - val_accuracy: 0.8317 - _timestamp: 1654975295.0000 - _runtime: 71.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4624 - accuracy: 0.8403 - val_loss: 0.4639 - val_accuracy: 0.8396 - _timestamp: 1654975325.0000 - _runtime: 101.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4383 - accuracy: 0.8471 - val_loss: 0.4338 - val_accuracy: 0.8453 - _timestamp: 1654975355.0000 - _runtime: 131.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4235 - accuracy: 0.8506 - val_loss: 0.4292 - val_accuracy: 0.8500 - _timestamp: 1654975384.0000 - _runtime: 160.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4114 - accuracy: 0.8530 - val_loss: 0.4250 - val_accuracy: 0.8495 - _timestamp: 1654975414.0000 - _runtime: 190.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.4015 - accuracy: 0.8554 - val_loss: 0.4216 - val_accuracy: 0.8524 - _timestamp: 1654975444.0000 - _runtime: 220.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.3943 - accuracy: 0.8582 - val_loss: 0.4172 - val_accuracy: 0.8533 - _timestamp: 1654975474.0000 - _runtime: 250.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.3874 - accuracy: 0.8597 - val_loss: 0.4042 - val_accuracy: 0.8566 - _timestamp: 1654975503.0000 - _runtime: 279.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 30s 7ms/step - loss: 0.3811 - accuracy: 0.8614 - val_loss: 0.4001 - val_accuracy: 0.8582 - _timestamp: 1654975533.0000 - _runtime: 309.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8265a99b8f440391f84a1cf1c16901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.223 MB of 4.223 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▆▇▇▇▇██</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86136</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.40014</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.3811</td></tr><tr><td>val_accuracy</td><td>0.85822</td></tr><tr><td>val_loss</td><td>0.40014</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dazzling-sweep-19</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/m08o59c0\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/m08o59c0</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_042024-m08o59c0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ajjcoswl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_042543-ajjcoswl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/ajjcoswl\" target=\"_blank\">likely-sweep-20</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 128)       102528    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                7998      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 260,094\n",
      "Trainable params: 259,518\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 28s 6ms/step - loss: 0.8556 - accuracy: 0.7514 - val_loss: 0.5600 - val_accuracy: 0.8155 - _timestamp: 1654975582.0000 - _runtime: 39.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 28s 6ms/step - loss: 0.5150 - accuracy: 0.8264 - val_loss: 0.5200 - val_accuracy: 0.8270 - _timestamp: 1654975610.0000 - _runtime: 67.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 28s 6ms/step - loss: 0.4691 - accuracy: 0.8377 - val_loss: 0.4592 - val_accuracy: 0.8428 - _timestamp: 1654975637.0000 - _runtime: 94.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 28s 6ms/step - loss: 0.4446 - accuracy: 0.8452 - val_loss: 0.4369 - val_accuracy: 0.8450 - _timestamp: 1654975665.0000 - _runtime: 122.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 28s 6ms/step - loss: 0.4292 - accuracy: 0.8486 - val_loss: 0.4359 - val_accuracy: 0.8456 - _timestamp: 1654975693.0000 - _runtime: 150.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 28s 6ms/step - loss: 0.4168 - accuracy: 0.8516 - val_loss: 0.4289 - val_accuracy: 0.8485 - _timestamp: 1654975721.0000 - _runtime: 178.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 28s 6ms/step - loss: 0.4066 - accuracy: 0.8549 - val_loss: 0.4305 - val_accuracy: 0.8479 - _timestamp: 1654975748.0000 - _runtime: 205.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 28s 6ms/step - loss: 0.3988 - accuracy: 0.8567 - val_loss: 0.4083 - val_accuracy: 0.8562 - _timestamp: 1654975776.0000 - _runtime: 233.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 28s 6ms/step - loss: 0.3911 - accuracy: 0.8592 - val_loss: 0.4138 - val_accuracy: 0.8527 - _timestamp: 1654975804.0000 - _runtime: 261.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 28s 6ms/step - loss: 0.3855 - accuracy: 0.8601 - val_loss: 0.3967 - val_accuracy: 0.8563 - _timestamp: 1654975832.0000 - _runtime: 289.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38be0b11c344c31b663317693ec876f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.041 MB of 3.041 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▆▆▆▇▇█▇█</td></tr><tr><td>val_loss</td><td>█▆▄▃▃▂▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86006</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.39668</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.38551</td></tr><tr><td>val_accuracy</td><td>0.85632</td></tr><tr><td>val_loss</td><td>0.39668</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">likely-sweep-20</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/ajjcoswl\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/ajjcoswl</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_042543-ajjcoswl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cma3m6xj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_043042-cma3m6xj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/cma3m6xj\" target=\"_blank\">scarlet-sweep-21</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 256)       205056    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 128)       295040    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                7998      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 510,590\n",
      "Trainable params: 509,758\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 38s 8ms/step - loss: 0.8300 - accuracy: 0.7593 - val_loss: 0.5793 - val_accuracy: 0.8096 - _timestamp: 1654975891.0000 - _runtime: 49.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.5004 - accuracy: 0.8306 - val_loss: 0.4702 - val_accuracy: 0.8363 - _timestamp: 1654975928.0000 - _runtime: 86.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.4568 - accuracy: 0.8423 - val_loss: 0.4688 - val_accuracy: 0.8381 - _timestamp: 1654975964.0000 - _runtime: 122.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.4345 - accuracy: 0.8481 - val_loss: 0.4592 - val_accuracy: 0.8381 - _timestamp: 1654976001.0000 - _runtime: 159.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.4190 - accuracy: 0.8515 - val_loss: 0.4303 - val_accuracy: 0.8512 - _timestamp: 1654976038.0000 - _runtime: 196.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.4052 - accuracy: 0.8552 - val_loss: 0.4182 - val_accuracy: 0.8520 - _timestamp: 1654976075.0000 - _runtime: 233.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.3975 - accuracy: 0.8568 - val_loss: 0.4768 - val_accuracy: 0.8436 - _timestamp: 1654976111.0000 - _runtime: 269.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.3876 - accuracy: 0.8597 - val_loss: 0.4192 - val_accuracy: 0.8488 - _timestamp: 1654976148.0000 - _runtime: 306.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.3812 - accuracy: 0.8607 - val_loss: 0.3943 - val_accuracy: 0.8590 - _timestamp: 1654976185.0000 - _runtime: 343.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 37s 8ms/step - loss: 0.3747 - accuracy: 0.8635 - val_loss: 0.4079 - val_accuracy: 0.8539 - _timestamp: 1654976222.0000 - _runtime: 380.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9885be98312049a7b1b4bc7d5be6e2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.906 MB of 5.906 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▅▅▇▇▆▇█▇</td></tr><tr><td>val_loss</td><td>█▄▄▃▂▂▄▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86345</td></tr><tr><td>best_epoch</td><td>8</td></tr><tr><td>best_val_loss</td><td>0.39427</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.37466</td></tr><tr><td>val_accuracy</td><td>0.85388</td></tr><tr><td>val_loss</td><td>0.40786</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">scarlet-sweep-21</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/cma3m6xj\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/cma3m6xj</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_043042-cma3m6xj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p4rtpee0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_043714-p4rtpee0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/p4rtpee0\" target=\"_blank\">swift-sweep-22</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 128)       102528    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 256)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                15934     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 416,126\n",
      "Trainable params: 415,294\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 36s 8ms/step - loss: 0.7786 - accuracy: 0.7684 - val_loss: 0.5233 - val_accuracy: 0.8261 - _timestamp: 1654976281.0000 - _runtime: 47.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.4837 - accuracy: 0.8342 - val_loss: 0.4610 - val_accuracy: 0.8390 - _timestamp: 1654976316.0000 - _runtime: 82.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 36s 8ms/step - loss: 0.4450 - accuracy: 0.8450 - val_loss: 0.4428 - val_accuracy: 0.8455 - _timestamp: 1654976352.0000 - _runtime: 118.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.4237 - accuracy: 0.8507 - val_loss: 0.4450 - val_accuracy: 0.8460 - _timestamp: 1654976387.0000 - _runtime: 153.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.4090 - accuracy: 0.8535 - val_loss: 0.4150 - val_accuracy: 0.8537 - _timestamp: 1654976422.0000 - _runtime: 188.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.3986 - accuracy: 0.8568 - val_loss: 0.4125 - val_accuracy: 0.8525 - _timestamp: 1654976457.0000 - _runtime: 223.0000\n",
      "Epoch 7/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.3887 - accuracy: 0.8588 - val_loss: 0.3969 - val_accuracy: 0.8578 - _timestamp: 1654976493.0000 - _runtime: 259.0000\n",
      "Epoch 8/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.3797 - accuracy: 0.8613 - val_loss: 0.4087 - val_accuracy: 0.8480 - _timestamp: 1654976528.0000 - _runtime: 294.0000\n",
      "Epoch 9/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.3732 - accuracy: 0.8635 - val_loss: 0.4079 - val_accuracy: 0.8553 - _timestamp: 1654976564.0000 - _runtime: 330.0000\n",
      "Epoch 10/10\n",
      "4363/4363 [==============================] - 35s 8ms/step - loss: 0.3660 - accuracy: 0.8656 - val_loss: 0.4034 - val_accuracy: 0.8543 - _timestamp: 1654976599.0000 - _runtime: 365.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975cbde2f98e49dab46e12ef93b80454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.825 MB of 4.825 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▅▇▇█▆▇▇</td></tr><tr><td>val_loss</td><td>█▅▄▄▂▂▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86556</td></tr><tr><td>best_epoch</td><td>6</td></tr><tr><td>best_val_loss</td><td>0.3969</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.366</td></tr><tr><td>val_accuracy</td><td>0.85433</td></tr><tr><td>val_loss</td><td>0.4034</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">swift-sweep-22</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/p4rtpee0\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/p4rtpee0</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220612_043714-p4rtpee0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v09raihf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220612_044329-v09raihf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/v09raihf\" target=\"_blank\">rose-sweep-23</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/fd73n8t8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 128)       102528    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                7998      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 260,094\n",
      "Trainable params: 259,518\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "4363/4363 [==============================] - 28s 6ms/step - loss: 0.8581 - accuracy: 0.7516 - val_loss: 0.6421 - val_accuracy: 0.7905 - _timestamp: 1654976649.0000 - _runtime: 40.0000\n",
      "Epoch 2/10\n",
      "4363/4363 [==============================] - 28s 6ms/step - loss: 0.5131 - accuracy: 0.8269 - val_loss: 0.5086 - val_accuracy: 0.8301 - _timestamp: 1654976676.0000 - _runtime: 67.0000\n",
      "Epoch 3/10\n",
      "4363/4363 [==============================] - 28s 6ms/step - loss: 0.4672 - accuracy: 0.8392 - val_loss: 0.4986 - val_accuracy: 0.8270 - _timestamp: 1654976704.0000 - _runtime: 95.0000\n",
      "Epoch 4/10\n",
      "4363/4363 [==============================] - 28s 6ms/step - loss: 0.4429 - accuracy: 0.8458 - val_loss: 0.4465 - val_accuracy: 0.8440 - _timestamp: 1654976732.0000 - _runtime: 123.0000\n",
      "Epoch 5/10\n",
      "4363/4363 [==============================] - 28s 6ms/step - loss: 0.4278 - accuracy: 0.8489 - val_loss: 0.4302 - val_accuracy: 0.8483 - _timestamp: 1654976760.0000 - _runtime: 151.0000\n",
      "Epoch 6/10\n",
      "4363/4363 [==============================] - 28s 6ms/step - loss: 0.4147 - accuracy: 0.8524 - val_loss: 0.4112 - val_accuracy: 0.8534 - _timestamp: 1654976788.0000 - _runtime: 179.0000\n",
      "Epoch 7/10\n",
      "4355/4363 [============================>.] - ETA: 0s - loss: 0.4045 - accuracy: 0.8552"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "  'method': 'random',\n",
    "  'metric': {\n",
    "      'name': 'val_loss',\n",
    "      'goal': 'minimize'   \n",
    "    },\n",
    "  'parameters': {\n",
    "      'n_first_node' : {\n",
    "          'values' : [32, 64, 128]\n",
    "      },\n",
    "      'n_second_node' : {\n",
    "          'values' : [128, 256]\n",
    "      },\n",
    "      'n_third_node' : {\n",
    "          'values' : [64, 128, 256]\n",
    "      }\n",
    "  }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config)\n",
    "\n",
    "wandb.agent(sweep_id, function=sweep_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILD #220523\n",
    "\n",
    "OH GOD PLEASE WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 128)       3328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 128)      512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 256)       819456    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 512)       1180160   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 512)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                31806     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,038,334\n",
      "Trainable params: 2,036,542\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "my_lenet_5_selu_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(128, kernel_size=5, strides=1,  activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=train_x[0].shape, padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(256, kernel_size=5, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(512, kernel_size=3, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(62, activation='softmax')\n",
    "])\n",
    "\n",
    "my_lenet_5_selu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3636/3636 [==============================] - 22s 6ms/step - loss: 0.3583 - accuracy: 0.8701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35832297801971436, 0.8700761795043945]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lenet_5_selu_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "    5/17449 [..............................] - ETA: 3:51 - loss: 3.9902 - accuracy: 0.1063   WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0066s vs `on_train_batch_end` time: 0.0067s). Check your callbacks.\n",
      "17449/17449 [==============================] - 250s 14ms/step - loss: 0.5072 - accuracy: 0.8303 - val_loss: 0.4369 - val_accuracy: 0.8474 - _timestamp: 1654999508.0000 - _runtime: 3618.0000\n",
      "Epoch 2/240\n",
      "17449/17449 [==============================] - 250s 14ms/step - loss: 0.3931 - accuracy: 0.8587 - val_loss: 0.3994 - val_accuracy: 0.8545 - _timestamp: 1654999758.0000 - _runtime: 3868.0000\n",
      "Epoch 3/240\n",
      "17449/17449 [==============================] - 251s 14ms/step - loss: 0.3731 - accuracy: 0.8635 - val_loss: 0.3747 - val_accuracy: 0.8649 - _timestamp: 1655000009.0000 - _runtime: 4119.0000\n",
      "Epoch 4/240\n",
      "17449/17449 [==============================] - 251s 14ms/step - loss: 0.3605 - accuracy: 0.8676 - val_loss: 0.3763 - val_accuracy: 0.8604 - _timestamp: 1655000260.0000 - _runtime: 4370.0000\n",
      "Epoch 5/240\n",
      "17449/17449 [==============================] - 252s 14ms/step - loss: 0.3512 - accuracy: 0.8700 - val_loss: 0.3569 - val_accuracy: 0.8699 - _timestamp: 1655000512.0000 - _runtime: 4622.0000\n",
      "Epoch 6/240\n",
      "17449/17449 [==============================] - 251s 14ms/step - loss: 0.3441 - accuracy: 0.8725 - val_loss: 0.3636 - val_accuracy: 0.8691 - _timestamp: 1655000763.0000 - _runtime: 4873.0000\n",
      "Epoch 7/240\n",
      "17449/17449 [==============================] - 277s 16ms/step - loss: 0.3377 - accuracy: 0.8742 - val_loss: 0.3550 - val_accuracy: 0.8707 - _timestamp: 1655001040.0000 - _runtime: 5150.0000\n",
      "Epoch 8/240\n",
      "17449/17449 [==============================] - 281s 16ms/step - loss: 0.3317 - accuracy: 0.8756 - val_loss: 0.3563 - val_accuracy: 0.8674 - _timestamp: 1655001321.0000 - _runtime: 5431.0000\n",
      "Epoch 9/240\n",
      "17449/17449 [==============================] - 254s 15ms/step - loss: 0.3268 - accuracy: 0.8770 - val_loss: 0.3521 - val_accuracy: 0.8718 - _timestamp: 1655001575.0000 - _runtime: 5685.0000\n",
      "Epoch 10/240\n",
      "17449/17449 [==============================] - 253s 15ms/step - loss: 0.3215 - accuracy: 0.8788 - val_loss: 0.3485 - val_accuracy: 0.8732 - _timestamp: 1655001829.0000 - _runtime: 5939.0000\n",
      "Epoch 11/240\n",
      "17449/17449 [==============================] - 286s 16ms/step - loss: 0.3164 - accuracy: 0.8801 - val_loss: 0.3484 - val_accuracy: 0.8715 - _timestamp: 1655002114.0000 - _runtime: 6224.0000\n",
      "Epoch 12/240\n",
      "17449/17449 [==============================] - 285s 16ms/step - loss: 0.3116 - accuracy: 0.8815 - val_loss: 0.3542 - val_accuracy: 0.8719 - _timestamp: 1655002400.0000 - _runtime: 6510.0000\n",
      "Epoch 13/240\n",
      "17449/17449 [==============================] - 296s 17ms/step - loss: 0.3070 - accuracy: 0.8824 - val_loss: 0.3527 - val_accuracy: 0.8704 - _timestamp: 1655002696.0000 - _runtime: 6806.0000\n",
      "Epoch 14/240\n",
      "17449/17449 [==============================] - 294s 17ms/step - loss: 0.3021 - accuracy: 0.8844 - val_loss: 0.3602 - val_accuracy: 0.8698 - _timestamp: 1655002989.0000 - _runtime: 7099.0000\n",
      "Epoch 15/240\n",
      "17449/17449 [==============================] - 287s 16ms/step - loss: 0.2979 - accuracy: 0.8856 - val_loss: 0.3567 - val_accuracy: 0.8717 - _timestamp: 1655003277.0000 - _runtime: 7387.0000\n",
      "Epoch 16/240\n",
      "17449/17449 [==============================] - 277s 16ms/step - loss: 0.2931 - accuracy: 0.8864 - val_loss: 0.3571 - val_accuracy: 0.8716 - _timestamp: 1655003554.0000 - _runtime: 7664.0000\n",
      "Epoch 17/240\n",
      "17449/17449 [==============================] - 296s 17ms/step - loss: 0.2887 - accuracy: 0.8882 - val_loss: 0.3640 - val_accuracy: 0.8717 - _timestamp: 1655003850.0000 - _runtime: 7960.0000\n",
      "Epoch 18/240\n",
      "17449/17449 [==============================] - 299s 17ms/step - loss: 0.2842 - accuracy: 0.8898 - val_loss: 0.3634 - val_accuracy: 0.8699 - _timestamp: 1655004149.0000 - _runtime: 8259.0000\n",
      "Epoch 19/240\n",
      "17449/17449 [==============================] - 292s 17ms/step - loss: 0.2798 - accuracy: 0.8909 - val_loss: 0.3634 - val_accuracy: 0.8719 - _timestamp: 1655004441.0000 - _runtime: 8551.0000\n",
      "Epoch 20/240\n",
      "17449/17449 [==============================] - 287s 16ms/step - loss: 0.2741 - accuracy: 0.8929 - val_loss: 0.3788 - val_accuracy: 0.8686 - _timestamp: 1655004728.0000 - _runtime: 8838.0000\n",
      "Epoch 21/240\n",
      "17449/17449 [==============================] - 295s 17ms/step - loss: 0.2704 - accuracy: 0.8942 - val_loss: 0.3721 - val_accuracy: 0.8702 - _timestamp: 1655005023.0000 - _runtime: 9133.0000\n",
      "3636/3636 [==============================] - 20s 5ms/step - loss: 0.3449 - accuracy: 0.8727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34490063786506653, 0.8726896047592163]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lenet_5_selu_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_lenet5_emnist_model.h5\", save_best_only=True)\n",
    "  \n",
    "my_lenet_5_selu_model.fit(train_x, train_y, epochs=240, validation_data=(val_x, val_y), callbacks=[early_stopping_cb, WandbCallback()])\n",
    "\n",
    "my_lenet_5_selu_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.time()\n",
    "now = time.localtime(now)\n",
    "my_lenet_5_selu_model.save(\"my_lenet5_emnist_model_%2d%02d%02d.h5\" %(now.tm_year, now.tm_mon, now.tm_mday), save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cca9558bc5ad879ec93cc030b157d75f18267527c60932cecaace349eef54dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
