{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS & PREPRODUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhyunseokerikjung\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220517_162102-1inlq4hl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/LeNet_5_test/runs/1inlq4hl\" target=\"_blank\">good-frost-4</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/LeNet_5_test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/hyunseokerikjung/LeNet_5_test/runs/1inlq4hl?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x181bbc983d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "wandb.init(project=\"LeNet_5_test\", entity=\"hyunseokerikjung\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('emnist-byclass-mapping.txt', sep=\" \", header=None)\n",
    "data.columns = ['Target','ASCII']\n",
    "\n",
    "col=[]\n",
    "for i in data.ASCII.tolist():\n",
    "    col.append(chr(i))\n",
    "\n",
    "data['ASCII_Target'] = pd.Series(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('emnist-byclass-train.csv/emnist-byclass-train.csv')\n",
    "train_df.rename(columns={'35':'Target'}, inplace=True)\n",
    "\n",
    "# train_df=pd.merge(train_df, data, how='left', on='Target')\n",
    "# train_df=train_df.drop(['Target','ASCII'],axis=1)\n",
    "# train_df.rename(columns={'ASCII_Target':'Target'}, inplace=True)\n",
    "\n",
    "train_y = np.array(train_df.pop('Target'))\n",
    "train_x = train_df\n",
    "\n",
    "train_x = train_x / 255.0\n",
    "train_x = train_x.values.reshape([-1, 28, 28, 1])\n",
    "train_y = keras.utils.to_categorical(train_y)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('emnist-byclass-test.csv/emnist-byclass-test.csv')\n",
    "test_df.rename(columns={'18':'Target'}, inplace=True)\n",
    "\n",
    "# test_df=pd.merge(test_df, data, how='left', on='Target')\n",
    "# test_df=test_df.drop(['Target','ASCII'],axis=1)\n",
    "# test_df.rename(columns={'ASCII_Target':'Target'}, inplace=True)\n",
    "\n",
    "test_y = np.array(test_df.pop('Target'))\n",
    "test_x = test_df\n",
    "\n",
    "test_x = test_x / 255.0\n",
    "test_x = test_x.values.reshape([-1, 28, 28, 1])\n",
    "test_y = keras.utils.to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_df = pd.read_csv('our_handmade_dataset.csv')\n",
    "hand_df.rename(columns={'0':'Target'}, inplace=True)\n",
    "\n",
    "# hand_df=pd.merge(hand_df, data, how='left', on='Target')\n",
    "# hand_df=hand_df.drop(['Target','ASCII'],axis=1)\n",
    "# hand_df.rename(columns={'ASCII_Target':'Target'}, inplace=True)\n",
    "\n",
    "hand_y = np.array(hand_df.pop('Target'))\n",
    "hand_x = hand_df\n",
    "\n",
    "hand_x = hand_x / 255.0\n",
    "hand_x = hand_x.values.reshape([-1, 28, 28, 1])\n",
    "hand_y = keras.utils.to_categorical(hand_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original LeNet_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 14, 14, 6)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_3 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 1, 1, 120)         48120     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 62)                5270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,126\n",
      "Trainable params: 66,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lenet_5_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation='tanh', input_shape=train_x[0].shape, padding='same'),\n",
    "    keras.layers.AveragePooling2D(),\n",
    "    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation='tanh', padding='valid'),\n",
    "    keras.layers.AveragePooling2D(),\n",
    "    keras.layers.Conv2D(120, kernel_size=5, strides=1, activation='tanh', padding='valid'),\n",
    "    keras.layers.Flatten(),   \n",
    "    keras.layers.Dense(84, activation='tanh'),\n",
    "    keras.layers.Dense(62, activation='softmax')\n",
    "])\n",
    "lenet_5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet_5_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_lenet5_emnist_model.h5\", save_best_only=True)\n",
    "\n",
    "lenet_5_model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y), callbacks=[early_stopping_cb])\n",
    "\n",
    "lenet_5_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet_5_SeLU\n",
    "\n",
    "SeLU performs better(speed & accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 6)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 1, 120)         48120     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                5270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,126\n",
      "Trainable params: 66,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "lenet_5_selu_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=train_x[0].shape, padding='same'),\n",
    "    keras.layers.AveragePooling2D(),\n",
    "    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.AveragePooling2D(),\n",
    "    keras.layers.Conv2D(120, kernel_size=5, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.Flatten(),   \n",
    "    keras.layers.Dense(84, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(62, activation='softmax')\n",
    "])\n",
    "\n",
    "lenet_5_selu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17449/17449 [==============================] - 63s 3ms/step - loss: 0.5903 - accuracy: 0.8034 - val_loss: 0.4675 - val_accuracy: 0.8360\n",
      "Epoch 2/10\n",
      "17449/17449 [==============================] - 56s 3ms/step - loss: 0.4577 - accuracy: 0.8374 - val_loss: 0.4607 - val_accuracy: 0.8349\n",
      "Epoch 3/10\n",
      "17449/17449 [==============================] - 56s 3ms/step - loss: 0.4352 - accuracy: 0.8441 - val_loss: 0.4475 - val_accuracy: 0.8412\n",
      "Epoch 4/10\n",
      "17449/17449 [==============================] - 57s 3ms/step - loss: 0.4231 - accuracy: 0.8470 - val_loss: 0.4274 - val_accuracy: 0.8461\n",
      "Epoch 5/10\n",
      "17449/17449 [==============================] - 55s 3ms/step - loss: 0.4146 - accuracy: 0.8495 - val_loss: 0.4431 - val_accuracy: 0.8433\n",
      "Epoch 6/10\n",
      "17449/17449 [==============================] - 55s 3ms/step - loss: 0.4087 - accuracy: 0.8510 - val_loss: 0.4219 - val_accuracy: 0.8510\n",
      "Epoch 7/10\n",
      "17449/17449 [==============================] - 58s 3ms/step - loss: 0.4045 - accuracy: 0.8516 - val_loss: 0.4233 - val_accuracy: 0.8504\n",
      "Epoch 8/10\n",
      "17449/17449 [==============================] - 56s 3ms/step - loss: 0.4008 - accuracy: 0.8530 - val_loss: 0.4242 - val_accuracy: 0.8485\n",
      "Epoch 9/10\n",
      "17449/17449 [==============================] - 56s 3ms/step - loss: 0.3975 - accuracy: 0.8543 - val_loss: 0.4262 - val_accuracy: 0.8473\n",
      "Epoch 10/10\n",
      "17449/17449 [==============================] - 57s 3ms/step - loss: 0.3941 - accuracy: 0.8550 - val_loss: 0.4205 - val_accuracy: 0.8502\n",
      "3636/3636 [==============================] - 6s 2ms/step - loss: 0.4134 - accuracy: 0.8515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41336914896965027, 0.8514984250068665]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet_5_selu_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_lenet5_emnist_model.h5\", save_best_only=True)\n",
    "\n",
    "lenet_5_selu_model.fit(train_x, train_y, epochs=10, validation_data=(val_x, val_y), callbacks=[early_stopping_cb])\n",
    "\n",
    "lenet_5_selu_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He Yanmei SeLU Lenet_5 model\n",
    "\n",
    "Lowers amount of parameters = lower inference time, less stable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "lenet_5_improved_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, kernel_size=5, strides=2, activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=train_x[0].shape, padding='same'),\n",
    "    keras.layers.Conv2D(64, kernel_size=3, strides=2, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.Conv2D(32, kernel_size=1, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(62, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet_5_improved_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_lenet5_emnist_model.h5\", save_best_only=True)\n",
    "\n",
    "lenet_5_improved_model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y), callbacks=[early_stopping_cb])\n",
    "\n",
    "lenet_5_improved_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build #20220515\n",
    "\n",
    "87.09% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17449/17449 [==============================] - 74s 4ms/step - loss: 0.7140 - accuracy: 0.7826 - val_loss: 0.5925 - val_accuracy: 0.8015\n",
      "Epoch 2/100\n",
      "17449/17449 [==============================] - 67s 4ms/step - loss: 0.4887 - accuracy: 0.8336 - val_loss: 0.4914 - val_accuracy: 0.8313\n",
      "Epoch 3/100\n",
      "17449/17449 [==============================] - 69s 4ms/step - loss: 0.4593 - accuracy: 0.8417 - val_loss: 0.4470 - val_accuracy: 0.8422\n",
      "Epoch 4/100\n",
      "17449/17449 [==============================] - 68s 4ms/step - loss: 0.4448 - accuracy: 0.8452 - val_loss: 0.4483 - val_accuracy: 0.8451\n",
      "Epoch 5/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.4345 - accuracy: 0.8479 - val_loss: 0.4292 - val_accuracy: 0.8479\n",
      "Epoch 6/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.4279 - accuracy: 0.8499 - val_loss: 0.4252 - val_accuracy: 0.8513\n",
      "Epoch 7/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.4225 - accuracy: 0.8515 - val_loss: 0.4107 - val_accuracy: 0.8562\n",
      "Epoch 8/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.4180 - accuracy: 0.8525 - val_loss: 0.4115 - val_accuracy: 0.8541\n",
      "Epoch 9/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.4134 - accuracy: 0.8541 - val_loss: 0.4235 - val_accuracy: 0.8519\n",
      "Epoch 10/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.4100 - accuracy: 0.8543 - val_loss: 0.4049 - val_accuracy: 0.8560\n",
      "Epoch 11/100\n",
      "17449/17449 [==============================] - 65s 4ms/step - loss: 0.4078 - accuracy: 0.8550 - val_loss: 0.3971 - val_accuracy: 0.8568\n",
      "Epoch 12/100\n",
      "17449/17449 [==============================] - 62s 4ms/step - loss: 0.4057 - accuracy: 0.8557 - val_loss: 0.4042 - val_accuracy: 0.8572\n",
      "Epoch 13/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.4027 - accuracy: 0.8570 - val_loss: 0.3958 - val_accuracy: 0.8588\n",
      "Epoch 14/100\n",
      "17449/17449 [==============================] - 65s 4ms/step - loss: 0.4009 - accuracy: 0.8574 - val_loss: 0.3955 - val_accuracy: 0.8580\n",
      "Epoch 15/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3991 - accuracy: 0.8578 - val_loss: 0.3931 - val_accuracy: 0.8594\n",
      "Epoch 16/100\n",
      "17449/17449 [==============================] - 62s 4ms/step - loss: 0.3967 - accuracy: 0.8581 - val_loss: 0.3948 - val_accuracy: 0.8589\n",
      "Epoch 17/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3955 - accuracy: 0.8587 - val_loss: 0.3872 - val_accuracy: 0.8612\n",
      "Epoch 18/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3942 - accuracy: 0.8592 - val_loss: 0.3925 - val_accuracy: 0.8599\n",
      "Epoch 19/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3921 - accuracy: 0.8595 - val_loss: 0.3914 - val_accuracy: 0.8591\n",
      "Epoch 20/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3914 - accuracy: 0.8597 - val_loss: 0.3862 - val_accuracy: 0.8615\n",
      "Epoch 21/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3904 - accuracy: 0.8598 - val_loss: 0.3875 - val_accuracy: 0.8599\n",
      "Epoch 22/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3886 - accuracy: 0.8606 - val_loss: 0.3839 - val_accuracy: 0.8620\n",
      "Epoch 23/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3877 - accuracy: 0.8607 - val_loss: 0.3858 - val_accuracy: 0.8605\n",
      "Epoch 24/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3867 - accuracy: 0.8610 - val_loss: 0.3817 - val_accuracy: 0.8621\n",
      "Epoch 25/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3852 - accuracy: 0.8614 - val_loss: 0.3812 - val_accuracy: 0.8620\n",
      "Epoch 26/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3851 - accuracy: 0.8616 - val_loss: 0.3827 - val_accuracy: 0.8622\n",
      "Epoch 27/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3839 - accuracy: 0.8620 - val_loss: 0.3781 - val_accuracy: 0.8633\n",
      "Epoch 28/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3825 - accuracy: 0.8626 - val_loss: 0.3789 - val_accuracy: 0.8622\n",
      "Epoch 29/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3823 - accuracy: 0.8623 - val_loss: 0.3812 - val_accuracy: 0.8627\n",
      "Epoch 30/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3811 - accuracy: 0.8625 - val_loss: 0.3786 - val_accuracy: 0.8620\n",
      "Epoch 31/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3810 - accuracy: 0.8627 - val_loss: 0.3819 - val_accuracy: 0.8629\n",
      "Epoch 32/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3801 - accuracy: 0.8626 - val_loss: 0.3850 - val_accuracy: 0.8620\n",
      "Epoch 33/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3792 - accuracy: 0.8628 - val_loss: 0.3781 - val_accuracy: 0.8628\n",
      "Epoch 34/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3786 - accuracy: 0.8632 - val_loss: 0.3785 - val_accuracy: 0.8628\n",
      "Epoch 35/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3780 - accuracy: 0.8638 - val_loss: 0.3728 - val_accuracy: 0.8657\n",
      "Epoch 36/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3770 - accuracy: 0.8637 - val_loss: 0.3747 - val_accuracy: 0.8653\n",
      "Epoch 37/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3760 - accuracy: 0.8639 - val_loss: 0.3790 - val_accuracy: 0.8633\n",
      "Epoch 38/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3763 - accuracy: 0.8637 - val_loss: 0.3717 - val_accuracy: 0.8664\n",
      "Epoch 39/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3750 - accuracy: 0.8641 - val_loss: 0.3742 - val_accuracy: 0.8654\n",
      "Epoch 40/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3746 - accuracy: 0.8645 - val_loss: 0.3766 - val_accuracy: 0.8643\n",
      "Epoch 41/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3738 - accuracy: 0.8646 - val_loss: 0.3744 - val_accuracy: 0.8649\n",
      "Epoch 42/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3731 - accuracy: 0.8646 - val_loss: 0.3740 - val_accuracy: 0.8646\n",
      "Epoch 43/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3728 - accuracy: 0.8651 - val_loss: 0.3750 - val_accuracy: 0.8649\n",
      "Epoch 44/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3721 - accuracy: 0.8648 - val_loss: 0.3718 - val_accuracy: 0.8653\n",
      "Epoch 45/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3715 - accuracy: 0.8652 - val_loss: 0.3721 - val_accuracy: 0.8654\n",
      "Epoch 46/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3713 - accuracy: 0.8653 - val_loss: 0.3720 - val_accuracy: 0.8655\n",
      "Epoch 47/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3709 - accuracy: 0.8652 - val_loss: 0.3712 - val_accuracy: 0.8665\n",
      "Epoch 48/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3707 - accuracy: 0.8655 - val_loss: 0.3727 - val_accuracy: 0.8643\n",
      "Epoch 49/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3702 - accuracy: 0.8657 - val_loss: 0.3750 - val_accuracy: 0.8648\n",
      "Epoch 50/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3697 - accuracy: 0.8660 - val_loss: 0.3750 - val_accuracy: 0.8650\n",
      "Epoch 51/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3681 - accuracy: 0.8662 - val_loss: 0.3718 - val_accuracy: 0.8660\n",
      "Epoch 52/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3685 - accuracy: 0.8661 - val_loss: 0.3684 - val_accuracy: 0.8669\n",
      "Epoch 53/100\n",
      "17449/17449 [==============================] - 62s 4ms/step - loss: 0.3678 - accuracy: 0.8659 - val_loss: 0.3697 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "17449/17449 [==============================] - 62s 4ms/step - loss: 0.3679 - accuracy: 0.8665 - val_loss: 0.3687 - val_accuracy: 0.8669\n",
      "Epoch 55/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3670 - accuracy: 0.8664 - val_loss: 0.3744 - val_accuracy: 0.8640\n",
      "Epoch 56/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3671 - accuracy: 0.8664 - val_loss: 0.3734 - val_accuracy: 0.8653\n",
      "Epoch 57/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3659 - accuracy: 0.8665 - val_loss: 0.3665 - val_accuracy: 0.8671\n",
      "Epoch 58/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3660 - accuracy: 0.8664 - val_loss: 0.3685 - val_accuracy: 0.8659\n",
      "Epoch 59/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3650 - accuracy: 0.8668 - val_loss: 0.3663 - val_accuracy: 0.8675\n",
      "Epoch 60/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3647 - accuracy: 0.8672 - val_loss: 0.3687 - val_accuracy: 0.8676\n",
      "Epoch 61/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3646 - accuracy: 0.8670 - val_loss: 0.3671 - val_accuracy: 0.8674\n",
      "Epoch 62/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3640 - accuracy: 0.8671 - val_loss: 0.3730 - val_accuracy: 0.8647\n",
      "Epoch 63/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3638 - accuracy: 0.8674 - val_loss: 0.3658 - val_accuracy: 0.8681\n",
      "Epoch 64/100\n",
      "17449/17449 [==============================] - 62s 4ms/step - loss: 0.3630 - accuracy: 0.8673 - val_loss: 0.3685 - val_accuracy: 0.8672\n",
      "Epoch 65/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3631 - accuracy: 0.8671 - val_loss: 0.3701 - val_accuracy: 0.8663\n",
      "Epoch 66/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3627 - accuracy: 0.8676 - val_loss: 0.3693 - val_accuracy: 0.8662\n",
      "Epoch 67/100\n",
      "17449/17449 [==============================] - 62s 4ms/step - loss: 0.3621 - accuracy: 0.8679 - val_loss: 0.3727 - val_accuracy: 0.8639\n",
      "Epoch 68/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3620 - accuracy: 0.8678 - val_loss: 0.3643 - val_accuracy: 0.8684\n",
      "Epoch 69/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3613 - accuracy: 0.8677 - val_loss: 0.3676 - val_accuracy: 0.8679\n",
      "Epoch 70/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3609 - accuracy: 0.8679 - val_loss: 0.3655 - val_accuracy: 0.8674\n",
      "Epoch 71/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3606 - accuracy: 0.8678 - val_loss: 0.3637 - val_accuracy: 0.8683\n",
      "Epoch 72/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3606 - accuracy: 0.8684 - val_loss: 0.3634 - val_accuracy: 0.8692\n",
      "Epoch 73/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3598 - accuracy: 0.8684 - val_loss: 0.3685 - val_accuracy: 0.8668\n",
      "Epoch 74/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3585 - accuracy: 0.8687 - val_loss: 0.3652 - val_accuracy: 0.8673\n",
      "Epoch 75/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3592 - accuracy: 0.8684 - val_loss: 0.3663 - val_accuracy: 0.8676\n",
      "Epoch 76/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3589 - accuracy: 0.8685 - val_loss: 0.3650 - val_accuracy: 0.8671\n",
      "Epoch 77/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3589 - accuracy: 0.8689 - val_loss: 0.3666 - val_accuracy: 0.8678\n",
      "Epoch 78/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3586 - accuracy: 0.8686 - val_loss: 0.3667 - val_accuracy: 0.8672\n",
      "Epoch 79/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3582 - accuracy: 0.8688 - val_loss: 0.3680 - val_accuracy: 0.8680\n",
      "Epoch 80/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3574 - accuracy: 0.8687 - val_loss: 0.3654 - val_accuracy: 0.8678\n",
      "Epoch 81/100\n",
      "17449/17449 [==============================] - 62s 4ms/step - loss: 0.3579 - accuracy: 0.8689 - val_loss: 0.3653 - val_accuracy: 0.8681\n",
      "Epoch 82/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3573 - accuracy: 0.8691 - val_loss: 0.3622 - val_accuracy: 0.8695\n",
      "Epoch 83/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3567 - accuracy: 0.8692 - val_loss: 0.3620 - val_accuracy: 0.8693\n",
      "Epoch 84/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3563 - accuracy: 0.8693 - val_loss: 0.3668 - val_accuracy: 0.8670\n",
      "Epoch 85/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3562 - accuracy: 0.8693 - val_loss: 0.3688 - val_accuracy: 0.8660\n",
      "Epoch 86/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3557 - accuracy: 0.8689 - val_loss: 0.3676 - val_accuracy: 0.8675\n",
      "Epoch 87/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3559 - accuracy: 0.8695 - val_loss: 0.3621 - val_accuracy: 0.8690\n",
      "Epoch 88/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3552 - accuracy: 0.8695 - val_loss: 0.3667 - val_accuracy: 0.8676\n",
      "Epoch 89/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3547 - accuracy: 0.8696 - val_loss: 0.3638 - val_accuracy: 0.8688\n",
      "Epoch 90/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3549 - accuracy: 0.8694 - val_loss: 0.3656 - val_accuracy: 0.8678\n",
      "Epoch 91/100\n",
      "17449/17449 [==============================] - 64s 4ms/step - loss: 0.3548 - accuracy: 0.8697 - val_loss: 0.3658 - val_accuracy: 0.8670\n",
      "Epoch 92/100\n",
      "17449/17449 [==============================] - 63s 4ms/step - loss: 0.3548 - accuracy: 0.8696 - val_loss: 0.3659 - val_accuracy: 0.8686\n",
      "Epoch 93/100\n",
      "17449/17449 [==============================] - 62s 4ms/step - loss: 0.3544 - accuracy: 0.8698 - val_loss: 0.3658 - val_accuracy: 0.8672\n",
      "3636/3636 [==============================] - 6s 2ms/step - loss: 0.3567 - accuracy: 0.8709\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 3.9395 - accuracy: 0.2763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.939462184906006, 0.27632108330726624]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "my_lenet_5_selu_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, kernel_size=5, strides=1,  activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=train_x[0].shape, padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, kernel_size=5, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(32, kernel_size=3, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(62, activation='softmax')\n",
    "])\n",
    "\n",
    "my_lenet_5_selu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lenet_5_selu_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_lenet5_emnist_model.h5\", save_best_only=True)\n",
    "  \n",
    "my_lenet_5_selu_model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y), callbacks=[early_stopping_cb, model_checkpoint_cb])\n",
    "\n",
    "my_lenet_5_selu_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lenet_5_selu_model.evaluate(hand_x, hand_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lenet_5_selu_model.save(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build #20220516\n",
    "\n",
    "86.74% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 26, 26, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 32)        18464     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 24, 24, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 32)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                2046      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,350\n",
      "Trainable params: 40,094\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "my_lenet_5_selu_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, kernel_size=5, strides=1,  activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=train_x[0].shape, padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, kernel_size=3, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(32, kernel_size=3, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(62, activation='softmax')\n",
    "])\n",
    "\n",
    "my_lenet_5_selu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lenet_5_selu_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_lenet5_emnist_model.h5\", save_best_only=True)\n",
    "  \n",
    "my_lenet_5_selu_model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y), callbacks=[early_stopping_cb, model_checkpoint_cb])\n",
    "\n",
    "my_lenet_5_selu_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lenet_5_selu_model.evaluate(hand_x, hand_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build #20220517\n",
    "\n",
    "testing wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 6)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 1, 120)         48120     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                5270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,126\n",
      "Trainable params: 66,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "lenet_5_selu_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=train_x[0].shape, padding='same'),\n",
    "    keras.layers.AveragePooling2D(),\n",
    "    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.AveragePooling2D(),\n",
    "    keras.layers.Conv2D(120, kernel_size=5, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.Flatten(),   \n",
    "    keras.layers.Dense(84, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(62, activation='softmax')\n",
    "])\n",
    "\n",
    "lenet_5_selu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17449/17449 [==============================] - 56s 3ms/step - loss: 0.5971 - accuracy: 0.8012 - val_loss: 0.4906 - val_accuracy: 0.8291 - _timestamp: 1652767874.0000 - _runtime: 2725.0000\n",
      "Epoch 2/100\n",
      "17449/17449 [==============================] - 55s 3ms/step - loss: 0.4583 - accuracy: 0.8372 - val_loss: 0.4541 - val_accuracy: 0.8366 - _timestamp: 1652767929.0000 - _runtime: 2780.0000\n",
      "Epoch 3/100\n",
      "17449/17449 [==============================] - 57s 3ms/step - loss: 0.4361 - accuracy: 0.8434 - val_loss: 0.4447 - val_accuracy: 0.8411 - _timestamp: 1652767986.0000 - _runtime: 2837.0000\n",
      "Epoch 4/100\n",
      "17449/17449 [==============================] - 55s 3ms/step - loss: 0.4242 - accuracy: 0.8466 - val_loss: 0.4344 - val_accuracy: 0.8452 - _timestamp: 1652768041.0000 - _runtime: 2892.0000\n",
      "Epoch 5/100\n",
      "17449/17449 [==============================] - 56s 3ms/step - loss: 0.4164 - accuracy: 0.8489 - val_loss: 0.4324 - val_accuracy: 0.8459 - _timestamp: 1652768097.0000 - _runtime: 2948.0000\n",
      "Epoch 6/100\n",
      "17449/17449 [==============================] - 56s 3ms/step - loss: 0.4102 - accuracy: 0.8503 - val_loss: 0.4333 - val_accuracy: 0.8447 - _timestamp: 1652768153.0000 - _runtime: 3004.0000\n",
      "Epoch 7/100\n",
      "17449/17449 [==============================] - 57s 3ms/step - loss: 0.4054 - accuracy: 0.8515 - val_loss: 0.4341 - val_accuracy: 0.8476 - _timestamp: 1652768210.0000 - _runtime: 3061.0000\n",
      "Epoch 8/100\n",
      "17449/17449 [==============================] - 57s 3ms/step - loss: 0.4019 - accuracy: 0.8526 - val_loss: 0.4303 - val_accuracy: 0.8467 - _timestamp: 1652768268.0000 - _runtime: 3119.0000\n",
      "Epoch 9/100\n",
      "17449/17449 [==============================] - 56s 3ms/step - loss: 0.3986 - accuracy: 0.8537 - val_loss: 0.4309 - val_accuracy: 0.8470 - _timestamp: 1652768324.0000 - _runtime: 3175.0000\n",
      "Epoch 10/100\n",
      "17449/17449 [==============================] - 54s 3ms/step - loss: 0.3958 - accuracy: 0.8546 - val_loss: 0.4438 - val_accuracy: 0.8440 - _timestamp: 1652768378.0000 - _runtime: 3229.0000\n",
      "Epoch 11/100\n",
      "17449/17449 [==============================] - 56s 3ms/step - loss: 0.3937 - accuracy: 0.8547 - val_loss: 0.4443 - val_accuracy: 0.8457 - _timestamp: 1652768434.0000 - _runtime: 3285.0000\n",
      "Epoch 12/100\n",
      "17449/17449 [==============================] - 56s 3ms/step - loss: 0.3908 - accuracy: 0.8556 - val_loss: 0.4351 - val_accuracy: 0.8462 - _timestamp: 1652768490.0000 - _runtime: 3341.0000\n",
      "Epoch 13/100\n",
      "17449/17449 [==============================] - 54s 3ms/step - loss: 0.3893 - accuracy: 0.8562 - val_loss: 0.4300 - val_accuracy: 0.8496 - _timestamp: 1652768544.0000 - _runtime: 3395.0000\n",
      "Epoch 14/100\n",
      "17449/17449 [==============================] - 55s 3ms/step - loss: 0.3877 - accuracy: 0.8569 - val_loss: 0.4364 - val_accuracy: 0.8444 - _timestamp: 1652768600.0000 - _runtime: 3451.0000\n",
      "Epoch 15/100\n",
      "17449/17449 [==============================] - 56s 3ms/step - loss: 0.3861 - accuracy: 0.8572 - val_loss: 0.4328 - val_accuracy: 0.8518 - _timestamp: 1652768655.0000 - _runtime: 3506.0000\n",
      "Epoch 16/100\n",
      "17449/17449 [==============================] - 54s 3ms/step - loss: 0.3841 - accuracy: 0.8576 - val_loss: 0.4291 - val_accuracy: 0.8503 - _timestamp: 1652768710.0000 - _runtime: 3561.0000\n",
      "Epoch 17/100\n",
      "17449/17449 [==============================] - 57s 3ms/step - loss: 0.3828 - accuracy: 0.8579 - val_loss: 0.4377 - val_accuracy: 0.8482 - _timestamp: 1652768767.0000 - _runtime: 3618.0000\n",
      "Epoch 18/100\n",
      "17449/17449 [==============================] - 56s 3ms/step - loss: 0.3812 - accuracy: 0.8588 - val_loss: 0.4379 - val_accuracy: 0.8472 - _timestamp: 1652768823.0000 - _runtime: 3674.0000\n",
      "Epoch 19/100\n",
      "17449/17449 [==============================] - 55s 3ms/step - loss: 0.3806 - accuracy: 0.8586 - val_loss: 0.4315 - val_accuracy: 0.8479 - _timestamp: 1652768877.0000 - _runtime: 3728.0000\n",
      "Epoch 20/100\n",
      "17449/17449 [==============================] - 56s 3ms/step - loss: 0.3800 - accuracy: 0.8588 - val_loss: 0.4432 - val_accuracy: 0.8491 - _timestamp: 1652768933.0000 - _runtime: 3784.0000\n",
      "Epoch 21/100\n",
      "17449/17449 [==============================] - 55s 3ms/step - loss: 0.3778 - accuracy: 0.8596 - val_loss: 0.4419 - val_accuracy: 0.8447 - _timestamp: 1652768988.0000 - _runtime: 3839.0000\n",
      "Epoch 22/100\n",
      "17449/17449 [==============================] - 56s 3ms/step - loss: 0.3767 - accuracy: 0.8596 - val_loss: 0.4472 - val_accuracy: 0.8417 - _timestamp: 1652769044.0000 - _runtime: 3895.0000\n",
      "Epoch 23/100\n",
      "17449/17449 [==============================] - 55s 3ms/step - loss: 0.3759 - accuracy: 0.8600 - val_loss: 0.4378 - val_accuracy: 0.8478 - _timestamp: 1652769100.0000 - _runtime: 3951.0000\n",
      "Epoch 24/100\n",
      "17449/17449 [==============================] - 55s 3ms/step - loss: 0.3754 - accuracy: 0.8604 - val_loss: 0.4467 - val_accuracy: 0.8511 - _timestamp: 1652769155.0000 - _runtime: 4006.0000\n",
      "Epoch 25/100\n",
      "17449/17449 [==============================] - 59s 3ms/step - loss: 0.3746 - accuracy: 0.8607 - val_loss: 0.4518 - val_accuracy: 0.8445 - _timestamp: 1652769213.0000 - _runtime: 4064.0000\n",
      "Epoch 26/100\n",
      "17449/17449 [==============================] - 57s 3ms/step - loss: 0.3734 - accuracy: 0.8609 - val_loss: 0.4494 - val_accuracy: 0.8429 - _timestamp: 1652769270.0000 - _runtime: 4121.0000\n",
      "3636/3636 [==============================] - 6s 2ms/step - loss: 0.4185 - accuracy: 0.8535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4185050129890442, 0.8534842729568481]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet_5_selu_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "lenet_5_selu_model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y), callbacks=[early_stopping_cb, WandbCallback()])\n",
    "\n",
    "lenet_5_selu_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_train(config_defaults=None):\n",
    "    # Set default values\n",
    "    config_defaults = {\n",
    "      'batch_size': 64,\n",
    "      'optimizer' : 'adam',\n",
    "      'learning_rate' : 0.01,\n",
    "      'n_first_node' : 6,\n",
    "      'n_first_kernel_size' : 5,\n",
    "      'n_second_node' : 16,\n",
    "      'n_second_kernel_size' : 5,\n",
    "      'n_third_node' : 120,\n",
    "      'n_third_kernel_size' : 5,\n",
    "    }\n",
    "    # Initialize wandb with a sample project name\n",
    "    wandb.init(config=config_defaults)  # this gets over-written in the Sweep\n",
    "\n",
    "    # initialize model\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(wandb.config.n_first_node, kernel_size=wandb.config.n_first_kernel_size, strides=1,  activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=train_x[0].shape, padding='same'))\n",
    "    model.add(keras.layers.AveragePooling2D())\n",
    "    model.add(keras.layers.Conv2D(wandb.config.n_second_node, kernel_size=wandb.config.n_second_kernel_size, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'))\n",
    "    model.add(keras.layers.AveragePooling2D())\n",
    "    model.add(keras.layers.Conv2D(wandb.config.n_third_node, kernel_size=wandb.config.n_third_kernel_size, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(84, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
    "    model.add(keras.layers.Dense(62, activation='softmax'))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    # Instantiate an optimizer to train the model.\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=wandb.config.learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "    # Instantiate a loss function.\n",
    "    # loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])\n",
    "    hist = model.fit(train_x, train_y, epochs=20, validation_data=(val_x, val_y), callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: ankq1lqk\n",
      "Sweep URL: https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s00xquzi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfirst_layer_node: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_Dense_layer: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_kernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_kernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_kernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsecond_layer_node: 120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220517_162208-s00xquzi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/s00xquzi\" target=\"_blank\">easy-sweep-1</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 12)        312       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 12)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 16)        4816      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 1, 60)          24060     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 60)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                5124      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                5270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,582\n",
      "Trainable params: 39,582\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/20\n",
      "17449/17449 [==============================] - 57s 3ms/step - loss: 0.5847 - accuracy: 0.8051 - val_loss: 0.4916 - val_accuracy: 0.8237 - _timestamp: 1652772198.0000 - _runtime: 70.0000\n",
      "Epoch 2/20\n",
      "17449/17449 [==============================] - 53s 3ms/step - loss: 0.4573 - accuracy: 0.8377 - val_loss: 0.4504 - val_accuracy: 0.8374 - _timestamp: 1652772251.0000 - _runtime: 123.0000\n",
      "Epoch 3/20\n",
      "17449/17449 [==============================] - 55s 3ms/step - loss: 0.4367 - accuracy: 0.8435 - val_loss: 0.4383 - val_accuracy: 0.8452 - _timestamp: 1652772306.0000 - _runtime: 178.0000\n",
      "Epoch 4/20\n",
      "17449/17449 [==============================] - 53s 3ms/step - loss: 0.4260 - accuracy: 0.8459 - val_loss: 0.4435 - val_accuracy: 0.8450 - _timestamp: 1652772360.0000 - _runtime: 232.0000\n",
      "Epoch 5/20\n",
      "17449/17449 [==============================] - 54s 3ms/step - loss: 0.4188 - accuracy: 0.8483 - val_loss: 0.4387 - val_accuracy: 0.8401 - _timestamp: 1652772413.0000 - _runtime: 285.0000\n",
      "Epoch 6/20\n",
      "17449/17449 [==============================] - 54s 3ms/step - loss: 0.4135 - accuracy: 0.8498 - val_loss: 0.4359 - val_accuracy: 0.8408 - _timestamp: 1652772467.0000 - _runtime: 339.0000\n",
      "Epoch 7/20\n",
      "17449/17449 [==============================] - 54s 3ms/step - loss: 0.4097 - accuracy: 0.8507 - val_loss: 0.4368 - val_accuracy: 0.8478 - _timestamp: 1652772521.0000 - _runtime: 393.0000\n",
      "Epoch 8/20\n",
      "17449/17449 [==============================] - 54s 3ms/step - loss: 0.4060 - accuracy: 0.8516 - val_loss: 0.4312 - val_accuracy: 0.8468 - _timestamp: 1652772576.0000 - _runtime: 448.0000\n",
      "Epoch 9/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.4039 - accuracy: 0.8524 - val_loss: 0.4331 - val_accuracy: 0.8443 - _timestamp: 1652772628.0000 - _runtime: 500.0000\n",
      "Epoch 10/20\n",
      "17449/17449 [==============================] - 55s 3ms/step - loss: 0.4013 - accuracy: 0.8531 - val_loss: 0.4271 - val_accuracy: 0.8510 - _timestamp: 1652772683.0000 - _runtime: 555.0000\n",
      "Epoch 11/20\n",
      "17449/17449 [==============================] - 53s 3ms/step - loss: 0.4001 - accuracy: 0.8534 - val_loss: 0.4236 - val_accuracy: 0.8483 - _timestamp: 1652772736.0000 - _runtime: 608.0000\n",
      "Epoch 12/20\n",
      "17449/17449 [==============================] - 54s 3ms/step - loss: 0.3976 - accuracy: 0.8542 - val_loss: 0.4370 - val_accuracy: 0.8437 - _timestamp: 1652772790.0000 - _runtime: 662.0000\n",
      "Epoch 13/20\n",
      "17449/17449 [==============================] - 53s 3ms/step - loss: 0.3961 - accuracy: 0.8546 - val_loss: 0.4195 - val_accuracy: 0.8522 - _timestamp: 1652772843.0000 - _runtime: 715.0000\n",
      "Epoch 14/20\n",
      "17449/17449 [==============================] - 54s 3ms/step - loss: 0.3954 - accuracy: 0.8547 - val_loss: 0.4360 - val_accuracy: 0.8460 - _timestamp: 1652772897.0000 - _runtime: 769.0000\n",
      "Epoch 15/20\n",
      "17449/17449 [==============================] - 54s 3ms/step - loss: 0.3943 - accuracy: 0.8550 - val_loss: 0.4259 - val_accuracy: 0.8497 - _timestamp: 1652772951.0000 - _runtime: 823.0000\n",
      "Epoch 16/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.3926 - accuracy: 0.8555 - val_loss: 0.4262 - val_accuracy: 0.8518 - _timestamp: 1652773003.0000 - _runtime: 875.0000\n",
      "Epoch 17/20\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.3911 - accuracy: 0.8555 - val_loss: 0.4341 - val_accuracy: 0.8451 - _timestamp: 1652773053.0000 - _runtime: 925.0000\n",
      "Epoch 18/20\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.3914 - accuracy: 0.8558 - val_loss: 0.4354 - val_accuracy: 0.8481 - _timestamp: 1652773103.0000 - _runtime: 975.0000\n",
      "Epoch 19/20\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.3901 - accuracy: 0.8559 - val_loss: 0.4435 - val_accuracy: 0.8367 - _timestamp: 1652773153.0000 - _runtime: 1025.0000\n",
      "Epoch 20/20\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.3895 - accuracy: 0.8560 - val_loss: 0.4255 - val_accuracy: 0.8485 - _timestamp: 1652773203.0000 - _runtime: 1075.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4291a92e59054160a9ed30fb86ee6a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.505 MB of 0.505 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▇▇▇▇▇████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▆▅▅▇▇▆█▇▆█▆▇█▆▇▄▇</td></tr><tr><td>val_loss</td><td>█▄▃▃▃▃▃▂▂▂▁▃▁▃▂▂▂▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.85603</td></tr><tr><td>best_epoch</td><td>12</td></tr><tr><td>best_val_loss</td><td>0.41951</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.38952</td></tr><tr><td>val_accuracy</td><td>0.84848</td></tr><tr><td>val_loss</td><td>0.42555</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">easy-sweep-1</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/s00xquzi\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/s00xquzi</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220517_162208-s00xquzi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v2ndhp4a with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfirst_layer_node: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_Dense_layer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_kernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 120\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsecond_layer_node: 120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220517_164016-v2ndhp4a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/v2ndhp4a\" target=\"_blank\">noble-sweep-2</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 6)         60        \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 6)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 120)         17400     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1080)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                90804     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                5270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,950\n",
      "Trainable params: 115,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.6519 - accuracy: 0.7892 - val_loss: 0.5245 - val_accuracy: 0.8172 - _timestamp: 1652773280.0000 - _runtime: 64.0000\n",
      "Epoch 2/20\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.5001 - accuracy: 0.8261 - val_loss: 0.4905 - val_accuracy: 0.8265 - _timestamp: 1652773331.0000 - _runtime: 115.0000\n",
      "Epoch 3/20\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4762 - accuracy: 0.8326 - val_loss: 0.4831 - val_accuracy: 0.8290 - _timestamp: 1652773382.0000 - _runtime: 166.0000\n",
      "Epoch 4/20\n",
      "17449/17449 [==============================] - 50s 3ms/step - loss: 0.4624 - accuracy: 0.8362 - val_loss: 0.4738 - val_accuracy: 0.8352 - _timestamp: 1652773432.0000 - _runtime: 216.0000\n",
      "Epoch 5/20\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4536 - accuracy: 0.8384 - val_loss: 0.4775 - val_accuracy: 0.8341 - _timestamp: 1652773483.0000 - _runtime: 267.0000\n",
      "Epoch 6/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.4463 - accuracy: 0.8414 - val_loss: 0.4699 - val_accuracy: 0.8326 - _timestamp: 1652773536.0000 - _runtime: 320.0000\n",
      "Epoch 7/20\n",
      "17449/17449 [==============================] - 55s 3ms/step - loss: 0.4423 - accuracy: 0.8418 - val_loss: 0.4535 - val_accuracy: 0.8400 - _timestamp: 1652773590.0000 - _runtime: 374.0000\n",
      "Epoch 8/20\n",
      "17449/17449 [==============================] - 53s 3ms/step - loss: 0.4376 - accuracy: 0.8433 - val_loss: 0.4581 - val_accuracy: 0.8401 - _timestamp: 1652773644.0000 - _runtime: 428.0000\n",
      "Epoch 9/20\n",
      "17449/17449 [==============================] - 55s 3ms/step - loss: 0.4338 - accuracy: 0.8441 - val_loss: 0.4564 - val_accuracy: 0.8377 - _timestamp: 1652773699.0000 - _runtime: 483.0000\n",
      "Epoch 10/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.4314 - accuracy: 0.8453 - val_loss: 0.4444 - val_accuracy: 0.8451 - _timestamp: 1652773751.0000 - _runtime: 535.0000\n",
      "Epoch 11/20\n",
      "17449/17449 [==============================] - 54s 3ms/step - loss: 0.4287 - accuracy: 0.8457 - val_loss: 0.4379 - val_accuracy: 0.8437 - _timestamp: 1652773805.0000 - _runtime: 589.0000\n",
      "Epoch 12/20\n",
      "17449/17449 [==============================] - 53s 3ms/step - loss: 0.4259 - accuracy: 0.8464 - val_loss: 0.4566 - val_accuracy: 0.8392 - _timestamp: 1652773858.0000 - _runtime: 642.0000\n",
      "Epoch 13/20\n",
      "17449/17449 [==============================] - 54s 3ms/step - loss: 0.4247 - accuracy: 0.8472 - val_loss: 0.4627 - val_accuracy: 0.8361 - _timestamp: 1652773912.0000 - _runtime: 696.0000\n",
      "Epoch 14/20\n",
      "17449/17449 [==============================] - 53s 3ms/step - loss: 0.4230 - accuracy: 0.8475 - val_loss: 0.4474 - val_accuracy: 0.8428 - _timestamp: 1652773965.0000 - _runtime: 749.0000\n",
      "Epoch 15/20\n",
      "17449/17449 [==============================] - 53s 3ms/step - loss: 0.4213 - accuracy: 0.8479 - val_loss: 0.4632 - val_accuracy: 0.8425 - _timestamp: 1652774019.0000 - _runtime: 803.0000\n",
      "Epoch 16/20\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4199 - accuracy: 0.8480 - val_loss: 0.4605 - val_accuracy: 0.8409 - _timestamp: 1652774069.0000 - _runtime: 853.0000\n",
      "Epoch 17/20\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4188 - accuracy: 0.8483 - val_loss: 0.4516 - val_accuracy: 0.8382 - _timestamp: 1652774121.0000 - _runtime: 905.0000\n",
      "Epoch 18/20\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4175 - accuracy: 0.8492 - val_loss: 0.4456 - val_accuracy: 0.8451 - _timestamp: 1652774171.0000 - _runtime: 955.0000\n",
      "Epoch 19/20\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4163 - accuracy: 0.8491 - val_loss: 0.4581 - val_accuracy: 0.8422 - _timestamp: 1652774223.0000 - _runtime: 1007.0000\n",
      "Epoch 20/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.4148 - accuracy: 0.8497 - val_loss: 0.4505 - val_accuracy: 0.8418 - _timestamp: 1652774275.0000 - _runtime: 1059.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105310697d204dae8f815ddc4668c770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.379 MB of 1.379 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▆▇▇▇▇▇▇██████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▆▅▅▇▇▆██▇▆▇▇▇▆█▇▇</td></tr><tr><td>val_loss</td><td>█▅▅▄▄▄▂▃▂▂▁▃▃▂▃▃▂▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.84965</td></tr><tr><td>best_epoch</td><td>10</td></tr><tr><td>best_val_loss</td><td>0.43794</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.41485</td></tr><tr><td>val_accuracy</td><td>0.84181</td></tr><tr><td>val_loss</td><td>0.45055</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">noble-sweep-2</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/v2ndhp4a\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/v2ndhp4a</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220517_164016-v2ndhp4a\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f8s1m95r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfirst_layer_node: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_Dense_layer: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_kernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 120\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsecond_layer_node: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220517_165811-f8s1m95r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/f8s1m95r\" target=\"_blank\">logical-sweep-3</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 12)        312       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 12)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 16)        1744      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 6, 6, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 120)         17400     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1920)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                161364    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                5270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 186,090\n",
      "Trainable params: 186,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ef73dc4f924592923ef37939931d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">logical-sweep-3</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/f8s1m95r\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/f8s1m95r</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220517_165811-f8s1m95r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run f8s1m95r errored: InternalError()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x772s0mz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfirst_layer_node: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_Dense_layer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_kernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_kernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsecond_layer_node: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220517_165838-x772s0mz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/x772s0mz\" target=\"_blank\">grateful-sweep-4</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 12)        312       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 12)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 16)        4816      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 60)          8700      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 540)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                45444     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                5270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,542\n",
      "Trainable params: 64,542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5565e5ca4fd247a7b33afcb05b057c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">grateful-sweep-4</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/x772s0mz\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/x772s0mz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220517_165838-x772s0mz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run x772s0mz errored: InternalError()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d9gex14g with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfirst_layer_node: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_Dense_layer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_kernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_kernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_kernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 120\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsecond_layer_node: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220517_165916-d9gex14g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/d9gex14g\" target=\"_blank\">rosy-sweep-5</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 12)        312       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 12)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 32)        9632      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 32)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 1, 120)         96120     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                5270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,498\n",
      "Trainable params: 121,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55d48aa3db5431ba5f5177fc2a3960a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rosy-sweep-5</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/d9gex14g\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/d9gex14g</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220517_165916-d9gex14g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run d9gex14g errored: InternalError()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: refvs7ln with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfirst_layer_node: 800\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_Dense_layer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_kernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_kernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsecond_layer_node: 120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220517_165953-refvs7ln</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/refvs7ln\" target=\"_blank\">sandy-sweep-6</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 6)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 32)        4832      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 32)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 60)          17340     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 540)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                45444     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                5270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,042\n",
      "Trainable params: 73,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6bfa79eb77c458b801e3ff541247876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sandy-sweep-6</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/refvs7ln\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/refvs7ln</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220517_165953-refvs7ln\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run refvs7ln errored: InternalError()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: txjw17nm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfirst_layer_node: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_Dense_layer: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_kernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 120\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsecond_layer_node: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220517_170031-txjw17nm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/txjw17nm\" target=\"_blank\">eager-sweep-7</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 12)        120       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 12)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 16)        4816      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 120)         17400     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1080)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                90804     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                5270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,410\n",
      "Trainable params: 118,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69129c21a7d24e459bd41a6dd523eeab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">eager-sweep-7</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/txjw17nm\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/txjw17nm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220517_170031-txjw17nm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run txjw17nm errored: InternalError()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: of12gljh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfirst_layer_node: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_Dense_layer: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_kernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_kernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsecond_layer_node: 120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220517_170108-of12gljh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/of12gljh\" target=\"_blank\">icy-sweep-8</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 6)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 16)        880       \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 6, 6, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 2, 60)          24060     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 240)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                20244     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                5270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,610\n",
      "Trainable params: 50,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88343fadad3647ce984b99e7abbefe72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">icy-sweep-8</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/of12gljh\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/of12gljh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220517_170108-of12gljh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run of12gljh errored: InternalError()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eobwhmr3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfirst_layer_node: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_Dense_layer: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_kernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_kernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 120\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsecond_layer_node: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220517_170146-eobwhmr3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/eobwhmr3\" target=\"_blank\">dandy-sweep-9</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 6)         60        \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 6)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 1, 120)         48120     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                5270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,030\n",
      "Trainable params: 66,030\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf649a6c35049879cfafa4e3826cf5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dandy-sweep-9</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/eobwhmr3\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/eobwhmr3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220517_170146-eobwhmr3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run eobwhmr3 errored: InternalError()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i1yebecq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfirst_layer_node: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_Dense_layer: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_first_node: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_second_node: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_kernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_third_node: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsecond_layer_node: 120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220517_170219-i1yebecq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/i1yebecq\" target=\"_blank\">magic-sweep-10</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/sweeps/ankq1lqk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 6)         60        \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 6)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 32)        1760      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 6, 6, 32)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 2, 60)          48060     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 240)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                20244     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                5270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 75,394\n",
      "Trainable params: 75,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "17449/17449 [==============================] - 53s 3ms/step - loss: 0.5874 - accuracy: 0.8044 - val_loss: 0.4948 - val_accuracy: 0.8256 - _timestamp: 1652774604.0000 - _runtime: 65.0000\n",
      "Epoch 2/20\n",
      "17449/17449 [==============================] - 54s 3ms/step - loss: 0.4557 - accuracy: 0.8385 - val_loss: 0.4569 - val_accuracy: 0.8393 - _timestamp: 1652774658.0000 - _runtime: 119.0000\n",
      "Epoch 3/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.4349 - accuracy: 0.8439 - val_loss: 0.4484 - val_accuracy: 0.8442 - _timestamp: 1652774710.0000 - _runtime: 171.0000\n",
      "Epoch 4/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.4245 - accuracy: 0.8470 - val_loss: 0.4522 - val_accuracy: 0.8422 - _timestamp: 1652774762.0000 - _runtime: 223.0000\n",
      "Epoch 5/20\n",
      "17449/17449 [==============================] - 53s 3ms/step - loss: 0.4175 - accuracy: 0.8487 - val_loss: 0.4393 - val_accuracy: 0.8454 - _timestamp: 1652774815.0000 - _runtime: 276.0000\n",
      "Epoch 6/20\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4129 - accuracy: 0.8501 - val_loss: 0.4403 - val_accuracy: 0.8431 - _timestamp: 1652774866.0000 - _runtime: 327.0000\n",
      "Epoch 7/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.4077 - accuracy: 0.8515 - val_loss: 0.4361 - val_accuracy: 0.8420 - _timestamp: 1652774918.0000 - _runtime: 379.0000\n",
      "Epoch 8/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.4052 - accuracy: 0.8519 - val_loss: 0.4365 - val_accuracy: 0.8457 - _timestamp: 1652774970.0000 - _runtime: 431.0000\n",
      "Epoch 9/20\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.4022 - accuracy: 0.8532 - val_loss: 0.4273 - val_accuracy: 0.8493 - _timestamp: 1652775022.0000 - _runtime: 483.0000\n",
      "Epoch 10/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.3991 - accuracy: 0.8538 - val_loss: 0.4369 - val_accuracy: 0.8457 - _timestamp: 1652775074.0000 - _runtime: 535.0000\n",
      "Epoch 11/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.3967 - accuracy: 0.8546 - val_loss: 0.4395 - val_accuracy: 0.8438 - _timestamp: 1652775126.0000 - _runtime: 587.0000\n",
      "Epoch 12/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.3947 - accuracy: 0.8550 - val_loss: 0.4328 - val_accuracy: 0.8458 - _timestamp: 1652775178.0000 - _runtime: 639.0000\n",
      "Epoch 13/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.3931 - accuracy: 0.8556 - val_loss: 0.4357 - val_accuracy: 0.8466 - _timestamp: 1652775230.0000 - _runtime: 691.0000\n",
      "Epoch 14/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.3910 - accuracy: 0.8559 - val_loss: 0.4311 - val_accuracy: 0.8468 - _timestamp: 1652775282.0000 - _runtime: 743.0000\n",
      "Epoch 15/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.3898 - accuracy: 0.8569 - val_loss: 0.4491 - val_accuracy: 0.8455 - _timestamp: 1652775333.0000 - _runtime: 794.0000\n",
      "Epoch 16/20\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3888 - accuracy: 0.8569 - val_loss: 0.4320 - val_accuracy: 0.8466 - _timestamp: 1652775384.0000 - _runtime: 845.0000\n",
      "Epoch 17/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.3870 - accuracy: 0.8573 - val_loss: 0.4389 - val_accuracy: 0.8492 - _timestamp: 1652775437.0000 - _runtime: 898.0000\n",
      "Epoch 18/20\n",
      "17449/17449 [==============================] - 51s 3ms/step - loss: 0.3861 - accuracy: 0.8575 - val_loss: 0.4457 - val_accuracy: 0.8479 - _timestamp: 1652775487.0000 - _runtime: 948.0000\n",
      "Epoch 19/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.3853 - accuracy: 0.8575 - val_loss: 0.4398 - val_accuracy: 0.8518 - _timestamp: 1652775540.0000 - _runtime: 1001.0000\n",
      "Epoch 20/20\n",
      "17449/17449 [==============================] - 52s 3ms/step - loss: 0.3842 - accuracy: 0.8580 - val_loss: 0.4404 - val_accuracy: 0.8510 - _timestamp: 1652775591.0000 - _runtime: 1052.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45be9345f9a44e89eb135e67849149e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.916 MB of 0.916 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▇▇▇▇▇▇▇██████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▅▆▆▅▆▇▆▆▆▇▇▆▇▇▇██</td></tr><tr><td>val_loss</td><td>█▄▃▄▂▂▂▂▁▂▂▂▂▁▃▁▂▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.858</td></tr><tr><td>best_epoch</td><td>8</td></tr><tr><td>best_val_loss</td><td>0.42731</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.38418</td></tr><tr><td>val_accuracy</td><td>0.85095</td></tr><tr><td>val_loss</td><td>0.44041</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">magic-sweep-10</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/uncategorized/runs/i1yebecq\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/uncategorized/runs/i1yebecq</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220517_170219-i1yebecq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sweep_config = {\n",
    "  'method': 'random', \n",
    "  'parameters': {\n",
    "      'learning_rate':{\n",
    "          'values' : [0.05, 0.01, 0.005]\n",
    "      },\n",
    "      'n_first_node' : {\n",
    "          'values' : [6, 12]\n",
    "      },\n",
    "      'n_second_node' : {\n",
    "          'values' : [16, 32]\n",
    "      },\n",
    "      'n_third_node' : {\n",
    "          'values' : [120, 60]\n",
    "      },\n",
    "      'n_first_kernel_size' : {\n",
    "          'values' : [5, 3]\n",
    "      },\n",
    "      'n_second_kernel_size' : {\n",
    "          'values' : [5, 3]\n",
    "      },\n",
    "      'n_third_kernel_size' : {\n",
    "          'values' : [5, 3]\n",
    "      }\n",
    "  }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config)\n",
    "\n",
    "wandb.agent(sweep_id, function=sweep_train, count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING AND SAVING MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_test_model = keras.models.load_model(\"my_lenet5_emnist_model_20220515.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3636/3636 [==============================] - 7s 2ms/step - loss: 0.3567 - accuracy: 0.8709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35671404004096985, 0.8708842992782593]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_test_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save current model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.time()\n",
    "now = time.localtime(now)\n",
    "my_lenet_5_selu_model.save(\"my_lenet5_emnist_model_%2d%02d%02d.h5\" %(now.tm_year, now.tm_mon, now.tm_mday), save_format=\"h5\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cca9558bc5ad879ec93cc030b157d75f18267527c60932cecaace349eef54dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
