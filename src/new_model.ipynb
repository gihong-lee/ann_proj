{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = \"../data\"\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(f'{data_dir_path}/emnist-byclass-train.csv', header=None)\n",
    "test_df = pd.read_csv(f\"{data_dir_path}/emnist-byclass-test.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_csv_to_numpy(data, sorting = False): # pandas 통해 읽은 csv data numpy 형태로 변경\n",
    "  if sorting == True:\n",
    "    data = data.sort_values(by=[0], axis=0)\n",
    "\n",
    "  label = np.array(data[0]) # csv file 에서 0번째 colum은 index임\n",
    "  only_data = np.array(data.drop([0], axis = 1)).reshape((-1, 28, 28, 1)) # csv file에서 0번 째 colum 탈락 -> data만 남게 됨\n",
    "  # only_data = tf.convert_to_tensor(only_data, dtype=tf.float32)\n",
    "  return only_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train  = convert_data_csv_to_numpy(train_df)\n",
    "X_test, y_test  = convert_data_csv_to_numpy(test_df)\n",
    "\n",
    "train_df = None\n",
    "test_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "X_train = np.repeat(X_train, 3, axis=-1)\n",
    "X_test = np.repeat(X_test, 3, axis=-1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train = tf.image.resize(X_train, [32,32])\n",
    "# X_val = tf.image.resize(X_val, [32,32])\n",
    "# X_test = tf.image.resize(X_test, [32,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape,X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # expand new axis, channel axis \n",
    "# X_train = np.expand_dims(X_train, axis=-1)\n",
    "# X_val = np.expand_dims(X_val, axis=-1)\n",
    "# X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# # [optional]: we may need 3 channel (instead of 1)\n",
    "# X_train = np.repeat(X_train, 3, axis=-1)\n",
    "# X_val = np.repeat(X_val, 3, axis=-1)\n",
    "# X_test = np.repeat(X_test, 3, axis=-1)\n",
    "\n",
    "# # it's always better to normalize \n",
    "# X_train = X_train.astype('float32') / 255\n",
    "# X_val = X_val.astype('float32') / 255\n",
    "# X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# # resize the input shape , i.e. old shape: 28, new shape: 32\n",
    "# X_train = tf.image.resize(X_train, [32,32]) # if we want to resize \n",
    "# X_val = tf.image.resize(X_val, [32,32]) # if we want to resize \n",
    "# X_test = tf.image.resize(X_test, [32,32]) # if we want to resize \n",
    "\n",
    "# # one hot \n",
    "# y_train = tf.keras.utils.to_categorical(y_train , num_classes=10)\n",
    "# y_val = tf.keras.utils.to_categorical(y_val , num_classes=10)\n",
    "# y_test = tf.keras.utils.to_categorical(y_test , num_classes=10)\n",
    "\n",
    "# print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(keras.models.Model):\n",
    "    \"\"\"\n",
    "    A standard resnet block.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int, down_sample=False):\n",
    "        \"\"\"\n",
    "        channels: same as number of convolution kernels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.__channels = channels\n",
    "        self.__down_sample = down_sample\n",
    "        self.__strides = [2, 1] if down_sample else [1, 1]\n",
    "\n",
    "        KERNEL_SIZE = (3, 3)\n",
    "        # use He initialization, instead of Xavier (a.k.a 'glorot_uniform' in Keras), as suggested in [2]\n",
    "        INIT_SCHEME = \"he_normal\"\n",
    "\n",
    "        self.conv_1 = keras.layers.Conv2D(self.__channels, strides=self.__strides[0],\n",
    "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
    "        self.bn_1 = keras.layers.BatchNormalization()\n",
    "        self.conv_2 = keras.layers.Conv2D(self.__channels, strides=self.__strides[1],\n",
    "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
    "        self.bn_2 = keras.layers.BatchNormalization()\n",
    "        self.merge = keras.layers.Add()\n",
    "\n",
    "        if self.__down_sample:\n",
    "            # perform down sampling using stride of 2, according to [1].\n",
    "            self.res_conv = keras.layers.Conv2D(\n",
    "                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n",
    "            self.res_bn = keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        res = inputs\n",
    "\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.bn_1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x)\n",
    "\n",
    "        if self.__down_sample:\n",
    "            res = self.res_conv(res)\n",
    "            res = self.res_bn(res)\n",
    "\n",
    "        # if not perform down sample, then add a shortcut directly\n",
    "        x = self.merge([x, res])\n",
    "        out = tf.nn.relu(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "# class ResNet18(keras.models.Model):\n",
    "\n",
    "#     def __init__(self, num_classes, **kwargs):\n",
    "#         \"\"\"\n",
    "#             num_classes: number of classes in specific classification task.\n",
    "#         \"\"\"\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.conv_1 = keras.layers.Conv2D(64, (7, 7), strides=2,\n",
    "#                              padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "#         self.init_bn = keras.layers.BatchNormalization()\n",
    "#         self.pool_2 = keras.layers.MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
    "#         self.res_1_1 = ResnetBlock(64)\n",
    "#         self.res_1_2 = ResnetBlock(64)\n",
    "#         self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
    "#         self.res_2_2 = ResnetBlock(128)\n",
    "#         self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
    "#         self.res_3_2 = ResnetBlock(256)\n",
    "#         self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
    "#         self.res_4_2 = ResnetBlock(512)\n",
    "#         self.avg_pool = keras.layers.GlobalAveragePooling2D()\n",
    "#         self.flat = keras.layers.Flatten()\n",
    "#         self.fc = keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         out = self.conv_1(inputs)\n",
    "#         out = self.init_bn(out)\n",
    "#         out = tf.nn.relu(out)\n",
    "#         out = self.pool_2(out)\n",
    "#         for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
    "#             out = res_block(out)\n",
    "#         out = self.avg_pool(out)\n",
    "#         out = self.flat(out)\n",
    "#         out = self.fc(out)\n",
    "#         return out\n",
    "\n",
    "\n",
    "# resnet_model = ResNet18(62)\n",
    "# resnet_model.build(input_shape = (None,28,28,1))\n",
    "# #use categorical_crossentropy since the label is one-hot encoded\n",
    "\n",
    "# # from keras.optimizers import SGD\n",
    "# # opt = SGD(learning_rate=0.1,momentum=0.9,decay = 1e-04) #parameters suggested by He [1]\n",
    "# resnet_model.compile(optimizer = \"adam\",loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
    "# resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = tf.keras.Input(shape=(32,32,3))\n",
    "# efnet = tf.keras.applications.ResNet50(weights='imagenet',\n",
    "#                                              include_top = False, \n",
    "#                                              input_tensor = input)\n",
    "# # Now that we apply global max pooling.\n",
    "\n",
    "# # Finally, we add a classification layer.\n",
    "# number_output = tf.keras.layers.Dense(10, activation='softmax', use_bias=True)()\n",
    "# upper_output = tf.keras.layers.Dense(26,  activation='softmax', use_bias=True)()\n",
    "# lower_output = tf.keras.layers.Dense(26,  activation='softmax', use_bias=True)()\n",
    "\n",
    "# # bind all\n",
    "# func_model = tf.keras.Model(efnet.input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"res_base_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_34 (Conv2D)          multiple                  3200      \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  multiple                 256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " resnet_block_14 (ResnetBloc  multiple                 74368     \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_15 (ResnetBloc  multiple                 74368     \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_16 (ResnetBloc  multiple                 231296    \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_17 (ResnetBloc  multiple                 296192    \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_18 (ResnetBloc  multiple                 921344    \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_19 (ResnetBloc  multiple                 1182208   \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_20 (ResnetBloc  multiple                 3677696   \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_21 (ResnetBloc  multiple                 4723712   \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_22 (ResnetBloc  multiple                 3677696   \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_23 (ResnetBloc  multiple                 4723712   \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_24 (ResnetBloc  multiple                 4723712   \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_25 (ResnetBloc  multiple                 3677696   \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_26 (ResnetBloc  multiple                 4723712   \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_27 (ResnetBloc  multiple                 4723712   \n",
      " k)                                                              \n",
      "                                                                 \n",
      " global_average_pooling2d_3   multiple                 0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " global_average_pooling2d_4   multiple                 0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " global_average_pooling2d_5   multiple                 0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  31806     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,466,686\n",
      "Trainable params: 37,442,750\n",
      "Non-trainable params: 23,936\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class ResBaseModel(keras.models.Model):\n",
    "\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        \"\"\"\n",
    "            num_classes: number of classes in specific classification task.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv_1 = keras.layers.Conv2D(64, (7, 7), strides=2,\n",
    "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "        self.init_bn = keras.layers.BatchNormalization()\n",
    "        self.pool_2 = keras.layers.MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
    "        self.res_1_1 = ResnetBlock(64)\n",
    "        self.res_1_2 = ResnetBlock(64)\n",
    "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
    "        self.res_2_2 = ResnetBlock(128)\n",
    "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
    "        self.res_3_2 = ResnetBlock(256)\n",
    "        \n",
    "        self.res_num_1 = ResnetBlock(512, down_sample=True)\n",
    "        self.res_num_2 = ResnetBlock(512)\n",
    "\n",
    "\n",
    "        self.res_upper_1 = ResnetBlock(512, down_sample=True)\n",
    "        self.res_upper_2 = ResnetBlock(512)        \n",
    "        self.res_upper_3 = ResnetBlock(512)        \n",
    "\n",
    "\n",
    "        self.res_lower_1 = ResnetBlock(512, down_sample=True)\n",
    "        self.res_lower_2 = ResnetBlock(512)\n",
    "        self.res_lower_3 = ResnetBlock(512)\n",
    "\n",
    "        self.num_avg_pool = keras.layers.GlobalAveragePooling2D()\n",
    "        self.upper_avg_pool = keras.layers.GlobalAveragePooling2D()\n",
    "        self.lower_avg_pool = keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "        self.num_flat = keras.layers.Flatten()\n",
    "        self.upper_flat = keras.layers.Flatten()\n",
    "        self.lower_flat = keras.layers.Flatten()\n",
    "        self.fc = keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        out = self.conv_1(inputs)\n",
    "        out = self.init_bn(out)\n",
    "        out = tf.nn.relu(out)\n",
    "        out = self.pool_2(out)\n",
    "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2]:\n",
    "            out = res_block(out)\n",
    "        \n",
    "        num_out = self.res_num_1(out)\n",
    "        num_out = self.res_num_2(num_out)\n",
    "        num_out = self.num_avg_pool(num_out)\n",
    "        num_out = self.num_flat(num_out)\n",
    "\n",
    "        upper_out = self.res_upper_1(out)\n",
    "        upper_out = self.res_upper_2(upper_out)\n",
    "        upper_out = self.res_upper_3(upper_out)\n",
    "        upper_out = self.upper_avg_pool(upper_out)\n",
    "        upper_out = self.upper_flat(upper_out)\n",
    "\n",
    "        lower_out = self.res_lower_1(out)\n",
    "        lower_out = self.res_lower_2(lower_out)\n",
    "        lower_out = self.res_lower_3(lower_out)\n",
    "        lower_out = self.lower_avg_pool(lower_out)\n",
    "        lower_out = self.lower_flat(lower_out)\n",
    "\n",
    "        out = keras.layers.Add()([num_out, upper_out, lower_out])\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "resnet_model = ResBaseModel(62)\n",
    "resnet_model.build(input_shape = (None,28,28,1))\n",
    "#use categorical_crossentropy since the label is one-hot encoded\n",
    "\n",
    "# from keras.optimizers import SGD\n",
    "# opt = SGD(learning_rate=0.1,momentum=0.9,decay = 1e-04) #parameters suggested by He [1]\n",
    "resnet_model.compile(optimizer = \"adam\",loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "\n",
    "es = EarlyStopping(patience= 8, restore_best_weights=True)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"new_model.h5\", save_best_only=True)\n",
    "\n",
    "batch_size = 256\n",
    "#I did not use cross validation, so the validate performance is not accurate.\n",
    "STEPS = len(X_train) / 256\n",
    "\n",
    "history = resnet_model.fit(aug.flow(X_train,y_train,batch_size = batch_size), \n",
    "      steps_per_epoch=STEPS, \n",
    "      batch_size = batch_size, \n",
    "      epochs=50, \n",
    "      validation_data=(X_train, y_train),\n",
    "      callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Resizing(height = 32, width = 32, input_shape = [28, 28, 3])\n",
    "\n",
    "input = tf.keras.Input(shape=(32,32,3))\n",
    "efnet = tf.keras.applications.ResNet50(weights='imagenet',\n",
    "                                             include_top = False, \n",
    "                                             input_tensor = input)\n",
    "# Now that we apply global max pooling.\n",
    "gap = tf.keras.layers.GlobalMaxPooling2D()\n",
    "\n",
    "# Finally, we add a classification layer.\n",
    "output = tf.keras.layers.Dense(62, activation='softmax', use_bias=True)\n",
    "\n",
    "# bind all\n",
    "func_model = keras.models.Sequential()\n",
    "func_model.add(input_layer)\n",
    "func_model.add(efnet)\n",
    "func_model.add(gap)\n",
    "func_model.add(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "res50_checkpoint = keras.callbacks.ModelCheckpoint(\"res50.h5\", save_best_only=True)\n",
    "es = EarlyStopping(patience= 8, restore_best_weights=True)\n",
    "\n",
    "# func_model.compile(\n",
    "#           loss  = 'sparse_categorical_crossentropy',\n",
    "#           metrics = tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "#           optimizer = tf.keras.optimizers.Adam())\n",
    "\n",
    "func_model.compile(optimizer='adam',\n",
    "          loss='sparse_categorical_crossentropy', \n",
    "          metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model.fit(X_train, y_train, epochs=5, verbose = 2,\n",
    "          callbacks=[es, res50_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cca9558bc5ad879ec93cc030b157d75f18267527c60932cecaace349eef54dd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
