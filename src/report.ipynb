{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DaGNky6bH6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf8c0c2-0769-4367-d074-34089f597521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU found\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import datasets, layers, models, losses, Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, Input, BatchNormalization, Dropout\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
        "\n",
        "if tf.test.gpu_device_name():\n",
        "    print('GPU found')\n",
        "else:\n",
        "    print(\"No GPU found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2u0ayo7bH60"
      },
      "source": [
        "Data Preparing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vcr9a3cmbH62"
      },
      "outputs": [],
      "source": [
        "def convert_data_csv_to_numpy(data, sorting = False): # pandas 통해 읽은 csv data numpy 형태로 변경\n",
        "  if sorting == True:\n",
        "    data = data.sort_values(by=[0], axis=0)\n",
        "\n",
        "  label = np.array(data[0]) # csv file 에서 0번째 colum은 index임\n",
        "  only_data = np.array(data.drop([0], axis = 1)) # csv file에서 0번 째 colum 탈락 -> data만 남게 됨\n",
        "  # only_data = tf.convert_to_tensor(only_data, dtype=tf.float32)\n",
        "  only_data = tf.keras.utils.normalize(only_data, axis=-1, order=2).reshape((-1, 28, 28, 1)) #data nomalize & reshaping\n",
        "  return only_data, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWuRDGQebH65"
      },
      "outputs": [],
      "source": [
        "data_dir_path = \"../data\"\n",
        "\n",
        "train_df = pd.read_csv(f'{data_dir_path}/emnist-byclass-train.csv', header=None)\n",
        "test_df = pd.read_csv(f\"{data_dir_path}/emnist-byclass-test.csv\", header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFVUrw-sbH66"
      },
      "outputs": [],
      "source": [
        "X_train, y_train  = convert_data_csv_to_numpy(train_df)\n",
        "X_test, y_test  = convert_data_csv_to_numpy(test_df)\n",
        "\n",
        "train_df = None\n",
        "test_df = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbhBO24wbH68"
      },
      "outputs": [],
      "source": [
        "# add channel\n",
        "# channel = 3\n",
        "# X_train_3 = np.repeat(X_train, channel, axis=-1)\n",
        "# X_test_3 = np.repeat(X_test, channel, axis=-1)\n",
        "# y_test_3 = y_test\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "# X_train_3, X_val_3, y_train_3, y_val_3 = train_test_split(X_train_3, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUxZ18-nbH69"
      },
      "outputs": [],
      "source": [
        "# data resizing\n",
        "# X_train = tf.image.resize(X_train, [32,32])\n",
        "# X_val = tf.image.resize(X_val, [32,32])\n",
        "# X_test = tf.image.resize(X_test, [32,32])\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hTxA6aTbH6-"
      },
      "outputs": [],
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_val = tf.keras.utils.to_categorical(y_val)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_UV5mPIbH6_"
      },
      "outputs": [],
      "source": [
        "print(y_train.shape,y_val.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNYMTOLtbH7A"
      },
      "outputs": [],
      "source": [
        "def show_data_scheme(data, label, row = 4, col = 5, i = 1): # data 어떻게 생겼는지 plot\n",
        "  label_value_list = []\n",
        "  for i in range(62):\n",
        "    if i <=9:\n",
        "      label_value_list.append(f'{i}')\n",
        "    elif 10<=i<=35:\n",
        "      label_value_list.append(f'{chr(i+55)}')\n",
        "    else:\n",
        "      label_value_list.append(f'{chr(i+61)}')\n",
        "\n",
        "  plt.figure(figsize = (11, 8))\n",
        "  for r in range(row):\n",
        "    for c in range(col):\n",
        "      plt.subplot(row, col, i)\n",
        "      plt.imshow(data[i,...,0], 'gray')\n",
        "      plt.axis('off')\n",
        "      plt.title(f'{label_value_list[label[i]]}')\n",
        "      i+=1\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lDN17WUbH7B"
      },
      "outputs": [],
      "source": [
        "show_data_scheme(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CHG1hCCbH7B"
      },
      "source": [
        "3. Base line accuracy 측정 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PwmEb8PbH7C"
      },
      "source": [
        "3 - A. Lenet5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDxz1TiTbH7D"
      },
      "outputs": [],
      "source": [
        "lenet_5_model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation='tanh', input_shape=X_train[0].shape, padding='same'),\n",
        "    keras.layers.AveragePooling2D(),\n",
        "    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation='tanh', padding='valid'),\n",
        "    keras.layers.AveragePooling2D(),\n",
        "    keras.layers.Conv2D(120, kernel_size=5, strides=1, activation='tanh', padding='valid'),\n",
        "    keras.layers.Flatten(),   \n",
        "    keras.layers.Dense(84, activation='tanh'),\n",
        "    keras.layers.Dense(62, activation='softmax')\n",
        "])\n",
        "lenet_5_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lPM9ILIbH7E"
      },
      "outputs": [],
      "source": [
        "lenet_5_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "# model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_lenet5_emnist_model.h5\", save_best_only=True)\n",
        "\n",
        "lenet_5_model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping_cb])\n",
        "\n",
        "lenet_5_model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brycW6YSbH7E"
      },
      "source": [
        "LeNet_5_SeLU\n",
        "\n",
        "SeLU performs better(speed & accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3mbjx1VbH7F"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "lenet_5_selu_model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=X_train[0].shape, padding='same'),\n",
        "    keras.layers.AveragePooling2D(),\n",
        "    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
        "    keras.layers.AveragePooling2D(),\n",
        "    keras.layers.Conv2D(120, kernel_size=5, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
        "    keras.layers.Flatten(),   \n",
        "    keras.layers.Dense(84, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(62, activation='softmax')\n",
        "])\n",
        "\n",
        "lenet_5_selu_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fHtepMIbH7G"
      },
      "outputs": [],
      "source": [
        "lenet_5_selu_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "# model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_lenet5_emnist_model.h5\", save_best_only=True)\n",
        "\n",
        "lenet_5_selu_model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), callbacks=[early_stopping_cb])\n",
        "\n",
        "lenet_5_selu_model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te_4hp58bH7G"
      },
      "source": [
        "3 - B. Mobilenet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy type의 data tf.tensor type으로 변경\n",
        "train_data = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "val_data = tf.convert_to_tensor(X_val, dtype=tf.float32)\n",
        "test_data = tf.convert_to_tensor(X_test, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "gq4WlwPcdMN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1채널 gray 영상 3채널로 변경 -> pretrained model이 3채널 영상 사용하기 때문\n",
        "final_train = tf.image.grayscale_to_rgb(train_data)\n",
        "final_val = tf.image.grayscale_to_rgb(val_data)\n",
        "final_test = tf.image.grayscale_to_rgb(val_data)"
      ],
      "metadata": {
        "id": "GXCu9gepdDT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mobilenet predtrained model 다운로드\n",
        "mobile2 = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape = (224, 224, 3), include_top=False)"
      ],
      "metadata": {
        "id": "n3KmN-fOeq-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9OC83dfbH7G"
      },
      "outputs": [],
      "source": [
        "# mobilenoet v2 파라미터 변경 baseline(test_acc : 0.8805)\n",
        "# Mobile_ReLU_SGD_800_05.h5\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(62, activation = 'softmax')\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate = 0.05)\n",
        "\n",
        "mobilev2_best_model = keras.models.Sequential()\n",
        "mobilev2_best_model.add(tf.keras.layers.Normalization( axis=-1, mean=44.412914, variance=84.77896, input_shape = (28, 28, 3)))\n",
        "mobilev2_best_model.add(tf.keras.layers.Resizing(height = 224, width = 224))\n",
        "mobilev2_best_model.add(mobile2)\n",
        "mobilev2_best_model.add(global_average_layer)\n",
        "mobilev2_best_model.add(tf.keras.layers.Dense(800))\n",
        "mobilev2_best_model.add(tf.keras.layers.LeakyReLU())\n",
        "mobilev2_best_model.add(tf.keras.layers.Dense(100))\n",
        "mobilev2_best_model.add(tf.keras.layers.LeakyReLU())\n",
        "mobilev2_best_model.add(prediction_layer)\n",
        "\n",
        "mobilev2_best_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 compile 및 training\n",
        "mobilev2_best_model.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=optimizer,\n",
        "                metrics=[\"accuracy\"])\n",
        "best_history = mobilev2_best_model.fit(final_train, y_train, epochs=20, validation_data=(final_val, y_val), callbacks=[early_stopping_cb])\n",
        "mobilev2_best_model.evaluate(final_test, y_test)"
      ],
      "metadata": {
        "id": "2R6flr8chq9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 eval\n",
        "mobilev2_best_model.evaluate(final_test, y_test)"
      ],
      "metadata": {
        "id": "hiLre_JPgTeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvY08e4fbH7I"
      },
      "source": [
        "4. Model 선정 및 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t02MvV0bH7I"
      },
      "source": [
        "4 - A.  Lenet base - new architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INefDJ4xbH7J"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "lenet_5_improved_model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, kernel_size=5, strides=2, activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=X_train[0].shape, padding='same'),\n",
        "    keras.layers.Conv2D(64, kernel_size=3, strides=2, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
        "    keras.layers.Conv2D(32, kernel_size=1, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
        "    keras.layers.GlobalAveragePooling2D(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(62, activation='softmax')\n",
        "])\n",
        "\n",
        "lenet_5_improved_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuDcqIJLbH7J"
      },
      "outputs": [],
      "source": [
        "lenet_5_improved_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "# model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_lenet5_emnist_model.h5\", save_best_only=True)\n",
        "\n",
        "lenet_5_improved_model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping_cb])\n",
        "\n",
        "lenet_5_improved_model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1Ij2EDTbH7J"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "lenet_5_selu_dropout_model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, kernel_size=5, strides=1,  activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=X_train[0].shape, padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(64, kernel_size=5, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(32, kernel_size=3, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.GlobalAveragePooling2D(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(62, activation='softmax')\n",
        "])\n",
        "\n",
        "lenet_5_selu_dropout_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICcPCq7AbH7J"
      },
      "outputs": [],
      "source": [
        "lenet_5_selu_dropout_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "# model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_lenet5_emnist_model.h5\", save_best_only=True)\n",
        "  \n",
        "lenet_5_selu_dropout_model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping_cb])\n",
        "\n",
        "lenet_5_selu_dropout_model.evaluate(X_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60iQZ4edbH7J"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "lenet_5_selu_bn_model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, kernel_size=5, strides=1,  activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=X_train[0].shape, padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(64, kernel_size=3, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(32, kernel_size=3, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.GlobalAveragePooling2D(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(62, activation='softmax')\n",
        "])\n",
        "\n",
        "lenet_5_selu_bn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iS063x0bH7K"
      },
      "outputs": [],
      "source": [
        "lenet_5_selu_bn_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "# model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_lenet5_emnist_model.h5\", save_best_only=True)\n",
        "  \n",
        "lenet_5_selu_bn_model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping_cb])\n",
        "\n",
        "lenet_5_selu_bn_model.evaluate(X_val, y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD0TD9mabH7K"
      },
      "source": [
        "4 - B.  Res base - new architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzW_zqUobH7K"
      },
      "outputs": [],
      "source": [
        "class ResnetBlock(keras.models.Model):\n",
        "    \"\"\"\n",
        "    A standard resnet block.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels: int, down_sample=False):\n",
        "        \"\"\"\n",
        "        channels: same as number of convolution kernels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.__channels = channels\n",
        "        self.__down_sample = down_sample\n",
        "        self.__strides = [2, 1] if down_sample else [1, 1]\n",
        "\n",
        "        KERNEL_SIZE = (3, 3)\n",
        "        # use He initialization, instead of Xavier (a.k.a 'glorot_uniform' in Keras), as suggested in [2]\n",
        "        INIT_SCHEME = \"he_normal\"\n",
        "\n",
        "        self.conv_1 = keras.layers.Conv2D(self.__channels, strides=self.__strides[0],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_1 = keras.layers.BatchNormalization()\n",
        "        self.conv_2 = keras.layers.Conv2D(self.__channels, strides=self.__strides[1],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_2 = keras.layers.BatchNormalization()\n",
        "        self.merge = keras.layers.Add()\n",
        "\n",
        "        if self.__down_sample:\n",
        "            # perform down sampling using stride of 2, according to [1].\n",
        "            self.res_conv = keras.layers.Conv2D(\n",
        "                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n",
        "            self.res_bn = keras.layers.BatchNormalization()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        res = inputs\n",
        "\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.bn_1(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.bn_2(x)\n",
        "\n",
        "        if self.__down_sample:\n",
        "            res = self.res_conv(res)\n",
        "            res = self.res_bn(res)\n",
        "\n",
        "        # if not perform down sample, then add a shortcut directly\n",
        "        x = self.merge([x, res])\n",
        "        out = tf.nn.relu(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVcIDaHQbH7L"
      },
      "outputs": [],
      "source": [
        "class ResNet18(keras.models.Model):\n",
        "\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        \"\"\"\n",
        "            num_classes: number of classes in specific classification task.\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv_1 = keras.layers.Conv2D(64, (7, 7), strides=2,\n",
        "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
        "        self.init_bn = keras.layers.BatchNormalization()\n",
        "        self.pool_2 = keras.layers.MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
        "        self.res_1_1 = ResnetBlock(64)\n",
        "        self.res_1_2 = ResnetBlock(64)\n",
        "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
        "        self.res_2_2 = ResnetBlock(128)\n",
        "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
        "        self.res_3_2 = ResnetBlock(256)\n",
        "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
        "        self.res_4_2 = ResnetBlock(512)\n",
        "        self.avg_pool = keras.layers.GlobalAveragePooling2D()\n",
        "        self.flat = keras.layers.Flatten()\n",
        "        self.fc = keras.layers.Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        out = self.conv_1(inputs)\n",
        "        out = self.init_bn(out)\n",
        "        out = tf.nn.relu(out)\n",
        "        out = self.pool_2(out)\n",
        "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
        "            out = res_block(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = self.flat(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uU252tlZbH7L"
      },
      "outputs": [],
      "source": [
        "resnet_model = ResNet18(62)\n",
        "resnet_model.build(input_shape = (None,28,28,1))\n",
        "#use categorical_crossentropy since the label is one-hot encoded\n",
        "\n",
        "# from keras.optimizers import SGD\n",
        "# opt = SGD(learning_rate=0.1,momentum=0.9,decay = 1e-04) #parameters suggested by He [1]\n",
        "resnet_model.compile(optimizer = \"adam\",loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
        "resnet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cIGjD9JbH7M"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKqlrYF3bH7N"
      },
      "source": [
        "Edit input kernel size & seperate upper layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dELExQE2bH7O"
      },
      "outputs": [],
      "source": [
        "class Res_5x5(keras.models.Model):\n",
        "\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        \"\"\"\n",
        "            num_classes: number of classes in specific classification task.\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        input_ch = 32\n",
        "        self.conv_1 = keras.layers.Conv2D(input_ch, (5, 5), strides=1,\n",
        "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
        "        self.pool_2 = keras.layers.MaxPool2D(pool_size=(2, 2), strides=1, padding=\"same\")\n",
        "        self.res_1_1 = ResnetBlock(input_ch)\n",
        "        self.res_1_2 = ResnetBlock(input_ch)\n",
        "        self.res_2_1 = ResnetBlock(input_ch*2, down_sample=True)\n",
        "        self.res_2_2 = ResnetBlock(input_ch*2)\n",
        "        \n",
        "        self.res_num_1 = ResnetBlock(input_ch*4, down_sample=True)\n",
        "        self.res_num_2 = ResnetBlock(input_ch*4)\n",
        "        \n",
        "        self.res_upper_1 = ResnetBlock(input_ch*4, down_sample=True)\n",
        "        self.res_upper_2 = ResnetBlock(input_ch*4)\n",
        "        self.res_upper_3 = ResnetBlock(input_ch*8, down_sample=True)\n",
        "        self.res_upper_4 = ResnetBlock(input_ch*8)\n",
        "   \n",
        "\n",
        "        self.res_lower_1 = ResnetBlock(input_ch*4, down_sample=True)\n",
        "        self.res_lower_2 = ResnetBlock(input_ch*4)\n",
        "\n",
        "        self.num_avg_pool = keras.layers.GlobalAveragePooling2D()\n",
        "        self.upper_avg_pool = keras.layers.GlobalAveragePooling2D()\n",
        "        self.lower_avg_pool = keras.layers.GlobalAveragePooling2D()\n",
        "\n",
        "        self.num_flat = keras.layers.Flatten()\n",
        "        self.upper_flat = keras.layers.Flatten()\n",
        "        self.lower_flat = keras.layers.Flatten()\n",
        "\n",
        "        self.fc_out = keras.layers.Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        out = keras.layers.BatchNormalization()(inputs)\n",
        "        out = self.conv_1(out)\n",
        "        out = tf.nn.relu(out)\n",
        "        out = self.pool_2(out)\n",
        "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2]:\n",
        "            out = res_block(out)\n",
        "        \n",
        "        num_out = self.res_num_1(out)\n",
        "        num_out = self.res_num_2(num_out)\n",
        "        num_out = self.num_avg_pool(num_out)\n",
        "        num_out = self.num_flat(num_out)\n",
        "\n",
        "        upper_out = self.res_upper_1(out)\n",
        "        upper_out = self.res_upper_2(upper_out)\n",
        "        upper_out = self.res_upper_3(upper_out)\n",
        "        upper_out = self.res_upper_4(upper_out)\n",
        "        upper_out = self.upper_avg_pool(upper_out)\n",
        "        upper_out = self.upper_flat(upper_out)\n",
        "\n",
        "        lower_out = self.res_lower_1(out)\n",
        "        lower_out = self.res_lower_2(lower_out)\n",
        "        lower_out = self.lower_avg_pool(lower_out)\n",
        "        lower_out = self.lower_flat(lower_out)\n",
        "\n",
        "        out = keras.layers.Concatenate()([num_out, upper_out, lower_out])\n",
        "\n",
        "        out = self.fc_out(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zu1BCVd9bH7O"
      },
      "outputs": [],
      "source": [
        "res_base_model = Res_5x5(62)\n",
        "res_base_model.build(input_shape = (None,28,28,1))\n",
        "#use categorical_crossentropy since the label is one-hot encoded\n",
        "\n",
        "# from keras.optimizers import SGD\n",
        "# opt = SGD(learning_rate=0.1,momentum=0.9,decay = 1e-04) #parameters suggested by He [1]\n",
        "res_base_model.compile(optimizer = \"adam\",loss='categorical_crossentropy', metrics=[\"accuracy\"]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QN0gmtg2bH7P"
      },
      "outputs": [],
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\",\n",
        ")\n",
        "\n",
        "es = EarlyStopping(patience= 5, restore_best_weights=True, monitor=\"val_accuracy\")\n",
        "\n",
        "batch_size = 256\n",
        "#I did not use cross validation, so the validate performance is not accurate.\n",
        "STEPS = len(X_train) / 256\n",
        "\n",
        "res_base_history = resnet_model.fit(aug.flow(X_train,y_train,batch_size = batch_size), \n",
        "      steps_per_epoch=STEPS, \n",
        "      batch_size = batch_size, \n",
        "      epochs=50, \n",
        "      validation_data=(X_val, y_val),\n",
        "      callbacks=[es])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYY6vAeabH7P"
      },
      "source": [
        "Res + Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zzFCvTDbH7P"
      },
      "outputs": [],
      "source": [
        "# res_dense 구조 best 모델 (test_acc : 87.5%)\n",
        "# parameter : 185,724\n",
        "\n",
        "class Res_dense(keras.models.Model):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        \"\"\"\n",
        "            num_classes: number of classes in specific classification task.\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        input_ch = 32\n",
        "        self.conv_1 = keras.layers.Conv2D(input_ch, (5, 5), strides=1,\n",
        "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
        "        self.pool_2 = keras.layers.MaxPool2D(pool_size=(2, 2), strides=1, padding=\"same\")\n",
        "        self.res_1_1 = ResnetBlock(input_ch)\n",
        "        self.res_1_2 = ResnetBlock(input_ch)\n",
        "        self.res_2_1 = ResnetBlock(input_ch*2, down_sample=True)\n",
        "        self.res_2_2 = ResnetBlock(input_ch*2)\n",
        "        \n",
        "        self.avg_pool = keras.layers.GlobalAveragePooling2D()\n",
        "        self.flat = keras.layers.Flatten()\n",
        "        \n",
        "        self.res_num_1 = keras.layers.Dense(46, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
        "        self.res_num_2 = keras.layers.Dense(28, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
        "        self.res_num_3 = keras.layers.Dense(10, activation = None)\n",
        "        \n",
        "        self.res_upper_1 = keras.layers.Dense(40, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
        "        self.res_upper_2 = keras.layers.Dense(26, activation = None)\n",
        "   \n",
        "\n",
        "        self.res_lower_1 = keras.layers.Dense(48, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
        "        self.res_lower_2 = keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
        "        self.res_lower_3 = keras.layers.Dense(26, activation = None)\n",
        "\n",
        "    def call(self, inputs):\n",
        "      # input 부터 feature detection part\n",
        "        out = keras.layers.BatchNormalization()(inputs)\n",
        "        out = self.conv_1(out)\n",
        "        out = keras.layers.BatchNormalization()(out)\n",
        "        out = self.pool_2(out)\n",
        "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2]:\n",
        "            out = res_block(out)\n",
        "\n",
        "        out = self.avg_pool(out)\n",
        "        feature_out = self.flat(out)\n",
        "\n",
        "      # 숫자 feture detection 부분 (분기 1)\n",
        "        num_out = self.res_num_1(feature_out)\n",
        "        num_out = keras.layers.BatchNormalization()(num_out)\n",
        "        num_out = self.res_num_2(num_out)\n",
        "        num_out = keras.layers.BatchNormalization()(num_out)\n",
        "        num_out = self.res_num_3(num_out)\n",
        "      \n",
        "      # 대문자 feature detection 부분 (분기 2)\n",
        "        upper_out = self.res_upper_1(feature_out)\n",
        "        upper_out = keras.layers.BatchNormalization()(upper_out)\n",
        "        upper_out = self.res_upper_2(upper_out)\n",
        "\n",
        "      # 대문자 feature detection 부분 (분기 2)\n",
        "        lower_out = self.res_lower_1(feature_out)\n",
        "        lower_out = keras.layers.BatchNormalization()(lower_out)\n",
        "        lower_out = self.res_lower_2(lower_out)\n",
        "        lower_out = keras.layers.BatchNormalization()(lower_out)\n",
        "        lower_out = self.res_lower_3(lower_out)\n",
        "\n",
        "      # concat 후 predict\n",
        "        final_out = keras.layers.Concatenate()([num_out, upper_out, lower_out])\n",
        "        result = tf.nn.softmax(final_out)\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjzZT0bUbH7Q"
      },
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.SGD(learning_rate = 0.01, momentum=0.9)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "res_dense_model = Res_dense()\n",
        "res_dense_model.build(input_shape = (None,28,28,1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res_dense_model.compile(optimizer = optimizer,loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
        "res_dense_model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=[early_stopping_cb])"
      ],
      "metadata": {
        "id": "ZHqUd9eI2zxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yjmj5bg5bH7Q"
      },
      "outputs": [],
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\",\n",
        ")\n",
        "\n",
        "es = EarlyStopping(patience= 5, restore_best_weights=True, monitor=\"val_accuracy\")\n",
        "\n",
        "batch_size = 256\n",
        "#I did not use cross validation, so the validate performance is not accurate.\n",
        "STEPS = len(X_train) / 256\n",
        "\n",
        "res_dense_history = resnet_model.fit(aug.flow(X_train,y_train,batch_size = batch_size), \n",
        "      steps_per_epoch=STEPS, \n",
        "      batch_size = batch_size, \n",
        "      epochs=50, \n",
        "      validation_data=(X_val, y_val),\n",
        "      callbacks=[es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NmWdCsHbH7Q"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHnwF3gGbH7Q"
      },
      "source": [
        "4 - C.  VGG – pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-w4b5dJUbH7Q"
      },
      "outputs": [],
      "source": [
        "inputs = Input(shape = (28,28,1))\n",
        "x = Conv2D (filters =32, kernel_size =3, padding ='same', activation='relu')(inputs)\n",
        "x = Conv2D (filters =32, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x= BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# 2nd Conv Block\n",
        "x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x= BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# 3rd Conv block  \n",
        "x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x) \n",
        "x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x) \n",
        "x= BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# 4th Conv block\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x= BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# 5th Conv block\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x= BatchNormalization()(x)\n",
        "x= Dropout(0.3)(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# Fully connected layers  \n",
        "x = Flatten()(x)\n",
        "x= BatchNormalization()(x)\n",
        "x = Dense(units = 4096, activation ='relu')(x)\n",
        "x = Dense(units = 4096, activation ='relu')(x)\n",
        "output = Dense(units = 62, activation ='softmax')(x)\n",
        "# creating the model\n",
        "\n",
        "VGG_model = Model (inputs=inputs, outputs =output)\n",
        "VGG_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7M464CnzbH7R"
      },
      "outputs": [],
      "source": [
        "VGG_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.005), loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "  \n",
        "VGG_model.fit(X_train, y_train, batch_size = 32, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping_cb])\n",
        "\n",
        "VGG_model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BJ3fRR3bH7R"
      },
      "outputs": [],
      "source": [
        "inputs = Input(shape = (28,28,1))\n",
        "x = Conv2D (filters =32, kernel_size =3, padding ='same', activation='relu')(inputs)\n",
        "x = Conv2D (filters =32, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x= BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# 2nd Conv Block\n",
        "x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x= BatchNormalization()(x)\n",
        "x= Dropout(0.3)(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# 3rd Conv block  \n",
        "x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x) \n",
        "x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x) \n",
        "x= BatchNormalization()(x)\n",
        "x= Dropout(0.3)(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# 4th Conv block\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x= BatchNormalization()(x)\n",
        "x= Dropout(0.3)(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# 5th Conv block\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x= BatchNormalization()(x)\n",
        "x= Dropout(0.3)(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# Fully connected layers  \n",
        "x = Flatten()(x)\n",
        "x= BatchNormalization()(x)\n",
        "x = Dense(units = 4096, activation ='relu')(x)\n",
        "x = Dense(units = 4096, activation ='relu')(x)\n",
        "output = Dense(units = 62, activation ='softmax')(x)\n",
        "# creating the model\n",
        "\n",
        "VGG_model_2 = Model (inputs=inputs, outputs =output)\n",
        "VGG_model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDg67J_XbH7R"
      },
      "outputs": [],
      "source": [
        "VGG_model_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.005), loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "# model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_new_emnist_model.h5\", save_best_only=True)\n",
        "  \n",
        "VGG_model_2.fit(X_train, y_train, batch_size = 32, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping_cb])\n",
        "\n",
        "VGG_model_2.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1s_NEciBbH7S"
      },
      "outputs": [],
      "source": [
        "inputs = Input(shape = (28,28,1))\n",
        "x = Conv2D (filters =32, kernel_size =3, padding ='same', activation='relu')(inputs)\n",
        "x = Conv2D (filters =32, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x= BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# 2nd Conv Block\n",
        "x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x= BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# 3rd Conv block  \n",
        "x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x) \n",
        "x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x) \n",
        "x= BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# 4th Conv block\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x= BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# 5th Conv block\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x= BatchNormalization()(x)\n",
        "x= Dropout(0.3)(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# Fully connected layers  \n",
        "x = Flatten()(x)\n",
        "x= BatchNormalization()(x)\n",
        "x = Dense(units = 4096, activation ='relu')(x)\n",
        "x = Dense(units = 4096, activation ='relu')(x)\n",
        "output = Dense(units = 62, activation ='softmax')(x)\n",
        "# creating the model\n",
        "\n",
        "VGG_model_3 = Model (inputs=inputs, outputs =output)\n",
        "VGG_model_3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E30zr1QsbH7S"
      },
      "outputs": [],
      "source": [
        "VGG_model_3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01), loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "# model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_new_emnist_model.h5\", save_best_only=True)\n",
        "  \n",
        "VGG_model_3.fit(X_train, y_train, batch_size = 64, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping_cb])\n",
        "\n",
        "VGG_model_3.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nsrYs68bH7S"
      },
      "outputs": [],
      "source": [
        "#new VGG\n",
        "inputs = Input(shape = (28,28,1))\n",
        "x = Conv2D (filters =32, kernel_size =3, padding ='same', activation='relu')(inputs)\n",
        "x = Conv2D (filters =32, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# 2nd Conv Block\n",
        "x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# 3rd Conv block  \n",
        "x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x) \n",
        "x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x) \n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# 4th Conv block\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# 5th Conv block\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "# Fully connected layers  \n",
        "x = Flatten()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(units = 4096, activation ='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(units = 4096, activation ='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "output = Dense(units = 62, activation ='softmax')(x)\n",
        "# creating the model\n",
        "\n",
        "VGG_model_4 = Model (inputs=inputs, outputs =output)\n",
        "VGG_model_4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuCTQNsfbH7S"
      },
      "outputs": [],
      "source": [
        "VGG_model_4.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.005), loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "# model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_new_model.h5\", save_best_only=True)\n",
        "  \n",
        "VGG_model_4.fit(X_train, y_train, batch_size = 64, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping_cb])\n",
        "\n",
        "VGG_model_4.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8GHRxaebH7W"
      },
      "source": [
        "4 - D.  Efficient net - pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9B_09njbH7W"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7A89Fg1bH7W"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqxXtcZ4bH7W"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSPBTU1tbH7W"
      },
      "source": [
        "Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qC6qvoEbH7W"
      },
      "outputs": [],
      "source": [
        "def plt_learning_curve(history, model_name):\n",
        "  pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "  plt.grid(True)\n",
        "  plt.gca().set_ylim(0, 1)\n",
        "  plt.title(f\"{model_name}'s learnig curve\", fontsize=14)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF24v77VbH7W"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P32NwJ2rbH7W"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_QlTe3PbH7X"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WolgGcwKbH7X"
      },
      "source": [
        "PreProcessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYm7mU5dbH7X"
      },
      "outputs": [],
      "source": [
        "def data_crop(data, mean):\n",
        "  # images = np.zeros((data.shape[0], 20, 20))\n",
        "  for i in range(data.shape[0]):\n",
        "    image = data[i]\n",
        "    first_norm = 255/np.max(image)\n",
        "    image = (image*first_norm).astype(np.uint8)\n",
        "\n",
        "    _, binary_image = cv2.threshold(image.astype(np.uint8), 20, 255, cv2.THRESH_BINARY)\n",
        "    min_max_list = np.where(binary_image==255)\n",
        "    x_min, x_max = np.min(min_max_list[1]), np.max(min_max_list[1])\n",
        "    y_min, y_max = np.min(min_max_list[0]), np.max(min_max_list[0])\n",
        "\n",
        "    if abs(x_max - x_min) >abs(y_max - y_min):\n",
        "      add_sub_factor = (abs(x_max - x_min) - abs(y_max - y_min))//2\n",
        "      y_min = max(0, y_min-add_sub_factor-1)\n",
        "      y_max = min(27, y_max+add_sub_factor+1)\n",
        "\n",
        "    if abs(y_max - y_min) > abs(x_max - x_min):\n",
        "      add_sub_factor = (abs(y_max - y_min)-abs(x_max - x_min))//2\n",
        "      x_min = max(0, x_min-add_sub_factor-1)\n",
        "      x_max = min(27, x_max+add_sub_factor+1)\n",
        "    # print(x_min, x_max)\n",
        "    # print(y_min, y_max)\n",
        "    data[i] = np.pad(cv2.resize(image.astype(np.uint8)[y_min:y_max, x_min:x_max], (20, 20)), ((4, 4), (4, 4)), 'constant', constant_values = 0)\n",
        "    second_norm = 255/np.max(data[i])\n",
        "    data[i] = (data[i]*second_norm).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvCXBEONbH7X"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.normalize(nparr, axis=-1, order=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dG1UU_J4bH7Y"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsBc5FZsbH7Y"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "report.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}