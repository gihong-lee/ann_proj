{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS & PREPRODUCTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU found\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "    \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhyunseokerikjung\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('emnist-byclass-mapping.txt', sep=\" \", header=None)\n",
    "data.columns = ['Target','ASCII']\n",
    "\n",
    "col=[]\n",
    "for i in data.ASCII.tolist():\n",
    "    col.append(chr(i))\n",
    "\n",
    "data['ASCII_Target'] = pd.Series(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_df = pd.read_csv('augmented_emnist.csv')\n",
    "aug_df.rename(columns={'25':'Target'}, inplace=True)\n",
    "\n",
    "# train_df=pd.merge(train_df, data, how='left', on='Target')\n",
    "# train_df=train_df.drop(['Target','ASCII'],axis=1)\n",
    "# train_df.rename(columns={'ASCII_Target':'Target'}, inplace=True)\n",
    "\n",
    "train_y = np.array(aug_df.pop('Target'))\n",
    "train_x = aug_df\n",
    "\n",
    "train_x = train_x / 255.0\n",
    "train_x = train_x.values.reshape([-1, 28, 28, 1])\n",
    "train_y = keras.utils.to_categorical(train_y)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_df = pd.read_csv('emnist-byclass-test.csv/emnist-byclass-test.csv')\n",
    "test_df.rename(columns={'18':'Target'}, inplace=True)\n",
    "\n",
    "# test_df=pd.merge(test_df, data, how='left', on='Target')\n",
    "# test_df=test_df.drop(['Target','ASCII'],axis=1)\n",
    "# test_df.rename(columns={'ASCII_Target':'Target'}, inplace=True)\n",
    "\n",
    "test_y = np.array(test_df.pop('Target'))\n",
    "test_x = test_df\n",
    "\n",
    "test_x = test_x / 255.0\n",
    "test_x = test_x.values.reshape([-1, 28, 28, 1])\n",
    "test_y = keras.utils.to_categorical(test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_df = pd.read_csv('our_handmade_dataset.csv')\n",
    "hand_df.rename(columns={'0':'Target'}, inplace=True)\n",
    "\n",
    "# hand_df=pd.merge(hand_df, data, how='left', on='Target')\n",
    "# hand_df=hand_df.drop(['Target','ASCII'],axis=1)\n",
    "# hand_df.rename(columns={'ASCII_Target':'Target'}, inplace=True)\n",
    "\n",
    "hand_y = np.array(hand_df.pop('Target'))\n",
    "hand_x = hand_df\n",
    "\n",
    "hand_x = hand_x / 255.0\n",
    "hand_x = hand_x.values.reshape([-1, 28, 28, 1])\n",
    "hand_y = keras.utils.to_categorical(hand_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode=\"constant\",\n",
    "    cval=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELS\n",
    "\n",
    "Original LeNet_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 6)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 1, 120)         48120     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                5270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,126\n",
      "Trainable params: 66,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "lenet_5_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation='tanh', input_shape=train_x[0].shape, padding='same'),\n",
    "    keras.layers.AveragePooling2D(),\n",
    "    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation='tanh', padding='valid'),\n",
    "    keras.layers.AveragePooling2D(),\n",
    "    keras.layers.Conv2D(120, kernel_size=5, strides=1, activation='tanh', padding='valid'),\n",
    "    keras.layers.Flatten(),   \n",
    "    keras.layers.Dense(84, activation='tanh'),\n",
    "    keras.layers.Dense(62, activation='softmax')\n",
    "])\n",
    "lenet_5_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220525_003539-pye8fbjh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/new_data_test/runs/pye8fbjh\" target=\"_blank\">grateful-shadow-2</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/new_data_test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13830/13830 [==============================] - 47s 3ms/step - loss: 0.8872 - accuracy: 0.6666 - val_loss: 0.7262 - val_accuracy: 0.7025 - _timestamp: 1653406599.0000 - _runtime: 60.0000\n",
      "Epoch 2/100\n",
      "13830/13830 [==============================] - 45s 3ms/step - loss: 0.6869 - accuracy: 0.7161 - val_loss: 0.6892 - val_accuracy: 0.7154 - _timestamp: 1653406644.0000 - _runtime: 105.0000\n",
      "Epoch 3/100\n",
      "13830/13830 [==============================] - 46s 3ms/step - loss: 0.6532 - accuracy: 0.7259 - val_loss: 0.6566 - val_accuracy: 0.7233 - _timestamp: 1653406690.0000 - _runtime: 151.0000\n",
      "Epoch 4/100\n",
      "13830/13830 [==============================] - 44s 3ms/step - loss: 0.6331 - accuracy: 0.7320 - val_loss: 0.6462 - val_accuracy: 0.7275 - _timestamp: 1653406735.0000 - _runtime: 196.0000\n",
      "Epoch 5/100\n",
      "13830/13830 [==============================] - 44s 3ms/step - loss: 0.6200 - accuracy: 0.7354 - val_loss: 0.6369 - val_accuracy: 0.7318 - _timestamp: 1653406779.0000 - _runtime: 240.0000\n",
      "Epoch 6/100\n",
      "13830/13830 [==============================] - 45s 3ms/step - loss: 0.6108 - accuracy: 0.7394 - val_loss: 0.6354 - val_accuracy: 0.7327 - _timestamp: 1653406824.0000 - _runtime: 285.0000\n",
      "Epoch 7/100\n",
      "13830/13830 [==============================] - 45s 3ms/step - loss: 0.6020 - accuracy: 0.7412 - val_loss: 0.6245 - val_accuracy: 0.7342 - _timestamp: 1653406868.0000 - _runtime: 329.0000\n",
      "Epoch 8/100\n",
      "13830/13830 [==============================] - 46s 3ms/step - loss: 0.5957 - accuracy: 0.7433 - val_loss: 0.6313 - val_accuracy: 0.7335 - _timestamp: 1653406914.0000 - _runtime: 375.0000\n",
      "Epoch 9/100\n",
      "13830/13830 [==============================] - 45s 3ms/step - loss: 0.5903 - accuracy: 0.7450 - val_loss: 0.6285 - val_accuracy: 0.7319 - _timestamp: 1653406959.0000 - _runtime: 420.0000\n",
      "Epoch 10/100\n",
      "13830/13830 [==============================] - 46s 3ms/step - loss: 0.5851 - accuracy: 0.7475 - val_loss: 0.6309 - val_accuracy: 0.7334 - _timestamp: 1653407005.0000 - _runtime: 466.0000\n",
      "Epoch 11/100\n",
      "13830/13830 [==============================] - 44s 3ms/step - loss: 0.5805 - accuracy: 0.7485 - val_loss: 0.6291 - val_accuracy: 0.7339 - _timestamp: 1653407049.0000 - _runtime: 510.0000\n",
      "Epoch 12/100\n",
      "13830/13830 [==============================] - 45s 3ms/step - loss: 0.5760 - accuracy: 0.7500 - val_loss: 0.6196 - val_accuracy: 0.7379 - _timestamp: 1653407094.0000 - _runtime: 555.0000\n",
      "Epoch 13/100\n",
      "13830/13830 [==============================] - 45s 3ms/step - loss: 0.5721 - accuracy: 0.7513 - val_loss: 0.6254 - val_accuracy: 0.7376 - _timestamp: 1653407139.0000 - _runtime: 600.0000\n",
      "Epoch 14/100\n",
      "13830/13830 [==============================] - 44s 3ms/step - loss: 0.5700 - accuracy: 0.7523 - val_loss: 0.6200 - val_accuracy: 0.7367 - _timestamp: 1653407184.0000 - _runtime: 645.0000\n",
      "Epoch 15/100\n",
      "13830/13830 [==============================] - 44s 3ms/step - loss: 0.5662 - accuracy: 0.7539 - val_loss: 0.6239 - val_accuracy: 0.7366 - _timestamp: 1653407228.0000 - _runtime: 689.0000\n",
      "Epoch 16/100\n",
      "13830/13830 [==============================] - 44s 3ms/step - loss: 0.5633 - accuracy: 0.7538 - val_loss: 0.6210 - val_accuracy: 0.7389 - _timestamp: 1653407271.0000 - _runtime: 732.0000\n",
      "Epoch 17/100\n",
      "13830/13830 [==============================] - 44s 3ms/step - loss: 0.5607 - accuracy: 0.7555 - val_loss: 0.6172 - val_accuracy: 0.7405 - _timestamp: 1653407315.0000 - _runtime: 776.0000\n",
      "Epoch 18/100\n",
      "13830/13830 [==============================] - 44s 3ms/step - loss: 0.5582 - accuracy: 0.7564 - val_loss: 0.6197 - val_accuracy: 0.7377 - _timestamp: 1653407360.0000 - _runtime: 821.0000\n",
      "Epoch 19/100\n",
      "13830/13830 [==============================] - 40s 3ms/step - loss: 0.5564 - accuracy: 0.7573 - val_loss: 0.6218 - val_accuracy: 0.7375 - _timestamp: 1653407400.0000 - _runtime: 861.0000\n",
      "Epoch 20/100\n",
      "13830/13830 [==============================] - 41s 3ms/step - loss: 0.5539 - accuracy: 0.7582 - val_loss: 0.6228 - val_accuracy: 0.7382 - _timestamp: 1653407441.0000 - _runtime: 902.0000\n",
      "Epoch 21/100\n",
      "13830/13830 [==============================] - 40s 3ms/step - loss: 0.5530 - accuracy: 0.7587 - val_loss: 0.6203 - val_accuracy: 0.7375 - _timestamp: 1653407481.0000 - _runtime: 942.0000\n",
      "Epoch 22/100\n",
      "13830/13830 [==============================] - 41s 3ms/step - loss: 0.5505 - accuracy: 0.7589 - val_loss: 0.6168 - val_accuracy: 0.7397 - _timestamp: 1653407523.0000 - _runtime: 984.0000\n",
      "Epoch 23/100\n",
      "13830/13830 [==============================] - 41s 3ms/step - loss: 0.5492 - accuracy: 0.7597 - val_loss: 0.6137 - val_accuracy: 0.7410 - _timestamp: 1653407564.0000 - _runtime: 1025.0000\n",
      "Epoch 24/100\n",
      "13830/13830 [==============================] - 40s 3ms/step - loss: 0.5463 - accuracy: 0.7612 - val_loss: 0.6178 - val_accuracy: 0.7407 - _timestamp: 1653407604.0000 - _runtime: 1065.0000\n",
      "Epoch 25/100\n",
      "13830/13830 [==============================] - 41s 3ms/step - loss: 0.5461 - accuracy: 0.7610 - val_loss: 0.6304 - val_accuracy: 0.7376 - _timestamp: 1653407645.0000 - _runtime: 1106.0000\n",
      "Epoch 26/100\n",
      "13830/13830 [==============================] - 40s 3ms/step - loss: 0.5438 - accuracy: 0.7622 - val_loss: 0.6216 - val_accuracy: 0.7365 - _timestamp: 1653407685.0000 - _runtime: 1146.0000\n",
      "Epoch 27/100\n",
      "13830/13830 [==============================] - 42s 3ms/step - loss: 0.5412 - accuracy: 0.7633 - val_loss: 0.6252 - val_accuracy: 0.7394 - _timestamp: 1653407727.0000 - _runtime: 1188.0000\n",
      "Epoch 28/100\n",
      "13830/13830 [==============================] - 41s 3ms/step - loss: 0.5410 - accuracy: 0.7638 - val_loss: 0.6239 - val_accuracy: 0.7387 - _timestamp: 1653407768.0000 - _runtime: 1229.0000\n",
      "Epoch 29/100\n",
      "13830/13830 [==============================] - 41s 3ms/step - loss: 0.5390 - accuracy: 0.7644 - val_loss: 0.6237 - val_accuracy: 0.7396 - _timestamp: 1653407809.0000 - _runtime: 1270.0000\n",
      "Epoch 30/100\n",
      "13830/13830 [==============================] - 41s 3ms/step - loss: 0.5391 - accuracy: 0.7641 - val_loss: 0.6244 - val_accuracy: 0.7381 - _timestamp: 1653407850.0000 - _runtime: 1311.0000\n",
      "Epoch 31/100\n",
      "13830/13830 [==============================] - 41s 3ms/step - loss: 0.5373 - accuracy: 0.7645 - val_loss: 0.6219 - val_accuracy: 0.7395 - _timestamp: 1653407892.0000 - _runtime: 1353.0000\n",
      "Epoch 32/100\n",
      "13830/13830 [==============================] - 41s 3ms/step - loss: 0.5363 - accuracy: 0.7653 - val_loss: 0.6188 - val_accuracy: 0.7399 - _timestamp: 1653407933.0000 - _runtime: 1394.0000\n",
      "Epoch 33/100\n",
      "13830/13830 [==============================] - 41s 3ms/step - loss: 0.5357 - accuracy: 0.7654 - val_loss: 0.6207 - val_accuracy: 0.7405 - _timestamp: 1653407974.0000 - _runtime: 1435.0000\n",
      "3636/3636 [==============================] - 6s 2ms/step - loss: 0.7132 - accuracy: 0.7460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.713187038898468, 0.7460497617721558]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet_5_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_lenet5_emnist_model.h5\", save_best_only=True)\n",
    "\n",
    "wandb.init(project=\"new_data_test\", entity=\"hyunseokerikjung\")\n",
    "lenet_5_model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y), callbacks=[early_stopping_cb, WandbCallback()])\n",
    "\n",
    "lenet_5_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 6)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 1, 120)         48120     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                5270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,126\n",
      "Trainable params: 66,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "lenet_5_model_img_gen = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation='tanh', input_shape=train_x[0].shape, padding='same'),\n",
    "    keras.layers.AveragePooling2D(),\n",
    "    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation='tanh', padding='valid'),\n",
    "    keras.layers.AveragePooling2D(),\n",
    "    keras.layers.Conv2D(120, kernel_size=5, strides=1, activation='tanh', padding='valid'),\n",
    "    keras.layers.Flatten(),   \n",
    "    keras.layers.Dense(84, activation='tanh'),\n",
    "    keras.layers.Dense(62, activation='softmax')\n",
    "])\n",
    "lenet_5_model_img_gen.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:pye8fbjh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b85ab537ab43b4b99c0262db98a800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.810 MB of 0.810 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▆▆▆▇▇▆▇▇▇▇▇▇██▇▇▇▇███▇▇███▇███</td></tr><tr><td>val_loss</td><td>█▆▄▃▂▂▂▂▂▂▂▁▂▁▂▁▁▁▂▂▁▁▁▁▂▁▂▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.76539</td></tr><tr><td>best_epoch</td><td>22</td></tr><tr><td>best_val_loss</td><td>0.61369</td></tr><tr><td>epoch</td><td>32</td></tr><tr><td>loss</td><td>0.53575</td></tr><tr><td>val_accuracy</td><td>0.74045</td></tr><tr><td>val_loss</td><td>0.62075</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">grateful-shadow-2</strong>: <a href=\"https://wandb.ai/hyunseokerikjung/new_data_test/runs/pye8fbjh\" target=\"_blank\">https://wandb.ai/hyunseokerikjung/new_data_test/runs/pye8fbjh</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220525_003539-pye8fbjh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:pye8fbjh). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\PC\\Desktop\\PyTorch\\LeNet_5_test_050322\\wandb\\run-20220525_005941-u7ygl56e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hyunseokerikjung/new_data_test/runs/u7ygl56e\" target=\"_blank\">treasured-morning-3</a></strong> to <a href=\"https://wandb.ai/hyunseokerikjung/new_data_test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13830/13830 [==============================] - 72s 5ms/step - loss: 1.0988 - accuracy: 0.6087 - val_loss: 0.7699 - val_accuracy: 0.6932 - _timestamp: 1653408069.0000 - _runtime: 83.0000\n",
      "Epoch 2/100\n",
      "13830/13830 [==============================] - 71s 5ms/step - loss: 0.8329 - accuracy: 0.6727 - val_loss: 0.7169 - val_accuracy: 0.7050 - _timestamp: 1653408140.0000 - _runtime: 154.0000\n",
      "Epoch 3/100\n",
      "13830/13830 [==============================] - 72s 5ms/step - loss: 0.7951 - accuracy: 0.6838 - val_loss: 0.6835 - val_accuracy: 0.7177 - _timestamp: 1653408212.0000 - _runtime: 226.0000\n",
      "Epoch 4/100\n",
      "13830/13830 [==============================] - 72s 5ms/step - loss: 0.7736 - accuracy: 0.6882 - val_loss: 0.6808 - val_accuracy: 0.7163 - _timestamp: 1653408284.0000 - _runtime: 298.0000\n",
      "Epoch 5/100\n",
      "13830/13830 [==============================] - 71s 5ms/step - loss: 0.7603 - accuracy: 0.6928 - val_loss: 0.6796 - val_accuracy: 0.7153 - _timestamp: 1653408355.0000 - _runtime: 369.0000\n",
      "Epoch 6/100\n",
      "13830/13830 [==============================] - 71s 5ms/step - loss: 0.7514 - accuracy: 0.6945 - val_loss: 0.6774 - val_accuracy: 0.7137 - _timestamp: 1653408426.0000 - _runtime: 440.0000\n",
      "Epoch 7/100\n",
      "13830/13830 [==============================] - 76s 5ms/step - loss: 0.7442 - accuracy: 0.6966 - val_loss: 0.6699 - val_accuracy: 0.7169 - _timestamp: 1653408502.0000 - _runtime: 516.0000\n",
      "Epoch 8/100\n",
      "13830/13830 [==============================] - 70s 5ms/step - loss: 0.7384 - accuracy: 0.6981 - val_loss: 0.6611 - val_accuracy: 0.7221 - _timestamp: 1653408572.0000 - _runtime: 586.0000\n",
      "Epoch 9/100\n",
      "13830/13830 [==============================] - 71s 5ms/step - loss: 0.7368 - accuracy: 0.6997 - val_loss: 0.6586 - val_accuracy: 0.7222 - _timestamp: 1653408643.0000 - _runtime: 657.0000\n",
      "Epoch 10/100\n",
      "13830/13830 [==============================] - 72s 5ms/step - loss: 0.7314 - accuracy: 0.7006 - val_loss: 0.6643 - val_accuracy: 0.7181 - _timestamp: 1653408715.0000 - _runtime: 729.0000\n",
      "Epoch 11/100\n",
      "13830/13830 [==============================] - 72s 5ms/step - loss: 0.7310 - accuracy: 0.7002 - val_loss: 0.6608 - val_accuracy: 0.7226 - _timestamp: 1653408786.0000 - _runtime: 800.0000\n",
      "Epoch 12/100\n",
      "13830/13830 [==============================] - 69s 5ms/step - loss: 0.7280 - accuracy: 0.7013 - val_loss: 0.6630 - val_accuracy: 0.7190 - _timestamp: 1653408855.0000 - _runtime: 869.0000\n",
      "Epoch 13/100\n",
      "13830/13830 [==============================] - 67s 5ms/step - loss: 0.7246 - accuracy: 0.7022 - val_loss: 0.6543 - val_accuracy: 0.7226 - _timestamp: 1653408922.0000 - _runtime: 936.0000\n",
      "Epoch 14/100\n",
      "13830/13830 [==============================] - 72s 5ms/step - loss: 0.7232 - accuracy: 0.7029 - val_loss: 0.6603 - val_accuracy: 0.7190 - _timestamp: 1653408995.0000 - _runtime: 1009.0000\n",
      "Epoch 15/100\n",
      "13830/13830 [==============================] - 71s 5ms/step - loss: 0.7215 - accuracy: 0.7034 - val_loss: 0.6601 - val_accuracy: 0.7196 - _timestamp: 1653409066.0000 - _runtime: 1080.0000\n",
      "Epoch 16/100\n",
      "13830/13830 [==============================] - 73s 5ms/step - loss: 0.7208 - accuracy: 0.7041 - val_loss: 0.6580 - val_accuracy: 0.7228 - _timestamp: 1653409139.0000 - _runtime: 1153.0000\n",
      "Epoch 17/100\n",
      "13830/13830 [==============================] - 73s 5ms/step - loss: 0.7177 - accuracy: 0.7038 - val_loss: 0.6553 - val_accuracy: 0.7203 - _timestamp: 1653409212.0000 - _runtime: 1226.0000\n",
      "Epoch 18/100\n",
      "13830/13830 [==============================] - 73s 5ms/step - loss: 0.7190 - accuracy: 0.7044 - val_loss: 0.6495 - val_accuracy: 0.7251 - _timestamp: 1653409284.0000 - _runtime: 1298.0000\n",
      "Epoch 19/100\n",
      "13830/13830 [==============================] - 72s 5ms/step - loss: 0.7170 - accuracy: 0.7051 - val_loss: 0.6614 - val_accuracy: 0.7214 - _timestamp: 1653409356.0000 - _runtime: 1370.0000\n",
      "Epoch 20/100\n",
      "13830/13830 [==============================] - 73s 5ms/step - loss: 0.7163 - accuracy: 0.7043 - val_loss: 0.6543 - val_accuracy: 0.7233 - _timestamp: 1653409428.0000 - _runtime: 1442.0000\n",
      "Epoch 21/100\n",
      "13830/13830 [==============================] - 73s 5ms/step - loss: 0.7157 - accuracy: 0.7046 - val_loss: 0.6487 - val_accuracy: 0.7261 - _timestamp: 1653409501.0000 - _runtime: 1515.0000\n",
      "Epoch 22/100\n",
      "13830/13830 [==============================] - 73s 5ms/step - loss: 0.7171 - accuracy: 0.7052 - val_loss: 0.6503 - val_accuracy: 0.7230 - _timestamp: 1653409574.0000 - _runtime: 1588.0000\n",
      "Epoch 23/100\n",
      "13830/13830 [==============================] - 71s 5ms/step - loss: 0.7155 - accuracy: 0.7051 - val_loss: 0.6540 - val_accuracy: 0.7202 - _timestamp: 1653409645.0000 - _runtime: 1659.0000\n",
      "Epoch 24/100\n",
      "13830/13830 [==============================] - 71s 5ms/step - loss: 0.7157 - accuracy: 0.7051 - val_loss: 0.6534 - val_accuracy: 0.7220 - _timestamp: 1653409716.0000 - _runtime: 1730.0000\n",
      "Epoch 25/100\n",
      "13830/13830 [==============================] - 70s 5ms/step - loss: 0.7148 - accuracy: 0.7056 - val_loss: 0.6480 - val_accuracy: 0.7238 - _timestamp: 1653409786.0000 - _runtime: 1800.0000\n",
      "Epoch 26/100\n",
      "13830/13830 [==============================] - 72s 5ms/step - loss: 0.7129 - accuracy: 0.7067 - val_loss: 0.6517 - val_accuracy: 0.7255 - _timestamp: 1653409858.0000 - _runtime: 1872.0000\n",
      "Epoch 27/100\n",
      "13830/13830 [==============================] - 75s 5ms/step - loss: 0.7133 - accuracy: 0.7051 - val_loss: 0.6571 - val_accuracy: 0.7204 - _timestamp: 1653409933.0000 - _runtime: 1947.0000\n",
      "Epoch 28/100\n",
      "13830/13830 [==============================] - 77s 6ms/step - loss: 0.7134 - accuracy: 0.7054 - val_loss: 0.6503 - val_accuracy: 0.7236 - _timestamp: 1653410010.0000 - _runtime: 2024.0000\n",
      "Epoch 29/100\n",
      "13830/13830 [==============================] - 71s 5ms/step - loss: 0.7132 - accuracy: 0.7061 - val_loss: 0.6507 - val_accuracy: 0.7213 - _timestamp: 1653410081.0000 - _runtime: 2095.0000\n",
      "Epoch 30/100\n",
      "13830/13830 [==============================] - 73s 5ms/step - loss: 0.7123 - accuracy: 0.7061 - val_loss: 0.6568 - val_accuracy: 0.7217 - _timestamp: 1653410153.0000 - _runtime: 2167.0000\n",
      "Epoch 31/100\n",
      "13830/13830 [==============================] - 73s 5ms/step - loss: 0.7125 - accuracy: 0.7057 - val_loss: 0.6473 - val_accuracy: 0.7247 - _timestamp: 1653410227.0000 - _runtime: 2241.0000\n",
      "Epoch 32/100\n",
      "13830/13830 [==============================] - 68s 5ms/step - loss: 0.7124 - accuracy: 0.7061 - val_loss: 0.6432 - val_accuracy: 0.7278 - _timestamp: 1653410294.0000 - _runtime: 2308.0000\n",
      "Epoch 33/100\n",
      "13830/13830 [==============================] - 74s 5ms/step - loss: 0.7118 - accuracy: 0.7061 - val_loss: 0.6426 - val_accuracy: 0.7235 - _timestamp: 1653410369.0000 - _runtime: 2383.0000\n",
      "Epoch 34/100\n",
      "13830/13830 [==============================] - 71s 5ms/step - loss: 0.7124 - accuracy: 0.7061 - val_loss: 0.6393 - val_accuracy: 0.7274 - _timestamp: 1653410440.0000 - _runtime: 2454.0000\n",
      "Epoch 35/100\n",
      "13830/13830 [==============================] - 73s 5ms/step - loss: 0.7118 - accuracy: 0.7060 - val_loss: 0.6541 - val_accuracy: 0.7205 - _timestamp: 1653410513.0000 - _runtime: 2527.0000\n",
      "Epoch 36/100\n",
      "13830/13830 [==============================] - 73s 5ms/step - loss: 0.7100 - accuracy: 0.7068 - val_loss: 0.6521 - val_accuracy: 0.7222 - _timestamp: 1653410586.0000 - _runtime: 2600.0000\n",
      "Epoch 37/100\n",
      "13830/13830 [==============================] - 71s 5ms/step - loss: 0.7093 - accuracy: 0.7061 - val_loss: 0.6439 - val_accuracy: 0.7265 - _timestamp: 1653410657.0000 - _runtime: 2671.0000\n",
      "Epoch 38/100\n",
      "13830/13830 [==============================] - 73s 5ms/step - loss: 0.7099 - accuracy: 0.7060 - val_loss: 0.6516 - val_accuracy: 0.7241 - _timestamp: 1653410730.0000 - _runtime: 2744.0000\n",
      "Epoch 39/100\n",
      "13830/13830 [==============================] - 70s 5ms/step - loss: 0.7125 - accuracy: 0.7059 - val_loss: 0.6468 - val_accuracy: 0.7257 - _timestamp: 1653410800.0000 - _runtime: 2814.0000\n",
      "Epoch 40/100\n",
      "13830/13830 [==============================] - 75s 5ms/step - loss: 0.7076 - accuracy: 0.7069 - val_loss: 0.6472 - val_accuracy: 0.7236 - _timestamp: 1653410875.0000 - _runtime: 2889.0000\n",
      "Epoch 41/100\n",
      "13830/13830 [==============================] - 72s 5ms/step - loss: 0.7090 - accuracy: 0.7064 - val_loss: 0.6470 - val_accuracy: 0.7233 - _timestamp: 1653410947.0000 - _runtime: 2961.0000\n",
      "Epoch 42/100\n",
      "13830/13830 [==============================] - 72s 5ms/step - loss: 0.7092 - accuracy: 0.7068 - val_loss: 0.6420 - val_accuracy: 0.7270 - _timestamp: 1653411019.0000 - _runtime: 3033.0000\n",
      "Epoch 43/100\n",
      "13830/13830 [==============================] - 73s 5ms/step - loss: 0.7100 - accuracy: 0.7067 - val_loss: 0.6516 - val_accuracy: 0.7225 - _timestamp: 1653411092.0000 - _runtime: 3106.0000\n",
      "Epoch 44/100\n",
      "13830/13830 [==============================] - 70s 5ms/step - loss: 0.7100 - accuracy: 0.7065 - val_loss: 0.6539 - val_accuracy: 0.7218 - _timestamp: 1653411163.0000 - _runtime: 3177.0000\n",
      "3636/3636 [==============================] - 6s 2ms/step - loss: 0.6026 - accuracy: 0.7416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6026073098182678, 0.7416223883628845]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet_5_model_img_gen.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_lenet5_emnist_model.h5\", save_best_only=True)\n",
    "\n",
    "wandb.init(project=\"new_data_test\", entity=\"hyunseokerikjung\")\n",
    "lenet_5_model_img_gen.fit(aug.flow(train_x, train_y), epochs=100, validation_data=(val_x, val_y), callbacks=[early_stopping_cb, WandbCallback()])\n",
    "\n",
    "lenet_5_model_img_gen.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 16)        416       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 16)       64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 64)        25664     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 32)        18464     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 32)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 32)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 62)                2046      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47,038\n",
      "Trainable params: 46,814\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "my_lenet_5_selu_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(16, kernel_size=5, strides=1,  activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=train_x[0].shape, padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, kernel_size=5, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(32, kernel_size=3, strides=1, activation=\"selu\", kernel_initializer=\"lecun_normal\", padding='valid'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(62, activation='softmax')\n",
    "])\n",
    "\n",
    "my_lenet_5_selu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 1.1038 - accuracy: 0.6280 - val_loss: 0.9673 - val_accuracy: 0.6450 - _timestamp: 1653411219.0000 - _runtime: 3233.0000\n",
      "Epoch 2/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.7763 - accuracy: 0.6993 - val_loss: 0.7697 - val_accuracy: 0.6999 - _timestamp: 1653411268.0000 - _runtime: 3282.0000\n",
      "Epoch 3/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.7315 - accuracy: 0.7109 - val_loss: 0.7919 - val_accuracy: 0.6919 - _timestamp: 1653411317.0000 - _runtime: 3331.0000\n",
      "Epoch 4/100\n",
      "13830/13830 [==============================] - 48s 4ms/step - loss: 0.7088 - accuracy: 0.7174 - val_loss: 0.7055 - val_accuracy: 0.7173 - _timestamp: 1653411365.0000 - _runtime: 3379.0000\n",
      "Epoch 5/100\n",
      "13830/13830 [==============================] - 47s 3ms/step - loss: 0.6942 - accuracy: 0.7206 - val_loss: 0.7237 - val_accuracy: 0.7133 - _timestamp: 1653411412.0000 - _runtime: 3426.0000\n",
      "Epoch 6/100\n",
      "13830/13830 [==============================] - 50s 4ms/step - loss: 0.6827 - accuracy: 0.7239 - val_loss: 0.6651 - val_accuracy: 0.7286 - _timestamp: 1653411462.0000 - _runtime: 3476.0000\n",
      "Epoch 7/100\n",
      "13830/13830 [==============================] - 48s 4ms/step - loss: 0.6742 - accuracy: 0.7266 - val_loss: 0.6627 - val_accuracy: 0.7295 - _timestamp: 1653411511.0000 - _runtime: 3525.0000\n",
      "Epoch 8/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.6666 - accuracy: 0.7280 - val_loss: 0.6521 - val_accuracy: 0.7343 - _timestamp: 1653411559.0000 - _runtime: 3573.0000\n",
      "Epoch 9/100\n",
      "13830/13830 [==============================] - 48s 3ms/step - loss: 0.6612 - accuracy: 0.7300 - val_loss: 0.6341 - val_accuracy: 0.7387 - _timestamp: 1653411608.0000 - _runtime: 3622.0000\n",
      "Epoch 10/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.6566 - accuracy: 0.7306 - val_loss: 0.6413 - val_accuracy: 0.7349 - _timestamp: 1653411657.0000 - _runtime: 3671.0000\n",
      "Epoch 11/100\n",
      "13830/13830 [==============================] - 48s 3ms/step - loss: 0.6517 - accuracy: 0.7323 - val_loss: 0.6299 - val_accuracy: 0.7380 - _timestamp: 1653411705.0000 - _runtime: 3719.0000\n",
      "Epoch 12/100\n",
      "13830/13830 [==============================] - 48s 3ms/step - loss: 0.6477 - accuracy: 0.7337 - val_loss: 0.6370 - val_accuracy: 0.7351 - _timestamp: 1653411753.0000 - _runtime: 3767.0000\n",
      "Epoch 13/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.6446 - accuracy: 0.7343 - val_loss: 0.6377 - val_accuracy: 0.7368 - _timestamp: 1653411802.0000 - _runtime: 3816.0000\n",
      "Epoch 14/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.6426 - accuracy: 0.7346 - val_loss: 0.6340 - val_accuracy: 0.7357 - _timestamp: 1653411851.0000 - _runtime: 3865.0000\n",
      "Epoch 15/100\n",
      "13830/13830 [==============================] - 48s 3ms/step - loss: 0.6386 - accuracy: 0.7361 - val_loss: 0.6314 - val_accuracy: 0.7404 - _timestamp: 1653411899.0000 - _runtime: 3913.0000\n",
      "Epoch 16/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.6359 - accuracy: 0.7365 - val_loss: 0.6554 - val_accuracy: 0.7302 - _timestamp: 1653411948.0000 - _runtime: 3962.0000\n",
      "Epoch 17/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.6345 - accuracy: 0.7367 - val_loss: 0.6223 - val_accuracy: 0.7412 - _timestamp: 1653411997.0000 - _runtime: 4011.0000\n",
      "Epoch 18/100\n",
      "13830/13830 [==============================] - 48s 3ms/step - loss: 0.6307 - accuracy: 0.7385 - val_loss: 0.6118 - val_accuracy: 0.7420 - _timestamp: 1653412045.0000 - _runtime: 4059.0000\n",
      "Epoch 19/100\n",
      "13830/13830 [==============================] - 48s 3ms/step - loss: 0.6291 - accuracy: 0.7382 - val_loss: 0.6105 - val_accuracy: 0.7442 - _timestamp: 1653412094.0000 - _runtime: 4108.0000\n",
      "Epoch 20/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.6268 - accuracy: 0.7392 - val_loss: 0.6130 - val_accuracy: 0.7418 - _timestamp: 1653412143.0000 - _runtime: 4157.0000\n",
      "Epoch 21/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.6246 - accuracy: 0.7400 - val_loss: 0.6206 - val_accuracy: 0.7393 - _timestamp: 1653412192.0000 - _runtime: 4206.0000\n",
      "Epoch 22/100\n",
      "13830/13830 [==============================] - 47s 3ms/step - loss: 0.6230 - accuracy: 0.7403 - val_loss: 0.6184 - val_accuracy: 0.7423 - _timestamp: 1653412239.0000 - _runtime: 4253.0000\n",
      "Epoch 23/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.6220 - accuracy: 0.7406 - val_loss: 0.6137 - val_accuracy: 0.7413 - _timestamp: 1653412289.0000 - _runtime: 4303.0000\n",
      "Epoch 24/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.6203 - accuracy: 0.7414 - val_loss: 0.6218 - val_accuracy: 0.7403 - _timestamp: 1653412338.0000 - _runtime: 4352.0000\n",
      "Epoch 25/100\n",
      "13830/13830 [==============================] - 48s 3ms/step - loss: 0.6188 - accuracy: 0.7418 - val_loss: 0.6121 - val_accuracy: 0.7435 - _timestamp: 1653412386.0000 - _runtime: 4400.0000\n",
      "Epoch 26/100\n",
      "13830/13830 [==============================] - 48s 4ms/step - loss: 0.6171 - accuracy: 0.7424 - val_loss: 0.6101 - val_accuracy: 0.7424 - _timestamp: 1653412434.0000 - _runtime: 4448.0000\n",
      "Epoch 27/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.6163 - accuracy: 0.7433 - val_loss: 0.6015 - val_accuracy: 0.7458 - _timestamp: 1653412484.0000 - _runtime: 4498.0000\n",
      "Epoch 28/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.6150 - accuracy: 0.7433 - val_loss: 0.6015 - val_accuracy: 0.7466 - _timestamp: 1653412532.0000 - _runtime: 4546.0000\n",
      "Epoch 29/100\n",
      "13830/13830 [==============================] - 48s 3ms/step - loss: 0.6122 - accuracy: 0.7435 - val_loss: 0.5972 - val_accuracy: 0.7467 - _timestamp: 1653412581.0000 - _runtime: 4595.0000\n",
      "Epoch 30/100\n",
      "13830/13830 [==============================] - 48s 3ms/step - loss: 0.6132 - accuracy: 0.7430 - val_loss: 0.6031 - val_accuracy: 0.7436 - _timestamp: 1653412629.0000 - _runtime: 4643.0000\n",
      "Epoch 31/100\n",
      "13830/13830 [==============================] - 50s 4ms/step - loss: 0.6110 - accuracy: 0.7440 - val_loss: 0.6050 - val_accuracy: 0.7451 - _timestamp: 1653412678.0000 - _runtime: 4692.0000\n",
      "Epoch 32/100\n",
      "13830/13830 [==============================] - 48s 3ms/step - loss: 0.6097 - accuracy: 0.7445 - val_loss: 0.6005 - val_accuracy: 0.7465 - _timestamp: 1653412726.0000 - _runtime: 4740.0000\n",
      "Epoch 33/100\n",
      "13830/13830 [==============================] - 48s 4ms/step - loss: 0.6091 - accuracy: 0.7444 - val_loss: 0.5972 - val_accuracy: 0.7462 - _timestamp: 1653412775.0000 - _runtime: 4789.0000\n",
      "Epoch 34/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.6076 - accuracy: 0.7450 - val_loss: 0.5922 - val_accuracy: 0.7491 - _timestamp: 1653412824.0000 - _runtime: 4838.0000\n",
      "Epoch 35/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.6069 - accuracy: 0.7454 - val_loss: 0.5974 - val_accuracy: 0.7466 - _timestamp: 1653412873.0000 - _runtime: 4887.0000\n",
      "Epoch 36/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.6060 - accuracy: 0.7452 - val_loss: 0.5898 - val_accuracy: 0.7486 - _timestamp: 1653412922.0000 - _runtime: 4936.0000\n",
      "Epoch 37/100\n",
      "13830/13830 [==============================] - 48s 3ms/step - loss: 0.6052 - accuracy: 0.7459 - val_loss: 0.5930 - val_accuracy: 0.7504 - _timestamp: 1653412970.0000 - _runtime: 4984.0000\n",
      "Epoch 38/100\n",
      "13830/13830 [==============================] - 50s 4ms/step - loss: 0.6048 - accuracy: 0.7452 - val_loss: 0.5996 - val_accuracy: 0.7447 - _timestamp: 1653413020.0000 - _runtime: 5034.0000\n",
      "Epoch 39/100\n",
      "13830/13830 [==============================] - 48s 3ms/step - loss: 0.6030 - accuracy: 0.7467 - val_loss: 0.5966 - val_accuracy: 0.7479 - _timestamp: 1653413068.0000 - _runtime: 5082.0000\n",
      "Epoch 40/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.6023 - accuracy: 0.7466 - val_loss: 0.5902 - val_accuracy: 0.7500 - _timestamp: 1653413117.0000 - _runtime: 5131.0000\n",
      "Epoch 41/100\n",
      "13830/13830 [==============================] - 50s 4ms/step - loss: 0.6021 - accuracy: 0.7460 - val_loss: 0.5860 - val_accuracy: 0.7505 - _timestamp: 1653413167.0000 - _runtime: 5181.0000\n",
      "Epoch 42/100\n",
      "13830/13830 [==============================] - 48s 3ms/step - loss: 0.6010 - accuracy: 0.7467 - val_loss: 0.5888 - val_accuracy: 0.7495 - _timestamp: 1653413214.0000 - _runtime: 5228.0000\n",
      "Epoch 43/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.6000 - accuracy: 0.7475 - val_loss: 0.5882 - val_accuracy: 0.7501 - _timestamp: 1653413264.0000 - _runtime: 5278.0000\n",
      "Epoch 44/100\n",
      "13830/13830 [==============================] - 48s 3ms/step - loss: 0.5992 - accuracy: 0.7478 - val_loss: 0.5881 - val_accuracy: 0.7501 - _timestamp: 1653413312.0000 - _runtime: 5326.0000\n",
      "Epoch 45/100\n",
      "13830/13830 [==============================] - 50s 4ms/step - loss: 0.5989 - accuracy: 0.7470 - val_loss: 0.5815 - val_accuracy: 0.7505 - _timestamp: 1653413362.0000 - _runtime: 5376.0000\n",
      "Epoch 46/100\n",
      "13830/13830 [==============================] - 48s 3ms/step - loss: 0.5982 - accuracy: 0.7480 - val_loss: 0.5796 - val_accuracy: 0.7545 - _timestamp: 1653413409.0000 - _runtime: 5423.0000\n",
      "Epoch 47/100\n",
      "13830/13830 [==============================] - 47s 3ms/step - loss: 0.5973 - accuracy: 0.7482 - val_loss: 0.5908 - val_accuracy: 0.7493 - _timestamp: 1653413457.0000 - _runtime: 5471.0000\n",
      "Epoch 48/100\n",
      "13830/13830 [==============================] - 50s 4ms/step - loss: 0.5959 - accuracy: 0.7491 - val_loss: 0.5812 - val_accuracy: 0.7524 - _timestamp: 1653413506.0000 - _runtime: 5520.0000\n",
      "Epoch 49/100\n",
      "13830/13830 [==============================] - 47s 3ms/step - loss: 0.5959 - accuracy: 0.7487 - val_loss: 0.5975 - val_accuracy: 0.7492 - _timestamp: 1653413553.0000 - _runtime: 5567.0000\n",
      "Epoch 50/100\n",
      "13830/13830 [==============================] - 48s 4ms/step - loss: 0.5951 - accuracy: 0.7495 - val_loss: 0.5853 - val_accuracy: 0.7493 - _timestamp: 1653413601.0000 - _runtime: 5615.0000\n",
      "Epoch 51/100\n",
      "13830/13830 [==============================] - 47s 3ms/step - loss: 0.5944 - accuracy: 0.7489 - val_loss: 0.5922 - val_accuracy: 0.7487 - _timestamp: 1653413649.0000 - _runtime: 5663.0000\n",
      "Epoch 52/100\n",
      "13830/13830 [==============================] - 49s 4ms/step - loss: 0.5939 - accuracy: 0.7487 - val_loss: 0.5876 - val_accuracy: 0.7494 - _timestamp: 1653413697.0000 - _runtime: 5711.0000\n",
      "Epoch 53/100\n",
      "13830/13830 [==============================] - 48s 3ms/step - loss: 0.5937 - accuracy: 0.7489 - val_loss: 0.5809 - val_accuracy: 0.7533 - _timestamp: 1653413745.0000 - _runtime: 5759.0000\n",
      "Epoch 54/100\n",
      "13830/13830 [==============================] - 47s 3ms/step - loss: 0.5924 - accuracy: 0.7498 - val_loss: 0.5828 - val_accuracy: 0.7515 - _timestamp: 1653413792.0000 - _runtime: 5806.0000\n",
      "Epoch 55/100\n",
      "13830/13830 [==============================] - 50s 4ms/step - loss: 0.5917 - accuracy: 0.7490 - val_loss: 0.5816 - val_accuracy: 0.7524 - _timestamp: 1653413842.0000 - _runtime: 5856.0000\n",
      "Epoch 56/100\n",
      "13830/13830 [==============================] - 47s 3ms/step - loss: 0.5919 - accuracy: 0.7497 - val_loss: 0.5820 - val_accuracy: 0.7519 - _timestamp: 1653413888.0000 - _runtime: 5902.0000\n",
      "3636/3636 [==============================] - 6s 2ms/step - loss: 0.5790 - accuracy: 0.7883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5789974331855774, 0.7883375287055969]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lenet_5_selu_model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "  \n",
    "my_lenet_5_selu_model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y), callbacks=[early_stopping_cb, WandbCallback()])\n",
    "\n",
    "my_lenet_5_selu_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.time()\n",
    "now = time.localtime(now)\n",
    "my_lenet_5_selu_model.save(\"my_lenet5_emnist_model_%2d%02d%02d%02d%02d.h5\" %(now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min), save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cca9558bc5ad879ec93cc030b157d75f18267527c60932cecaace349eef54dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
